{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test basique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlflow import log_metric, log_param, log_artifact, end_run\n",
    "\n",
    "# Log a parameter (key-value pair)\n",
    "log_param(\"param1\", 5)\n",
    "\n",
    "# Log a metric; metrics can be updated throughout the run\n",
    "log_metric(\"foo\", 1)\n",
    "log_metric(\"foo\", 2)\n",
    "log_metric(\"foo\", 3)\n",
    "\n",
    "# Log an artifact (output file)\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"Hello world!\")\n",
    "log_artifact(\"output.txt\")\n",
    "end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.42073\n",
      "[1]\ttrain-mlogloss:0.22429\n",
      "[2]\ttrain-mlogloss:0.13501\n",
      "[3]\ttrain-mlogloss:0.09029\n",
      "[4]\ttrain-mlogloss:0.06451\n",
      "[5]\ttrain-mlogloss:0.05024\n",
      "[6]\ttrain-mlogloss:0.04099\n",
      "[7]\ttrain-mlogloss:0.03578\n",
      "[8]\ttrain-mlogloss:0.03339\n",
      "[9]\ttrain-mlogloss:0.03100\n",
      "weight ('f2', 'f3', 'f0', 'f1') (42, 18, 14, 17)\n",
      "gain ('f2', 'f3', 'f0', 'f1') (4.49206670922857, 2.831508774066668, 0.10483915840714284, 0.26904017021764703)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import xgboost as xgb\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "\n",
    "mpl.use('Agg')\n",
    "# prepare train and test data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# enable auto logging\n",
    "mlflow.xgboost.autolog(importance_types=['weight', 'gain'])\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # train model\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 3,\n",
    "        'learning_rate': 0.7,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'colsample_bytree': 1.0,\n",
    "        'subsample': 1,\n",
    "        'seed': 42,\n",
    "    }\n",
    "    model = xgb.train(params, dtrain,10,  evals=[(dtrain, 'train')])\n",
    "\n",
    "    # evaluate model\n",
    "    y_proba = model.predict(dtest)\n",
    "    y_pred = y_proba.argmax(axis=1)\n",
    "    loss = log_loss(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # log metrics\n",
    "    mlflow.log_metrics({'log_loss': loss, 'accuracy': acc})\n",
    "    \n",
    "    importance_types=['weight', 'gain']\n",
    "    for imp_type in importance_types:\n",
    "        imp = model.get_score(importance_type=imp_type)\n",
    "        features, importance = zip(*imp.items())\n",
    "        print(imp_type, features, importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.600000, l1_ratio=0.550000):\n",
      "  RMSE: 0.8220049455533543\n",
      "  MAE: 0.6558406216552346\n",
      "  R2: 0.04262388082012969\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "\n",
    "# Read the wine-quality csv file from the URL\n",
    "csv_url =\\\n",
    "    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "try:\n",
    "    data = pd.read_csv(csv_url, sep=';')\n",
    "except Exception as e:\n",
    "    logger.exception(\n",
    "        \"Unable to download training & test CSV, check your internet connection. Error: %s\", e)\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "\n",
    "alpha = 0.6\n",
    "l1_ratio = 0.55\n",
    "\n",
    "with mlflow.start_run():\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "    # Model registry does not work with file store\n",
    "    if tracking_url_type_store != \"file\":\n",
    "\n",
    "        # Register the model\n",
    "        # There are other ways to use the Model Registry, which depends on the use case,\n",
    "        # please refer to the doc for more information:\n",
    "        # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "        mlflow.sklearn.log_model(lr, \"model\", registered_model_name=\"ElasticnetWineModel\")\n",
    "    else:\n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6666666666666666\n",
      "Model saved in run 95c8f727aa8d480187c50a8970f16bb8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "X = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\n",
    "y = np.array([0, 0, 1, 1, 1, 0])\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "score = lr.score(X, y)\n",
    "print(\"Score: %s\" % score)\n",
    "\n",
    "mlflow.set_tracking_uri('file:/mnt/z/temp/mlruns')\n",
    "mlflow.set_experiment('Duret√© Shore')\n",
    "\n",
    "mlflow.log_param(\"learning_rate\", \"0.7\")\n",
    "mlflow.set_tag(\"source\",\"SCML,METEO,QMP\")\n",
    "mlflow.set_tag(\"notebook\",\"76\")\n",
    "\n",
    "mlflow.log_metric(\"score\", score)\n",
    "mlflow.sklearn.log_model(lr, \"model\")\n",
    "print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
