// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: databricks.proto

package com.databricks.api.proto.databricks;

public final class Databricks {
  private Databricks() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
    registry.add(com.databricks.api.proto.databricks.Databricks.visibility);
    registry.add(com.databricks.api.proto.databricks.Databricks.validateRequired);
    registry.add(com.databricks.api.proto.databricks.Databricks.jsonInline);
    registry.add(com.databricks.api.proto.databricks.Databricks.jsonMap);
    registry.add(com.databricks.api.proto.databricks.Databricks.fieldDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.rpc);
    registry.add(com.databricks.api.proto.databricks.Databricks.methodDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.messageDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.serviceDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.enumDoc);
    registry.add(com.databricks.api.proto.databricks.Databricks.enumValueVisibility);
    registry.add(com.databricks.api.proto.databricks.Databricks.enumValueDoc);
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * <pre>
   * Visibility defines who is allowed to use the RPC.
   * </pre>
   *
   * Protobuf enum {@code mlflow.Visibility}
   */
  public enum Visibility
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * Public indicates visible to both external and internal customers.
     * </pre>
     *
     * <code>PUBLIC = 1;</code>
     */
    PUBLIC(1),
    /**
     * <pre>
     * Internal is only available to Databricks-internal clients.
     * </pre>
     *
     * <code>INTERNAL = 2;</code>
     */
    INTERNAL(2),
    /**
     * <pre>
     * Public-undocumented are accessible via public endpoints, but not documented. This is useful
     * for internal clients that depend on public endpoints (e.g. workflows running in the driver).
     * </pre>
     *
     * <code>PUBLIC_UNDOCUMENTED = 3;</code>
     */
    PUBLIC_UNDOCUMENTED(3),
    ;

    /**
     * <pre>
     * Public indicates visible to both external and internal customers.
     * </pre>
     *
     * <code>PUBLIC = 1;</code>
     */
    public static final int PUBLIC_VALUE = 1;
    /**
     * <pre>
     * Internal is only available to Databricks-internal clients.
     * </pre>
     *
     * <code>INTERNAL = 2;</code>
     */
    public static final int INTERNAL_VALUE = 2;
    /**
     * <pre>
     * Public-undocumented are accessible via public endpoints, but not documented. This is useful
     * for internal clients that depend on public endpoints (e.g. workflows running in the driver).
     * </pre>
     *
     * <code>PUBLIC_UNDOCUMENTED = 3;</code>
     */
    public static final int PUBLIC_UNDOCUMENTED_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static Visibility valueOf(int value) {
      return forNumber(value);
    }

    public static Visibility forNumber(int value) {
      switch (value) {
        case 1: return PUBLIC;
        case 2: return INTERNAL;
        case 3: return PUBLIC_UNDOCUMENTED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<Visibility>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        Visibility> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<Visibility>() {
            public Visibility findValueByNumber(int number) {
              return Visibility.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.getDescriptor().getEnumTypes().get(0);
    }

    private static final Visibility[] VALUES = values();

    public static Visibility valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private Visibility(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:mlflow.Visibility)
  }

  /**
   * Protobuf enum {@code mlflow.ErrorCode}
   */
  public enum ErrorCode
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * Internal, system-level error codes, which generally cannot be resolved by the user, but
     * instead are due to service issues.
     * Generic internal error occurred.
     * </pre>
     *
     * <code>INTERNAL_ERROR = 1;</code>
     */
    INTERNAL_ERROR(1),
    /**
     * <pre>
     * An internal system could not be contacted due to a period of unavailability.
     * </pre>
     *
     * <code>TEMPORARILY_UNAVAILABLE = 2;</code>
     */
    TEMPORARILY_UNAVAILABLE(2),
    /**
     * <pre>
     * Indicates that an IOException has been internally thrown.
     * </pre>
     *
     * <code>IO_ERROR = 3;</code>
     */
    IO_ERROR(3),
    /**
     * <pre>
     * The request is invalid.
     * </pre>
     *
     * <code>BAD_REQUEST = 4;</code>
     */
    BAD_REQUEST(4),
    /**
     * <pre>
     * Common application-level error codes, which were caused by the user input but may be returned
     * by multiple services.
     * Supplied value for a parameter was invalid (e.g., giving a number for a string parameter).
     * </pre>
     *
     * <code>INVALID_PARAMETER_VALUE = 1000;</code>
     */
    INVALID_PARAMETER_VALUE(1000),
    /**
     * <pre>
     * Indicates that the given API endpoint does not exist.
     * </pre>
     *
     * <code>ENDPOINT_NOT_FOUND = 1001;</code>
     */
    ENDPOINT_NOT_FOUND(1001),
    /**
     * <pre>
     * Indicates that the given API request was malformed.
     * </pre>
     *
     * <code>MALFORMED_REQUEST = 1002;</code>
     */
    MALFORMED_REQUEST(1002),
    /**
     * <pre>
     * If one or more of the inputs to a given RPC are not in a valid state for the action.
     * </pre>
     *
     * <code>INVALID_STATE = 1003;</code>
     */
    INVALID_STATE(1003),
    /**
     * <pre>
     * If a given user/entity doesn't have the required permission(s) to perform an action
     * </pre>
     *
     * <code>PERMISSION_DENIED = 1004;</code>
     */
    PERMISSION_DENIED(1004),
    /**
     * <pre>
     * If a given user/entity is trying to use a feature which has been disabled
     * </pre>
     *
     * <code>FEATURE_DISABLED = 1005;</code>
     */
    FEATURE_DISABLED(1005),
    /**
     * <pre>
     * If customer-provided credentials are not authorized to perform an operation
     * </pre>
     *
     * <code>CUSTOMER_UNAUTHORIZED = 1006;</code>
     */
    CUSTOMER_UNAUTHORIZED(1006),
    /**
     * <pre>
     * If the API request is rejected due to throttling
     * </pre>
     *
     * <code>REQUEST_LIMIT_EXCEEDED = 1007;</code>
     */
    REQUEST_LIMIT_EXCEEDED(1007),
    /**
     * <pre>
     * If the user attempts to perform an invalid state transition on a shard.
     * </pre>
     *
     * <code>INVALID_STATE_TRANSITION = 2001;</code>
     */
    INVALID_STATE_TRANSITION(2001),
    /**
     * <pre>
     * Unable to perform the operation because the shard was locked by some other operation.
     * </pre>
     *
     * <code>COULD_NOT_ACQUIRE_LOCK = 2002;</code>
     */
    COULD_NOT_ACQUIRE_LOCK(2002),
    /**
     * <pre>
     * Operation was performed on a resource that already exists.
     * </pre>
     *
     * <code>RESOURCE_ALREADY_EXISTS = 3001;</code>
     */
    RESOURCE_ALREADY_EXISTS(3001),
    /**
     * <pre>
     * Operation was performed on a resource that does not exist.
     * </pre>
     *
     * <code>RESOURCE_DOES_NOT_EXIST = 3002;</code>
     */
    RESOURCE_DOES_NOT_EXIST(3002),
    /**
     * <code>QUOTA_EXCEEDED = 4001;</code>
     */
    QUOTA_EXCEEDED(4001),
    /**
     * <code>MAX_BLOCK_SIZE_EXCEEDED = 4002;</code>
     */
    MAX_BLOCK_SIZE_EXCEEDED(4002),
    /**
     * <code>MAX_READ_SIZE_EXCEEDED = 4003;</code>
     */
    MAX_READ_SIZE_EXCEEDED(4003),
    /**
     * <code>DRY_RUN_FAILED = 5001;</code>
     */
    DRY_RUN_FAILED(5001),
    /**
     * <pre>
     * Cluster request was rejected because it would exceed a resource limit.
     * </pre>
     *
     * <code>RESOURCE_LIMIT_EXCEEDED = 5002;</code>
     */
    RESOURCE_LIMIT_EXCEEDED(5002),
    /**
     * <code>DIRECTORY_NOT_EMPTY = 6001;</code>
     */
    DIRECTORY_NOT_EMPTY(6001),
    /**
     * <code>DIRECTORY_PROTECTED = 6002;</code>
     */
    DIRECTORY_PROTECTED(6002),
    /**
     * <code>MAX_NOTEBOOK_SIZE_EXCEEDED = 6003;</code>
     */
    MAX_NOTEBOOK_SIZE_EXCEEDED(6003),
    ;

    /**
     * <pre>
     * Internal, system-level error codes, which generally cannot be resolved by the user, but
     * instead are due to service issues.
     * Generic internal error occurred.
     * </pre>
     *
     * <code>INTERNAL_ERROR = 1;</code>
     */
    public static final int INTERNAL_ERROR_VALUE = 1;
    /**
     * <pre>
     * An internal system could not be contacted due to a period of unavailability.
     * </pre>
     *
     * <code>TEMPORARILY_UNAVAILABLE = 2;</code>
     */
    public static final int TEMPORARILY_UNAVAILABLE_VALUE = 2;
    /**
     * <pre>
     * Indicates that an IOException has been internally thrown.
     * </pre>
     *
     * <code>IO_ERROR = 3;</code>
     */
    public static final int IO_ERROR_VALUE = 3;
    /**
     * <pre>
     * The request is invalid.
     * </pre>
     *
     * <code>BAD_REQUEST = 4;</code>
     */
    public static final int BAD_REQUEST_VALUE = 4;
    /**
     * <pre>
     * Common application-level error codes, which were caused by the user input but may be returned
     * by multiple services.
     * Supplied value for a parameter was invalid (e.g., giving a number for a string parameter).
     * </pre>
     *
     * <code>INVALID_PARAMETER_VALUE = 1000;</code>
     */
    public static final int INVALID_PARAMETER_VALUE_VALUE = 1000;
    /**
     * <pre>
     * Indicates that the given API endpoint does not exist.
     * </pre>
     *
     * <code>ENDPOINT_NOT_FOUND = 1001;</code>
     */
    public static final int ENDPOINT_NOT_FOUND_VALUE = 1001;
    /**
     * <pre>
     * Indicates that the given API request was malformed.
     * </pre>
     *
     * <code>MALFORMED_REQUEST = 1002;</code>
     */
    public static final int MALFORMED_REQUEST_VALUE = 1002;
    /**
     * <pre>
     * If one or more of the inputs to a given RPC are not in a valid state for the action.
     * </pre>
     *
     * <code>INVALID_STATE = 1003;</code>
     */
    public static final int INVALID_STATE_VALUE = 1003;
    /**
     * <pre>
     * If a given user/entity doesn't have the required permission(s) to perform an action
     * </pre>
     *
     * <code>PERMISSION_DENIED = 1004;</code>
     */
    public static final int PERMISSION_DENIED_VALUE = 1004;
    /**
     * <pre>
     * If a given user/entity is trying to use a feature which has been disabled
     * </pre>
     *
     * <code>FEATURE_DISABLED = 1005;</code>
     */
    public static final int FEATURE_DISABLED_VALUE = 1005;
    /**
     * <pre>
     * If customer-provided credentials are not authorized to perform an operation
     * </pre>
     *
     * <code>CUSTOMER_UNAUTHORIZED = 1006;</code>
     */
    public static final int CUSTOMER_UNAUTHORIZED_VALUE = 1006;
    /**
     * <pre>
     * If the API request is rejected due to throttling
     * </pre>
     *
     * <code>REQUEST_LIMIT_EXCEEDED = 1007;</code>
     */
    public static final int REQUEST_LIMIT_EXCEEDED_VALUE = 1007;
    /**
     * <pre>
     * If the user attempts to perform an invalid state transition on a shard.
     * </pre>
     *
     * <code>INVALID_STATE_TRANSITION = 2001;</code>
     */
    public static final int INVALID_STATE_TRANSITION_VALUE = 2001;
    /**
     * <pre>
     * Unable to perform the operation because the shard was locked by some other operation.
     * </pre>
     *
     * <code>COULD_NOT_ACQUIRE_LOCK = 2002;</code>
     */
    public static final int COULD_NOT_ACQUIRE_LOCK_VALUE = 2002;
    /**
     * <pre>
     * Operation was performed on a resource that already exists.
     * </pre>
     *
     * <code>RESOURCE_ALREADY_EXISTS = 3001;</code>
     */
    public static final int RESOURCE_ALREADY_EXISTS_VALUE = 3001;
    /**
     * <pre>
     * Operation was performed on a resource that does not exist.
     * </pre>
     *
     * <code>RESOURCE_DOES_NOT_EXIST = 3002;</code>
     */
    public static final int RESOURCE_DOES_NOT_EXIST_VALUE = 3002;
    /**
     * <code>QUOTA_EXCEEDED = 4001;</code>
     */
    public static final int QUOTA_EXCEEDED_VALUE = 4001;
    /**
     * <code>MAX_BLOCK_SIZE_EXCEEDED = 4002;</code>
     */
    public static final int MAX_BLOCK_SIZE_EXCEEDED_VALUE = 4002;
    /**
     * <code>MAX_READ_SIZE_EXCEEDED = 4003;</code>
     */
    public static final int MAX_READ_SIZE_EXCEEDED_VALUE = 4003;
    /**
     * <code>DRY_RUN_FAILED = 5001;</code>
     */
    public static final int DRY_RUN_FAILED_VALUE = 5001;
    /**
     * <pre>
     * Cluster request was rejected because it would exceed a resource limit.
     * </pre>
     *
     * <code>RESOURCE_LIMIT_EXCEEDED = 5002;</code>
     */
    public static final int RESOURCE_LIMIT_EXCEEDED_VALUE = 5002;
    /**
     * <code>DIRECTORY_NOT_EMPTY = 6001;</code>
     */
    public static final int DIRECTORY_NOT_EMPTY_VALUE = 6001;
    /**
     * <code>DIRECTORY_PROTECTED = 6002;</code>
     */
    public static final int DIRECTORY_PROTECTED_VALUE = 6002;
    /**
     * <code>MAX_NOTEBOOK_SIZE_EXCEEDED = 6003;</code>
     */
    public static final int MAX_NOTEBOOK_SIZE_EXCEEDED_VALUE = 6003;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ErrorCode valueOf(int value) {
      return forNumber(value);
    }

    public static ErrorCode forNumber(int value) {
      switch (value) {
        case 1: return INTERNAL_ERROR;
        case 2: return TEMPORARILY_UNAVAILABLE;
        case 3: return IO_ERROR;
        case 4: return BAD_REQUEST;
        case 1000: return INVALID_PARAMETER_VALUE;
        case 1001: return ENDPOINT_NOT_FOUND;
        case 1002: return MALFORMED_REQUEST;
        case 1003: return INVALID_STATE;
        case 1004: return PERMISSION_DENIED;
        case 1005: return FEATURE_DISABLED;
        case 1006: return CUSTOMER_UNAUTHORIZED;
        case 1007: return REQUEST_LIMIT_EXCEEDED;
        case 2001: return INVALID_STATE_TRANSITION;
        case 2002: return COULD_NOT_ACQUIRE_LOCK;
        case 3001: return RESOURCE_ALREADY_EXISTS;
        case 3002: return RESOURCE_DOES_NOT_EXIST;
        case 4001: return QUOTA_EXCEEDED;
        case 4002: return MAX_BLOCK_SIZE_EXCEEDED;
        case 4003: return MAX_READ_SIZE_EXCEEDED;
        case 5001: return DRY_RUN_FAILED;
        case 5002: return RESOURCE_LIMIT_EXCEEDED;
        case 6001: return DIRECTORY_NOT_EMPTY;
        case 6002: return DIRECTORY_PROTECTED;
        case 6003: return MAX_NOTEBOOK_SIZE_EXCEEDED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ErrorCode>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ErrorCode> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ErrorCode>() {
            public ErrorCode findValueByNumber(int number) {
              return ErrorCode.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.getDescriptor().getEnumTypes().get(1);
    }

    private static final ErrorCode[] VALUES = values();

    public static ErrorCode valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ErrorCode(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:mlflow.ErrorCode)
  }

  public interface DatabricksRpcOptionsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.DatabricksRpcOptions)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> 
        getEndpointsList();
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    com.databricks.api.proto.databricks.Databricks.HttpEndpoint getEndpoints(int index);
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    int getEndpointsCount();
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    java.util.List<? extends com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> 
        getEndpointsOrBuilderList();
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder getEndpointsOrBuilder(
        int index);

    /**
     * <pre>
     * Indicates which users are allowed to initiate this RPC.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 2;</code>
     */
    boolean hasVisibility();
    /**
     * <pre>
     * Indicates which users are allowed to initiate this RPC.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 2;</code>
     */
    com.databricks.api.proto.databricks.Databricks.Visibility getVisibility();

    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     */
    java.util.List<com.databricks.api.proto.databricks.Databricks.ErrorCode> getErrorCodesList();
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     */
    int getErrorCodesCount();
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     */
    com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCodes(int index);

    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     */
    boolean hasRateLimit();
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     */
    com.databricks.api.proto.databricks.Databricks.RateLimit getRateLimit();
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     */
    com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder getRateLimitOrBuilder();

    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     */
    boolean hasRpcDocTitle();
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     */
    java.lang.String getRpcDocTitle();
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     */
    com.google.protobuf.ByteString
        getRpcDocTitleBytes();
  }
  /**
   * <pre>
   * Defines the set of options declared for every service RPC which are used to
   * direct RPCs to endpoints, as well as other metadata about the RPC.
   * </pre>
   *
   * Protobuf type {@code mlflow.DatabricksRpcOptions}
   */
  public  static final class DatabricksRpcOptions extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.DatabricksRpcOptions)
      DatabricksRpcOptionsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DatabricksRpcOptions.newBuilder() to construct.
    private DatabricksRpcOptions(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DatabricksRpcOptions() {
      endpoints_ = java.util.Collections.emptyList();
      visibility_ = 1;
      errorCodes_ = java.util.Collections.emptyList();
      rpcDocTitle_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DatabricksRpcOptions(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                endpoints_ = new java.util.ArrayList<com.databricks.api.proto.databricks.Databricks.HttpEndpoint>();
                mutable_bitField0_ |= 0x00000001;
              }
              endpoints_.add(
                  input.readMessage(com.databricks.api.proto.databricks.Databricks.HttpEndpoint.PARSER, extensionRegistry));
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              com.databricks.api.proto.databricks.Databricks.Visibility value = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                visibility_ = rawValue;
              }
              break;
            }
            case 24: {
              int rawValue = input.readEnum();
              @SuppressWarnings("deprecation")
              com.databricks.api.proto.databricks.Databricks.ErrorCode value = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(3, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                  errorCodes_ = new java.util.ArrayList<java.lang.Integer>();
                  mutable_bitField0_ |= 0x00000004;
                }
                errorCodes_.add(rawValue);
              }
              break;
            }
            case 26: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
                com.databricks.api.proto.databricks.Databricks.ErrorCode value = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(3, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                    errorCodes_ = new java.util.ArrayList<java.lang.Integer>();
                    mutable_bitField0_ |= 0x00000004;
                  }
                  errorCodes_.add(rawValue);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
            case 34: {
              com.databricks.api.proto.databricks.Databricks.RateLimit.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = rateLimit_.toBuilder();
              }
              rateLimit_ = input.readMessage(com.databricks.api.proto.databricks.Databricks.RateLimit.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(rateLimit_);
                rateLimit_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 42: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              rpcDocTitle_ = bs;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          endpoints_ = java.util.Collections.unmodifiableList(endpoints_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          errorCodes_ = java.util.Collections.unmodifiableList(errorCodes_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.class, com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.Builder.class);
    }

    private int bitField0_;
    public static final int ENDPOINTS_FIELD_NUMBER = 1;
    private java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> endpoints_;
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    public java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> getEndpointsList() {
      return endpoints_;
    }
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    public java.util.List<? extends com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> 
        getEndpointsOrBuilderList() {
      return endpoints_;
    }
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    public int getEndpointsCount() {
      return endpoints_.size();
    }
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.HttpEndpoint getEndpoints(int index) {
      return endpoints_.get(index);
    }
    /**
     * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder getEndpointsOrBuilder(
        int index) {
      return endpoints_.get(index);
    }

    public static final int VISIBILITY_FIELD_NUMBER = 2;
    private int visibility_;
    /**
     * <pre>
     * Indicates which users are allowed to initiate this RPC.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 2;</code>
     */
    public boolean hasVisibility() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <pre>
     * Indicates which users are allowed to initiate this RPC.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 2;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.Visibility getVisibility() {
      @SuppressWarnings("deprecation")
      com.databricks.api.proto.databricks.Databricks.Visibility result = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(visibility_);
      return result == null ? com.databricks.api.proto.databricks.Databricks.Visibility.PUBLIC : result;
    }

    public static final int ERROR_CODES_FIELD_NUMBER = 3;
    private java.util.List<java.lang.Integer> errorCodes_;
    private static final com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, com.databricks.api.proto.databricks.Databricks.ErrorCode> errorCodes_converter_ =
            new com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, com.databricks.api.proto.databricks.Databricks.ErrorCode>() {
              public com.databricks.api.proto.databricks.Databricks.ErrorCode convert(java.lang.Integer from) {
                @SuppressWarnings("deprecation")
                com.databricks.api.proto.databricks.Databricks.ErrorCode result = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(from);
                return result == null ? com.databricks.api.proto.databricks.Databricks.ErrorCode.INTERNAL_ERROR : result;
              }
            };
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     */
    public java.util.List<com.databricks.api.proto.databricks.Databricks.ErrorCode> getErrorCodesList() {
      return new com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, com.databricks.api.proto.databricks.Databricks.ErrorCode>(errorCodes_, errorCodes_converter_);
    }
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     */
    public int getErrorCodesCount() {
      return errorCodes_.size();
    }
    /**
     * <pre>
     * Complete definition of all error codes (from a statically defined set) which this method
     * may return.
     * </pre>
     *
     * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCodes(int index) {
      return errorCodes_converter_.convert(errorCodes_.get(index));
    }

    public static final int RATE_LIMIT_FIELD_NUMBER = 4;
    private com.databricks.api.proto.databricks.Databricks.RateLimit rateLimit_;
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     */
    public boolean hasRateLimit() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.RateLimit getRateLimit() {
      return rateLimit_ == null ? com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance() : rateLimit_;
    }
    /**
     * <pre>
     * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
     * </pre>
     *
     * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder getRateLimitOrBuilder() {
      return rateLimit_ == null ? com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance() : rateLimit_;
    }

    public static final int RPC_DOC_TITLE_FIELD_NUMBER = 5;
    private volatile java.lang.Object rpcDocTitle_;
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     */
    public boolean hasRpcDocTitle() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     */
    public java.lang.String getRpcDocTitle() {
      java.lang.Object ref = rpcDocTitle_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          rpcDocTitle_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
     * for more info.
     * </pre>
     *
     * <code>optional string rpc_doc_title = 5;</code>
     */
    public com.google.protobuf.ByteString
        getRpcDocTitleBytes() {
      java.lang.Object ref = rpcDocTitle_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        rpcDocTitle_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < endpoints_.size(); i++) {
        output.writeMessage(1, endpoints_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(2, visibility_);
      }
      for (int i = 0; i < errorCodes_.size(); i++) {
        output.writeEnum(3, errorCodes_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(4, getRateLimit());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, rpcDocTitle_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < endpoints_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, endpoints_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, visibility_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < errorCodes_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(errorCodes_.get(i));
        }
        size += dataSize;
        size += 1 * errorCodes_.size();
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getRateLimit());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, rpcDocTitle_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions other = (com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions) obj;

      boolean result = true;
      result = result && getEndpointsList()
          .equals(other.getEndpointsList());
      result = result && (hasVisibility() == other.hasVisibility());
      if (hasVisibility()) {
        result = result && visibility_ == other.visibility_;
      }
      result = result && errorCodes_.equals(other.errorCodes_);
      result = result && (hasRateLimit() == other.hasRateLimit());
      if (hasRateLimit()) {
        result = result && getRateLimit()
            .equals(other.getRateLimit());
      }
      result = result && (hasRpcDocTitle() == other.hasRpcDocTitle());
      if (hasRpcDocTitle()) {
        result = result && getRpcDocTitle()
            .equals(other.getRpcDocTitle());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getEndpointsCount() > 0) {
        hash = (37 * hash) + ENDPOINTS_FIELD_NUMBER;
        hash = (53 * hash) + getEndpointsList().hashCode();
      }
      if (hasVisibility()) {
        hash = (37 * hash) + VISIBILITY_FIELD_NUMBER;
        hash = (53 * hash) + visibility_;
      }
      if (getErrorCodesCount() > 0) {
        hash = (37 * hash) + ERROR_CODES_FIELD_NUMBER;
        hash = (53 * hash) + errorCodes_.hashCode();
      }
      if (hasRateLimit()) {
        hash = (37 * hash) + RATE_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getRateLimit().hashCode();
      }
      if (hasRpcDocTitle()) {
        hash = (37 * hash) + RPC_DOC_TITLE_FIELD_NUMBER;
        hash = (53 * hash) + getRpcDocTitle().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Defines the set of options declared for every service RPC which are used to
     * direct RPCs to endpoints, as well as other metadata about the RPC.
     * </pre>
     *
     * Protobuf type {@code mlflow.DatabricksRpcOptions}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.DatabricksRpcOptions)
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptionsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.class, com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getEndpointsFieldBuilder();
          getRateLimitFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (endpointsBuilder_ == null) {
          endpoints_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          endpointsBuilder_.clear();
        }
        visibility_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        errorCodes_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000004);
        if (rateLimitBuilder_ == null) {
          rateLimit_ = null;
        } else {
          rateLimitBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        rpcDocTitle_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksRpcOptions_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions build() {
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions buildPartial() {
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions result = new com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (endpointsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            endpoints_ = java.util.Collections.unmodifiableList(endpoints_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.endpoints_ = endpoints_;
        } else {
          result.endpoints_ = endpointsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.visibility_ = visibility_;
        if (((bitField0_ & 0x00000004) == 0x00000004)) {
          errorCodes_ = java.util.Collections.unmodifiableList(errorCodes_);
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.errorCodes_ = errorCodes_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000002;
        }
        if (rateLimitBuilder_ == null) {
          result.rateLimit_ = rateLimit_;
        } else {
          result.rateLimit_ = rateLimitBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rpcDocTitle_ = rpcDocTitle_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions other) {
        if (other == com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.getDefaultInstance()) return this;
        if (endpointsBuilder_ == null) {
          if (!other.endpoints_.isEmpty()) {
            if (endpoints_.isEmpty()) {
              endpoints_ = other.endpoints_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureEndpointsIsMutable();
              endpoints_.addAll(other.endpoints_);
            }
            onChanged();
          }
        } else {
          if (!other.endpoints_.isEmpty()) {
            if (endpointsBuilder_.isEmpty()) {
              endpointsBuilder_.dispose();
              endpointsBuilder_ = null;
              endpoints_ = other.endpoints_;
              bitField0_ = (bitField0_ & ~0x00000001);
              endpointsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getEndpointsFieldBuilder() : null;
            } else {
              endpointsBuilder_.addAllMessages(other.endpoints_);
            }
          }
        }
        if (other.hasVisibility()) {
          setVisibility(other.getVisibility());
        }
        if (!other.errorCodes_.isEmpty()) {
          if (errorCodes_.isEmpty()) {
            errorCodes_ = other.errorCodes_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensureErrorCodesIsMutable();
            errorCodes_.addAll(other.errorCodes_);
          }
          onChanged();
        }
        if (other.hasRateLimit()) {
          mergeRateLimit(other.getRateLimit());
        }
        if (other.hasRpcDocTitle()) {
          bitField0_ |= 0x00000010;
          rpcDocTitle_ = other.rpcDocTitle_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> endpoints_ =
        java.util.Collections.emptyList();
      private void ensureEndpointsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          endpoints_ = new java.util.ArrayList<com.databricks.api.proto.databricks.Databricks.HttpEndpoint>(endpoints_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.HttpEndpoint, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder, com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> endpointsBuilder_;

      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint> getEndpointsList() {
        if (endpointsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(endpoints_);
        } else {
          return endpointsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public int getEndpointsCount() {
        if (endpointsBuilder_ == null) {
          return endpoints_.size();
        } else {
          return endpointsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint getEndpoints(int index) {
        if (endpointsBuilder_ == null) {
          return endpoints_.get(index);
        } else {
          return endpointsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder setEndpoints(
          int index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint value) {
        if (endpointsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEndpointsIsMutable();
          endpoints_.set(index, value);
          onChanged();
        } else {
          endpointsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder setEndpoints(
          int index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder builderForValue) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          endpoints_.set(index, builderForValue.build());
          onChanged();
        } else {
          endpointsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addEndpoints(com.databricks.api.proto.databricks.Databricks.HttpEndpoint value) {
        if (endpointsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEndpointsIsMutable();
          endpoints_.add(value);
          onChanged();
        } else {
          endpointsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addEndpoints(
          int index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint value) {
        if (endpointsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEndpointsIsMutable();
          endpoints_.add(index, value);
          onChanged();
        } else {
          endpointsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addEndpoints(
          com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder builderForValue) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          endpoints_.add(builderForValue.build());
          onChanged();
        } else {
          endpointsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addEndpoints(
          int index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder builderForValue) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          endpoints_.add(index, builderForValue.build());
          onChanged();
        } else {
          endpointsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder addAllEndpoints(
          java.lang.Iterable<? extends com.databricks.api.proto.databricks.Databricks.HttpEndpoint> values) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, endpoints_);
          onChanged();
        } else {
          endpointsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder clearEndpoints() {
        if (endpointsBuilder_ == null) {
          endpoints_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          endpointsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public Builder removeEndpoints(int index) {
        if (endpointsBuilder_ == null) {
          ensureEndpointsIsMutable();
          endpoints_.remove(index);
          onChanged();
        } else {
          endpointsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder getEndpointsBuilder(
          int index) {
        return getEndpointsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder getEndpointsOrBuilder(
          int index) {
        if (endpointsBuilder_ == null) {
          return endpoints_.get(index);  } else {
          return endpointsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public java.util.List<? extends com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> 
           getEndpointsOrBuilderList() {
        if (endpointsBuilder_ != null) {
          return endpointsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(endpoints_);
        }
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder addEndpointsBuilder() {
        return getEndpointsFieldBuilder().addBuilder(
            com.databricks.api.proto.databricks.Databricks.HttpEndpoint.getDefaultInstance());
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder addEndpointsBuilder(
          int index) {
        return getEndpointsFieldBuilder().addBuilder(
            index, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.getDefaultInstance());
      }
      /**
       * <code>repeated .mlflow.HttpEndpoint endpoints = 1;</code>
       */
      public java.util.List<com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder> 
           getEndpointsBuilderList() {
        return getEndpointsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.HttpEndpoint, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder, com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder> 
          getEndpointsFieldBuilder() {
        if (endpointsBuilder_ == null) {
          endpointsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              com.databricks.api.proto.databricks.Databricks.HttpEndpoint, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder, com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder>(
                  endpoints_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          endpoints_ = null;
        }
        return endpointsBuilder_;
      }

      private int visibility_ = 1;
      /**
       * <pre>
       * Indicates which users are allowed to initiate this RPC.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 2;</code>
       */
      public boolean hasVisibility() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <pre>
       * Indicates which users are allowed to initiate this RPC.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 2;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.Visibility getVisibility() {
        @SuppressWarnings("deprecation")
        com.databricks.api.proto.databricks.Databricks.Visibility result = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(visibility_);
        return result == null ? com.databricks.api.proto.databricks.Databricks.Visibility.PUBLIC : result;
      }
      /**
       * <pre>
       * Indicates which users are allowed to initiate this RPC.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 2;</code>
       */
      public Builder setVisibility(com.databricks.api.proto.databricks.Databricks.Visibility value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        visibility_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Indicates which users are allowed to initiate this RPC.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 2;</code>
       */
      public Builder clearVisibility() {
        bitField0_ = (bitField0_ & ~0x00000002);
        visibility_ = 1;
        onChanged();
        return this;
      }

      private java.util.List<java.lang.Integer> errorCodes_ =
        java.util.Collections.emptyList();
      private void ensureErrorCodesIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          errorCodes_ = new java.util.ArrayList<java.lang.Integer>(errorCodes_);
          bitField0_ |= 0x00000004;
        }
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       */
      public java.util.List<com.databricks.api.proto.databricks.Databricks.ErrorCode> getErrorCodesList() {
        return new com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, com.databricks.api.proto.databricks.Databricks.ErrorCode>(errorCodes_, errorCodes_converter_);
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       */
      public int getErrorCodesCount() {
        return errorCodes_.size();
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCodes(int index) {
        return errorCodes_converter_.convert(errorCodes_.get(index));
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       */
      public Builder setErrorCodes(
          int index, com.databricks.api.proto.databricks.Databricks.ErrorCode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureErrorCodesIsMutable();
        errorCodes_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       */
      public Builder addErrorCodes(com.databricks.api.proto.databricks.Databricks.ErrorCode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureErrorCodesIsMutable();
        errorCodes_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       */
      public Builder addAllErrorCodes(
          java.lang.Iterable<? extends com.databricks.api.proto.databricks.Databricks.ErrorCode> values) {
        ensureErrorCodesIsMutable();
        for (com.databricks.api.proto.databricks.Databricks.ErrorCode value : values) {
          errorCodes_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Complete definition of all error codes (from a statically defined set) which this method
       * may return.
       * </pre>
       *
       * <code>repeated .mlflow.ErrorCode error_codes = 3;</code>
       */
      public Builder clearErrorCodes() {
        errorCodes_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }

      private com.databricks.api.proto.databricks.Databricks.RateLimit rateLimit_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.RateLimit, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder, com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder> rateLimitBuilder_;
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public boolean hasRateLimit() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.RateLimit getRateLimit() {
        if (rateLimitBuilder_ == null) {
          return rateLimit_ == null ? com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance() : rateLimit_;
        } else {
          return rateLimitBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public Builder setRateLimit(com.databricks.api.proto.databricks.Databricks.RateLimit value) {
        if (rateLimitBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          rateLimit_ = value;
          onChanged();
        } else {
          rateLimitBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public Builder setRateLimit(
          com.databricks.api.proto.databricks.Databricks.RateLimit.Builder builderForValue) {
        if (rateLimitBuilder_ == null) {
          rateLimit_ = builderForValue.build();
          onChanged();
        } else {
          rateLimitBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public Builder mergeRateLimit(com.databricks.api.proto.databricks.Databricks.RateLimit value) {
        if (rateLimitBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              rateLimit_ != null &&
              rateLimit_ != com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance()) {
            rateLimit_ =
              com.databricks.api.proto.databricks.Databricks.RateLimit.newBuilder(rateLimit_).mergeFrom(value).buildPartial();
          } else {
            rateLimit_ = value;
          }
          onChanged();
        } else {
          rateLimitBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public Builder clearRateLimit() {
        if (rateLimitBuilder_ == null) {
          rateLimit_ = null;
          onChanged();
        } else {
          rateLimitBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.RateLimit.Builder getRateLimitBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getRateLimitFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder getRateLimitOrBuilder() {
        if (rateLimitBuilder_ != null) {
          return rateLimitBuilder_.getMessageOrBuilder();
        } else {
          return rateLimit_ == null ?
              com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance() : rateLimit_;
        }
      }
      /**
       * <pre>
       * If defined, a rate limit will be applied to this RPC for all requests from the API proxy.
       * </pre>
       *
       * <code>optional .mlflow.RateLimit rate_limit = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.RateLimit, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder, com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder> 
          getRateLimitFieldBuilder() {
        if (rateLimitBuilder_ == null) {
          rateLimitBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.databricks.api.proto.databricks.Databricks.RateLimit, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder, com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder>(
                  getRateLimit(),
                  getParentForChildren(),
                  isClean());
          rateLimit_ = null;
        }
        return rateLimitBuilder_;
      }

      private java.lang.Object rpcDocTitle_ = "";
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       */
      public boolean hasRpcDocTitle() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       */
      public java.lang.String getRpcDocTitle() {
        java.lang.Object ref = rpcDocTitle_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            rpcDocTitle_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       */
      public com.google.protobuf.ByteString
          getRpcDocTitleBytes() {
        java.lang.Object ref = rpcDocTitle_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          rpcDocTitle_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       */
      public Builder setRpcDocTitle(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        rpcDocTitle_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       */
      public Builder clearRpcDocTitle() {
        bitField0_ = (bitField0_ & ~0x00000010);
        rpcDocTitle_ = getDefaultInstance().getRpcDocTitle();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If defined, overrides the default title used for in the API docs. See ProtobufDocGenerator
       * for more info.
       * </pre>
       *
       * <code>optional string rpc_doc_title = 5;</code>
       */
      public Builder setRpcDocTitleBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        rpcDocTitle_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.DatabricksRpcOptions)
    }

    // @@protoc_insertion_point(class_scope:mlflow.DatabricksRpcOptions)
    private static final com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions();
    }

    public static com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DatabricksRpcOptions>
        PARSER = new com.google.protobuf.AbstractParser<DatabricksRpcOptions>() {
      @java.lang.Override
      public DatabricksRpcOptions parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DatabricksRpcOptions(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DatabricksRpcOptions> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DatabricksRpcOptions> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface HttpEndpointOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.HttpEndpoint)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     */
    boolean hasMethod();
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     */
    java.lang.String getMethod();
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     */
    com.google.protobuf.ByteString
        getMethodBytes();

    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     */
    boolean hasPath();
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     */
    java.lang.String getPath();
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     */
    com.google.protobuf.ByteString
        getPathBytes();

    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     */
    boolean hasSince();
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     */
    com.databricks.api.proto.databricks.Databricks.ApiVersion getSince();
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     */
    com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder getSinceOrBuilder();
  }
  /**
   * Protobuf type {@code mlflow.HttpEndpoint}
   */
  public  static final class HttpEndpoint extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.HttpEndpoint)
      HttpEndpointOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use HttpEndpoint.newBuilder() to construct.
    private HttpEndpoint(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private HttpEndpoint() {
      method_ = "POST";
      path_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private HttpEndpoint(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              method_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              path_ = bs;
              break;
            }
            case 26: {
              com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = since_.toBuilder();
              }
              since_ = input.readMessage(com.databricks.api.proto.databricks.Databricks.ApiVersion.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(since_);
                since_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.HttpEndpoint.class, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder.class);
    }

    private int bitField0_;
    public static final int METHOD_FIELD_NUMBER = 1;
    private volatile java.lang.Object method_;
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     */
    public boolean hasMethod() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     */
    public java.lang.String getMethod() {
      java.lang.Object ref = method_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          method_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * HTTP method like POST or GET.
     * </pre>
     *
     * <code>optional string method = 1 [default = "POST"];</code>
     */
    public com.google.protobuf.ByteString
        getMethodBytes() {
      java.lang.Object ref = method_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        method_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PATH_FIELD_NUMBER = 2;
    private volatile java.lang.Object path_;
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     */
    public boolean hasPath() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     */
    public java.lang.String getPath() {
      java.lang.Object ref = path_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          path_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
     * </pre>
     *
     * <code>optional string path = 2;</code>
     */
    public com.google.protobuf.ByteString
        getPathBytes() {
      java.lang.Object ref = path_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        path_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SINCE_FIELD_NUMBER = 3;
    private com.databricks.api.proto.databricks.Databricks.ApiVersion since_;
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     */
    public boolean hasSince() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.ApiVersion getSince() {
      return since_ == null ? com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance() : since_;
    }
    /**
     * <pre>
     * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
     * Breaking changes to an RPC must use a different version number.
     * </pre>
     *
     * <code>optional .mlflow.ApiVersion since = 3;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder getSinceOrBuilder() {
      return since_ == null ? com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance() : since_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, method_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, path_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getSince());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, method_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, path_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getSince());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.HttpEndpoint)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.HttpEndpoint other = (com.databricks.api.proto.databricks.Databricks.HttpEndpoint) obj;

      boolean result = true;
      result = result && (hasMethod() == other.hasMethod());
      if (hasMethod()) {
        result = result && getMethod()
            .equals(other.getMethod());
      }
      result = result && (hasPath() == other.hasPath());
      if (hasPath()) {
        result = result && getPath()
            .equals(other.getPath());
      }
      result = result && (hasSince() == other.hasSince());
      if (hasSince()) {
        result = result && getSince()
            .equals(other.getSince());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMethod()) {
        hash = (37 * hash) + METHOD_FIELD_NUMBER;
        hash = (53 * hash) + getMethod().hashCode();
      }
      if (hasPath()) {
        hash = (37 * hash) + PATH_FIELD_NUMBER;
        hash = (53 * hash) + getPath().hashCode();
      }
      if (hasSince()) {
        hash = (37 * hash) + SINCE_FIELD_NUMBER;
        hash = (53 * hash) + getSince().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.HttpEndpoint prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code mlflow.HttpEndpoint}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.HttpEndpoint)
        com.databricks.api.proto.databricks.Databricks.HttpEndpointOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.HttpEndpoint.class, com.databricks.api.proto.databricks.Databricks.HttpEndpoint.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.HttpEndpoint.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getSinceFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        method_ = "POST";
        bitField0_ = (bitField0_ & ~0x00000001);
        path_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        if (sinceBuilder_ == null) {
          since_ = null;
        } else {
          sinceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_HttpEndpoint_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.HttpEndpoint.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint build() {
        com.databricks.api.proto.databricks.Databricks.HttpEndpoint result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.HttpEndpoint buildPartial() {
        com.databricks.api.proto.databricks.Databricks.HttpEndpoint result = new com.databricks.api.proto.databricks.Databricks.HttpEndpoint(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.method_ = method_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.path_ = path_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (sinceBuilder_ == null) {
          result.since_ = since_;
        } else {
          result.since_ = sinceBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.HttpEndpoint) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.HttpEndpoint)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.HttpEndpoint other) {
        if (other == com.databricks.api.proto.databricks.Databricks.HttpEndpoint.getDefaultInstance()) return this;
        if (other.hasMethod()) {
          bitField0_ |= 0x00000001;
          method_ = other.method_;
          onChanged();
        }
        if (other.hasPath()) {
          bitField0_ |= 0x00000002;
          path_ = other.path_;
          onChanged();
        }
        if (other.hasSince()) {
          mergeSince(other.getSince());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.HttpEndpoint parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.HttpEndpoint) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object method_ = "POST";
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       */
      public boolean hasMethod() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       */
      public java.lang.String getMethod() {
        java.lang.Object ref = method_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            method_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       */
      public com.google.protobuf.ByteString
          getMethodBytes() {
        java.lang.Object ref = method_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          method_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       */
      public Builder setMethod(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        method_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       */
      public Builder clearMethod() {
        bitField0_ = (bitField0_ & ~0x00000001);
        method_ = getDefaultInstance().getMethod();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * HTTP method like POST or GET.
       * </pre>
       *
       * <code>optional string method = 1 [default = "POST"];</code>
       */
      public Builder setMethodBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        method_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object path_ = "";
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       */
      public boolean hasPath() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       */
      public java.lang.String getPath() {
        java.lang.Object ref = path_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            path_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       */
      public com.google.protobuf.ByteString
          getPathBytes() {
        java.lang.Object ref = path_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          path_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       */
      public Builder setPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        path_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       */
      public Builder clearPath() {
        bitField0_ = (bitField0_ & ~0x00000002);
        path_ = getDefaultInstance().getPath();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Conceptual path of the API, like "/clusters" or "/clusters/create". Should start with a slash.
       * </pre>
       *
       * <code>optional string path = 2;</code>
       */
      public Builder setPathBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        path_ = value;
        onChanged();
        return this;
      }

      private com.databricks.api.proto.databricks.Databricks.ApiVersion since_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.ApiVersion, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder, com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder> sinceBuilder_;
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public boolean hasSince() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.ApiVersion getSince() {
        if (sinceBuilder_ == null) {
          return since_ == null ? com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance() : since_;
        } else {
          return sinceBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public Builder setSince(com.databricks.api.proto.databricks.Databricks.ApiVersion value) {
        if (sinceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          since_ = value;
          onChanged();
        } else {
          sinceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public Builder setSince(
          com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder builderForValue) {
        if (sinceBuilder_ == null) {
          since_ = builderForValue.build();
          onChanged();
        } else {
          sinceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public Builder mergeSince(com.databricks.api.proto.databricks.Databricks.ApiVersion value) {
        if (sinceBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              since_ != null &&
              since_ != com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance()) {
            since_ =
              com.databricks.api.proto.databricks.Databricks.ApiVersion.newBuilder(since_).mergeFrom(value).buildPartial();
          } else {
            since_ = value;
          }
          onChanged();
        } else {
          sinceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public Builder clearSince() {
        if (sinceBuilder_ == null) {
          since_ = null;
          onChanged();
        } else {
          sinceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder getSinceBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getSinceFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder getSinceOrBuilder() {
        if (sinceBuilder_ != null) {
          return sinceBuilder_.getMessageOrBuilder();
        } else {
          return since_ == null ?
              com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance() : since_;
        }
      }
      /**
       * <pre>
       * A version like 1.1 which is prepended to the URL (e.g., GET /1.1/clusters).
       * Breaking changes to an RPC must use a different version number.
       * </pre>
       *
       * <code>optional .mlflow.ApiVersion since = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.databricks.api.proto.databricks.Databricks.ApiVersion, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder, com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder> 
          getSinceFieldBuilder() {
        if (sinceBuilder_ == null) {
          sinceBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.databricks.api.proto.databricks.Databricks.ApiVersion, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder, com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder>(
                  getSince(),
                  getParentForChildren(),
                  isClean());
          since_ = null;
        }
        return sinceBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.HttpEndpoint)
    }

    // @@protoc_insertion_point(class_scope:mlflow.HttpEndpoint)
    private static final com.databricks.api.proto.databricks.Databricks.HttpEndpoint DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.HttpEndpoint();
    }

    public static com.databricks.api.proto.databricks.Databricks.HttpEndpoint getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<HttpEndpoint>
        PARSER = new com.google.protobuf.AbstractParser<HttpEndpoint>() {
      @java.lang.Override
      public HttpEndpoint parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new HttpEndpoint(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<HttpEndpoint> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<HttpEndpoint> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.HttpEndpoint getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApiVersionOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.ApiVersion)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 major = 1;</code>
     */
    boolean hasMajor();
    /**
     * <code>optional int32 major = 1;</code>
     */
    int getMajor();

    /**
     * <code>optional int32 minor = 2;</code>
     */
    boolean hasMinor();
    /**
     * <code>optional int32 minor = 2;</code>
     */
    int getMinor();
  }
  /**
   * Protobuf type {@code mlflow.ApiVersion}
   */
  public  static final class ApiVersion extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.ApiVersion)
      ApiVersionOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApiVersion.newBuilder() to construct.
    private ApiVersion(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApiVersion() {
      major_ = 0;
      minor_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApiVersion(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              major_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              minor_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.ApiVersion.class, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder.class);
    }

    private int bitField0_;
    public static final int MAJOR_FIELD_NUMBER = 1;
    private int major_;
    /**
     * <code>optional int32 major = 1;</code>
     */
    public boolean hasMajor() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 major = 1;</code>
     */
    public int getMajor() {
      return major_;
    }

    public static final int MINOR_FIELD_NUMBER = 2;
    private int minor_;
    /**
     * <code>optional int32 minor = 2;</code>
     */
    public boolean hasMinor() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 minor = 2;</code>
     */
    public int getMinor() {
      return minor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, major_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, minor_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, major_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, minor_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.ApiVersion)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.ApiVersion other = (com.databricks.api.proto.databricks.Databricks.ApiVersion) obj;

      boolean result = true;
      result = result && (hasMajor() == other.hasMajor());
      if (hasMajor()) {
        result = result && (getMajor()
            == other.getMajor());
      }
      result = result && (hasMinor() == other.hasMinor());
      if (hasMinor()) {
        result = result && (getMinor()
            == other.getMinor());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMajor()) {
        hash = (37 * hash) + MAJOR_FIELD_NUMBER;
        hash = (53 * hash) + getMajor();
      }
      if (hasMinor()) {
        hash = (37 * hash) + MINOR_FIELD_NUMBER;
        hash = (53 * hash) + getMinor();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.ApiVersion parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.ApiVersion prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code mlflow.ApiVersion}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.ApiVersion)
        com.databricks.api.proto.databricks.Databricks.ApiVersionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.ApiVersion.class, com.databricks.api.proto.databricks.Databricks.ApiVersion.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.ApiVersion.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        major_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        minor_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_ApiVersion_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.ApiVersion getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.ApiVersion build() {
        com.databricks.api.proto.databricks.Databricks.ApiVersion result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.ApiVersion buildPartial() {
        com.databricks.api.proto.databricks.Databricks.ApiVersion result = new com.databricks.api.proto.databricks.Databricks.ApiVersion(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.major_ = major_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.minor_ = minor_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.ApiVersion) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.ApiVersion)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.ApiVersion other) {
        if (other == com.databricks.api.proto.databricks.Databricks.ApiVersion.getDefaultInstance()) return this;
        if (other.hasMajor()) {
          setMajor(other.getMajor());
        }
        if (other.hasMinor()) {
          setMinor(other.getMinor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.ApiVersion parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.ApiVersion) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int major_ ;
      /**
       * <code>optional int32 major = 1;</code>
       */
      public boolean hasMajor() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 major = 1;</code>
       */
      public int getMajor() {
        return major_;
      }
      /**
       * <code>optional int32 major = 1;</code>
       */
      public Builder setMajor(int value) {
        bitField0_ |= 0x00000001;
        major_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 major = 1;</code>
       */
      public Builder clearMajor() {
        bitField0_ = (bitField0_ & ~0x00000001);
        major_ = 0;
        onChanged();
        return this;
      }

      private int minor_ ;
      /**
       * <code>optional int32 minor = 2;</code>
       */
      public boolean hasMinor() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 minor = 2;</code>
       */
      public int getMinor() {
        return minor_;
      }
      /**
       * <code>optional int32 minor = 2;</code>
       */
      public Builder setMinor(int value) {
        bitField0_ |= 0x00000002;
        minor_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 minor = 2;</code>
       */
      public Builder clearMinor() {
        bitField0_ = (bitField0_ & ~0x00000002);
        minor_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.ApiVersion)
    }

    // @@protoc_insertion_point(class_scope:mlflow.ApiVersion)
    private static final com.databricks.api.proto.databricks.Databricks.ApiVersion DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.ApiVersion();
    }

    public static com.databricks.api.proto.databricks.Databricks.ApiVersion getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApiVersion>
        PARSER = new com.google.protobuf.AbstractParser<ApiVersion>() {
      @java.lang.Override
      public ApiVersion parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApiVersion(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApiVersion> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApiVersion> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.ApiVersion getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RateLimitOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.RateLimit)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * The maximum burst of API requests allowed for a single endpoint. In the context of the
     * token bucket algorithm, this constant represents the total capacity of the token bucket.
     * </pre>
     *
     * <code>optional int64 max_burst = 1;</code>
     */
    boolean hasMaxBurst();
    /**
     * <pre>
     * The maximum burst of API requests allowed for a single endpoint. In the context of the
     * token bucket algorithm, this constant represents the total capacity of the token bucket.
     * </pre>
     *
     * <code>optional int64 max_burst = 1;</code>
     */
    long getMaxBurst();

    /**
     * <pre>
     * The maximum sustained request per second limit for a single endpoint. In the context of the,
     * token bucket algorithm, this constant represents the rate at which the token bucket fills.
     * </pre>
     *
     * <code>optional int64 max_sustained_per_second = 2;</code>
     */
    boolean hasMaxSustainedPerSecond();
    /**
     * <pre>
     * The maximum sustained request per second limit for a single endpoint. In the context of the,
     * token bucket algorithm, this constant represents the rate at which the token bucket fills.
     * </pre>
     *
     * <code>optional int64 max_sustained_per_second = 2;</code>
     */
    long getMaxSustainedPerSecond();
  }
  /**
   * <pre>
   * API rate limits applied to RPCs coming from the API Proxy. The rate limits are applied on a
   * per organization basis.
   * </pre>
   *
   * Protobuf type {@code mlflow.RateLimit}
   */
  public  static final class RateLimit extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.RateLimit)
      RateLimitOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RateLimit.newBuilder() to construct.
    private RateLimit(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RateLimit() {
      maxBurst_ = 0L;
      maxSustainedPerSecond_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RateLimit(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              maxBurst_ = input.readInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              maxSustainedPerSecond_ = input.readInt64();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.RateLimit.class, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder.class);
    }

    private int bitField0_;
    public static final int MAX_BURST_FIELD_NUMBER = 1;
    private long maxBurst_;
    /**
     * <pre>
     * The maximum burst of API requests allowed for a single endpoint. In the context of the
     * token bucket algorithm, this constant represents the total capacity of the token bucket.
     * </pre>
     *
     * <code>optional int64 max_burst = 1;</code>
     */
    public boolean hasMaxBurst() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <pre>
     * The maximum burst of API requests allowed for a single endpoint. In the context of the
     * token bucket algorithm, this constant represents the total capacity of the token bucket.
     * </pre>
     *
     * <code>optional int64 max_burst = 1;</code>
     */
    public long getMaxBurst() {
      return maxBurst_;
    }

    public static final int MAX_SUSTAINED_PER_SECOND_FIELD_NUMBER = 2;
    private long maxSustainedPerSecond_;
    /**
     * <pre>
     * The maximum sustained request per second limit for a single endpoint. In the context of the,
     * token bucket algorithm, this constant represents the rate at which the token bucket fills.
     * </pre>
     *
     * <code>optional int64 max_sustained_per_second = 2;</code>
     */
    public boolean hasMaxSustainedPerSecond() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <pre>
     * The maximum sustained request per second limit for a single endpoint. In the context of the,
     * token bucket algorithm, this constant represents the rate at which the token bucket fills.
     * </pre>
     *
     * <code>optional int64 max_sustained_per_second = 2;</code>
     */
    public long getMaxSustainedPerSecond() {
      return maxSustainedPerSecond_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, maxBurst_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, maxSustainedPerSecond_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, maxBurst_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, maxSustainedPerSecond_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.RateLimit)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.RateLimit other = (com.databricks.api.proto.databricks.Databricks.RateLimit) obj;

      boolean result = true;
      result = result && (hasMaxBurst() == other.hasMaxBurst());
      if (hasMaxBurst()) {
        result = result && (getMaxBurst()
            == other.getMaxBurst());
      }
      result = result && (hasMaxSustainedPerSecond() == other.hasMaxSustainedPerSecond());
      if (hasMaxSustainedPerSecond()) {
        result = result && (getMaxSustainedPerSecond()
            == other.getMaxSustainedPerSecond());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMaxBurst()) {
        hash = (37 * hash) + MAX_BURST_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getMaxBurst());
      }
      if (hasMaxSustainedPerSecond()) {
        hash = (37 * hash) + MAX_SUSTAINED_PER_SECOND_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getMaxSustainedPerSecond());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.RateLimit parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.RateLimit prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * API rate limits applied to RPCs coming from the API Proxy. The rate limits are applied on a
     * per organization basis.
     * </pre>
     *
     * Protobuf type {@code mlflow.RateLimit}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.RateLimit)
        com.databricks.api.proto.databricks.Databricks.RateLimitOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.RateLimit.class, com.databricks.api.proto.databricks.Databricks.RateLimit.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.RateLimit.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        maxBurst_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        maxSustainedPerSecond_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_RateLimit_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.RateLimit getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.RateLimit build() {
        com.databricks.api.proto.databricks.Databricks.RateLimit result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.RateLimit buildPartial() {
        com.databricks.api.proto.databricks.Databricks.RateLimit result = new com.databricks.api.proto.databricks.Databricks.RateLimit(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.maxBurst_ = maxBurst_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.maxSustainedPerSecond_ = maxSustainedPerSecond_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.RateLimit) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.RateLimit)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.RateLimit other) {
        if (other == com.databricks.api.proto.databricks.Databricks.RateLimit.getDefaultInstance()) return this;
        if (other.hasMaxBurst()) {
          setMaxBurst(other.getMaxBurst());
        }
        if (other.hasMaxSustainedPerSecond()) {
          setMaxSustainedPerSecond(other.getMaxSustainedPerSecond());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.RateLimit parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.RateLimit) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private long maxBurst_ ;
      /**
       * <pre>
       * The maximum burst of API requests allowed for a single endpoint. In the context of the
       * token bucket algorithm, this constant represents the total capacity of the token bucket.
       * </pre>
       *
       * <code>optional int64 max_burst = 1;</code>
       */
      public boolean hasMaxBurst() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <pre>
       * The maximum burst of API requests allowed for a single endpoint. In the context of the
       * token bucket algorithm, this constant represents the total capacity of the token bucket.
       * </pre>
       *
       * <code>optional int64 max_burst = 1;</code>
       */
      public long getMaxBurst() {
        return maxBurst_;
      }
      /**
       * <pre>
       * The maximum burst of API requests allowed for a single endpoint. In the context of the
       * token bucket algorithm, this constant represents the total capacity of the token bucket.
       * </pre>
       *
       * <code>optional int64 max_burst = 1;</code>
       */
      public Builder setMaxBurst(long value) {
        bitField0_ |= 0x00000001;
        maxBurst_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The maximum burst of API requests allowed for a single endpoint. In the context of the
       * token bucket algorithm, this constant represents the total capacity of the token bucket.
       * </pre>
       *
       * <code>optional int64 max_burst = 1;</code>
       */
      public Builder clearMaxBurst() {
        bitField0_ = (bitField0_ & ~0x00000001);
        maxBurst_ = 0L;
        onChanged();
        return this;
      }

      private long maxSustainedPerSecond_ ;
      /**
       * <pre>
       * The maximum sustained request per second limit for a single endpoint. In the context of the,
       * token bucket algorithm, this constant represents the rate at which the token bucket fills.
       * </pre>
       *
       * <code>optional int64 max_sustained_per_second = 2;</code>
       */
      public boolean hasMaxSustainedPerSecond() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <pre>
       * The maximum sustained request per second limit for a single endpoint. In the context of the,
       * token bucket algorithm, this constant represents the rate at which the token bucket fills.
       * </pre>
       *
       * <code>optional int64 max_sustained_per_second = 2;</code>
       */
      public long getMaxSustainedPerSecond() {
        return maxSustainedPerSecond_;
      }
      /**
       * <pre>
       * The maximum sustained request per second limit for a single endpoint. In the context of the,
       * token bucket algorithm, this constant represents the rate at which the token bucket fills.
       * </pre>
       *
       * <code>optional int64 max_sustained_per_second = 2;</code>
       */
      public Builder setMaxSustainedPerSecond(long value) {
        bitField0_ |= 0x00000002;
        maxSustainedPerSecond_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The maximum sustained request per second limit for a single endpoint. In the context of the,
       * token bucket algorithm, this constant represents the rate at which the token bucket fills.
       * </pre>
       *
       * <code>optional int64 max_sustained_per_second = 2;</code>
       */
      public Builder clearMaxSustainedPerSecond() {
        bitField0_ = (bitField0_ & ~0x00000002);
        maxSustainedPerSecond_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.RateLimit)
    }

    // @@protoc_insertion_point(class_scope:mlflow.RateLimit)
    private static final com.databricks.api.proto.databricks.Databricks.RateLimit DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.RateLimit();
    }

    public static com.databricks.api.proto.databricks.Databricks.RateLimit getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<RateLimit>
        PARSER = new com.google.protobuf.AbstractParser<RateLimit>() {
      @java.lang.Override
      public RateLimit parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RateLimit(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RateLimit> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RateLimit> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.RateLimit getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DocumentationMetadataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.DocumentationMetadata)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     */
    boolean hasDocstring();
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     */
    java.lang.String getDocstring();
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     */
    com.google.protobuf.ByteString
        getDocstringBytes();

    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     */
    boolean hasLeadDoc();
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     */
    java.lang.String getLeadDoc();
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     */
    com.google.protobuf.ByteString
        getLeadDocBytes();

    /**
     * <pre>
     * The visibility level when the docstring was generated.
     * The documentation extractor builds multiple versions of the documentation, one for each
     * visibility level. The documentation is then generated for each visibility level.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 3;</code>
     */
    boolean hasVisibility();
    /**
     * <pre>
     * The visibility level when the docstring was generated.
     * The documentation extractor builds multiple versions of the documentation, one for each
     * visibility level. The documentation is then generated for each visibility level.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 3;</code>
     */
    com.databricks.api.proto.databricks.Databricks.Visibility getVisibility();

    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     */
    java.util.List<java.lang.String>
        getOriginalProtoPathList();
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     */
    int getOriginalProtoPathCount();
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     */
    java.lang.String getOriginalProtoPath(int index);
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     */
    com.google.protobuf.ByteString
        getOriginalProtoPathBytes(int index);

    /**
     * <pre>
     * The location (line number) of the start of the documentation. This is required to keep the
     * pieces of documentation sorted.
     * </pre>
     *
     * <code>optional int32 position = 5;</code>
     */
    boolean hasPosition();
    /**
     * <pre>
     * The location (line number) of the start of the documentation. This is required to keep the
     * pieces of documentation sorted.
     * </pre>
     *
     * <code>optional int32 position = 5;</code>
     */
    int getPosition();
  }
  /**
   * <pre>
   * A block of documentation that is added to the AST after parsing the original protocol buffer.
   * </pre>
   *
   * Protobuf type {@code mlflow.DocumentationMetadata}
   */
  public  static final class DocumentationMetadata extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.DocumentationMetadata)
      DocumentationMetadataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DocumentationMetadata.newBuilder() to construct.
    private DocumentationMetadata(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DocumentationMetadata() {
      docstring_ = "";
      leadDoc_ = "";
      visibility_ = 1;
      originalProtoPath_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      position_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DocumentationMetadata(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              docstring_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              leadDoc_ = bs;
              break;
            }
            case 24: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              com.databricks.api.proto.databricks.Databricks.Visibility value = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(3, rawValue);
              } else {
                bitField0_ |= 0x00000004;
                visibility_ = rawValue;
              }
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                originalProtoPath_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000008;
              }
              originalProtoPath_.add(bs);
              break;
            }
            case 40: {
              bitField0_ |= 0x00000008;
              position_ = input.readInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          originalProtoPath_ = originalProtoPath_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class, com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.Builder.class);
    }

    private int bitField0_;
    public static final int DOCSTRING_FIELD_NUMBER = 1;
    private volatile java.lang.Object docstring_;
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     */
    public boolean hasDocstring() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     */
    public java.lang.String getDocstring() {
      java.lang.Object ref = docstring_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          docstring_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * The string of documentation attached to this particular item.
     * </pre>
     *
     * <code>optional string docstring = 1;</code>
     */
    public com.google.protobuf.ByteString
        getDocstringBytes() {
      java.lang.Object ref = docstring_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        docstring_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LEAD_DOC_FIELD_NUMBER = 2;
    private volatile java.lang.Object leadDoc_;
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     */
    public boolean hasLeadDoc() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     */
    public java.lang.String getLeadDoc() {
      java.lang.Object ref = leadDoc_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          leadDoc_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * The string of documentation that is *before* this item. This only makes sense for top-level
     * items such as (top-level) messages, (top-level) enumerations, or services. In all other
     * cases, this string is empty.
     * </pre>
     *
     * <code>optional string lead_doc = 2;</code>
     */
    public com.google.protobuf.ByteString
        getLeadDocBytes() {
      java.lang.Object ref = leadDoc_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        leadDoc_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VISIBILITY_FIELD_NUMBER = 3;
    private int visibility_;
    /**
     * <pre>
     * The visibility level when the docstring was generated.
     * The documentation extractor builds multiple versions of the documentation, one for each
     * visibility level. The documentation is then generated for each visibility level.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 3;</code>
     */
    public boolean hasVisibility() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <pre>
     * The visibility level when the docstring was generated.
     * The documentation extractor builds multiple versions of the documentation, one for each
     * visibility level. The documentation is then generated for each visibility level.
     * </pre>
     *
     * <code>optional .mlflow.Visibility visibility = 3;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.Visibility getVisibility() {
      @SuppressWarnings("deprecation")
      com.databricks.api.proto.databricks.Databricks.Visibility result = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(visibility_);
      return result == null ? com.databricks.api.proto.databricks.Databricks.Visibility.PUBLIC : result;
    }

    public static final int ORIGINAL_PROTO_PATH_FIELD_NUMBER = 4;
    private com.google.protobuf.LazyStringList originalProtoPath_;
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getOriginalProtoPathList() {
      return originalProtoPath_;
    }
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     */
    public int getOriginalProtoPathCount() {
      return originalProtoPath_.size();
    }
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     */
    public java.lang.String getOriginalProtoPath(int index) {
      return originalProtoPath_.get(index);
    }
    /**
     * <pre>
     * The original proto path in the internal representation. This is useful when performing field
     * flattening to figure out what the original field was.
     * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
     * This path is unique.
     * </pre>
     *
     * <code>repeated string original_proto_path = 4;</code>
     */
    public com.google.protobuf.ByteString
        getOriginalProtoPathBytes(int index) {
      return originalProtoPath_.getByteString(index);
    }

    public static final int POSITION_FIELD_NUMBER = 5;
    private int position_;
    /**
     * <pre>
     * The location (line number) of the start of the documentation. This is required to keep the
     * pieces of documentation sorted.
     * </pre>
     *
     * <code>optional int32 position = 5;</code>
     */
    public boolean hasPosition() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <pre>
     * The location (line number) of the start of the documentation. This is required to keep the
     * pieces of documentation sorted.
     * </pre>
     *
     * <code>optional int32 position = 5;</code>
     */
    public int getPosition() {
      return position_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, docstring_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, leadDoc_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeEnum(3, visibility_);
      }
      for (int i = 0; i < originalProtoPath_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, originalProtoPath_.getRaw(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(5, position_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, docstring_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, leadDoc_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, visibility_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < originalProtoPath_.size(); i++) {
          dataSize += computeStringSizeNoTag(originalProtoPath_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getOriginalProtoPathList().size();
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, position_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.DocumentationMetadata)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.DocumentationMetadata other = (com.databricks.api.proto.databricks.Databricks.DocumentationMetadata) obj;

      boolean result = true;
      result = result && (hasDocstring() == other.hasDocstring());
      if (hasDocstring()) {
        result = result && getDocstring()
            .equals(other.getDocstring());
      }
      result = result && (hasLeadDoc() == other.hasLeadDoc());
      if (hasLeadDoc()) {
        result = result && getLeadDoc()
            .equals(other.getLeadDoc());
      }
      result = result && (hasVisibility() == other.hasVisibility());
      if (hasVisibility()) {
        result = result && visibility_ == other.visibility_;
      }
      result = result && getOriginalProtoPathList()
          .equals(other.getOriginalProtoPathList());
      result = result && (hasPosition() == other.hasPosition());
      if (hasPosition()) {
        result = result && (getPosition()
            == other.getPosition());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasDocstring()) {
        hash = (37 * hash) + DOCSTRING_FIELD_NUMBER;
        hash = (53 * hash) + getDocstring().hashCode();
      }
      if (hasLeadDoc()) {
        hash = (37 * hash) + LEAD_DOC_FIELD_NUMBER;
        hash = (53 * hash) + getLeadDoc().hashCode();
      }
      if (hasVisibility()) {
        hash = (37 * hash) + VISIBILITY_FIELD_NUMBER;
        hash = (53 * hash) + visibility_;
      }
      if (getOriginalProtoPathCount() > 0) {
        hash = (37 * hash) + ORIGINAL_PROTO_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getOriginalProtoPathList().hashCode();
      }
      if (hasPosition()) {
        hash = (37 * hash) + POSITION_FIELD_NUMBER;
        hash = (53 * hash) + getPosition();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.DocumentationMetadata prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A block of documentation that is added to the AST after parsing the original protocol buffer.
     * </pre>
     *
     * Protobuf type {@code mlflow.DocumentationMetadata}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.DocumentationMetadata)
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class, com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        docstring_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        leadDoc_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        visibility_ = 1;
        bitField0_ = (bitField0_ & ~0x00000004);
        originalProtoPath_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        position_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DocumentationMetadata_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DocumentationMetadata getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DocumentationMetadata build() {
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DocumentationMetadata buildPartial() {
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata result = new com.databricks.api.proto.databricks.Databricks.DocumentationMetadata(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.docstring_ = docstring_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.leadDoc_ = leadDoc_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.visibility_ = visibility_;
        if (((bitField0_ & 0x00000008) == 0x00000008)) {
          originalProtoPath_ = originalProtoPath_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.originalProtoPath_ = originalProtoPath_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000008;
        }
        result.position_ = position_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.DocumentationMetadata) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.DocumentationMetadata)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.DocumentationMetadata other) {
        if (other == com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance()) return this;
        if (other.hasDocstring()) {
          bitField0_ |= 0x00000001;
          docstring_ = other.docstring_;
          onChanged();
        }
        if (other.hasLeadDoc()) {
          bitField0_ |= 0x00000002;
          leadDoc_ = other.leadDoc_;
          onChanged();
        }
        if (other.hasVisibility()) {
          setVisibility(other.getVisibility());
        }
        if (!other.originalProtoPath_.isEmpty()) {
          if (originalProtoPath_.isEmpty()) {
            originalProtoPath_ = other.originalProtoPath_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureOriginalProtoPathIsMutable();
            originalProtoPath_.addAll(other.originalProtoPath_);
          }
          onChanged();
        }
        if (other.hasPosition()) {
          setPosition(other.getPosition());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.DocumentationMetadata) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object docstring_ = "";
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       */
      public boolean hasDocstring() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       */
      public java.lang.String getDocstring() {
        java.lang.Object ref = docstring_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            docstring_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       */
      public com.google.protobuf.ByteString
          getDocstringBytes() {
        java.lang.Object ref = docstring_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          docstring_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       */
      public Builder setDocstring(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        docstring_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       */
      public Builder clearDocstring() {
        bitField0_ = (bitField0_ & ~0x00000001);
        docstring_ = getDefaultInstance().getDocstring();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The string of documentation attached to this particular item.
       * </pre>
       *
       * <code>optional string docstring = 1;</code>
       */
      public Builder setDocstringBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        docstring_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object leadDoc_ = "";
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       */
      public boolean hasLeadDoc() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       */
      public java.lang.String getLeadDoc() {
        java.lang.Object ref = leadDoc_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            leadDoc_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       */
      public com.google.protobuf.ByteString
          getLeadDocBytes() {
        java.lang.Object ref = leadDoc_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          leadDoc_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       */
      public Builder setLeadDoc(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        leadDoc_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       */
      public Builder clearLeadDoc() {
        bitField0_ = (bitField0_ & ~0x00000002);
        leadDoc_ = getDefaultInstance().getLeadDoc();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The string of documentation that is *before* this item. This only makes sense for top-level
       * items such as (top-level) messages, (top-level) enumerations, or services. In all other
       * cases, this string is empty.
       * </pre>
       *
       * <code>optional string lead_doc = 2;</code>
       */
      public Builder setLeadDocBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        leadDoc_ = value;
        onChanged();
        return this;
      }

      private int visibility_ = 1;
      /**
       * <pre>
       * The visibility level when the docstring was generated.
       * The documentation extractor builds multiple versions of the documentation, one for each
       * visibility level. The documentation is then generated for each visibility level.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 3;</code>
       */
      public boolean hasVisibility() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <pre>
       * The visibility level when the docstring was generated.
       * The documentation extractor builds multiple versions of the documentation, one for each
       * visibility level. The documentation is then generated for each visibility level.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 3;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.Visibility getVisibility() {
        @SuppressWarnings("deprecation")
        com.databricks.api.proto.databricks.Databricks.Visibility result = com.databricks.api.proto.databricks.Databricks.Visibility.valueOf(visibility_);
        return result == null ? com.databricks.api.proto.databricks.Databricks.Visibility.PUBLIC : result;
      }
      /**
       * <pre>
       * The visibility level when the docstring was generated.
       * The documentation extractor builds multiple versions of the documentation, one for each
       * visibility level. The documentation is then generated for each visibility level.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 3;</code>
       */
      public Builder setVisibility(com.databricks.api.proto.databricks.Databricks.Visibility value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        visibility_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The visibility level when the docstring was generated.
       * The documentation extractor builds multiple versions of the documentation, one for each
       * visibility level. The documentation is then generated for each visibility level.
       * </pre>
       *
       * <code>optional .mlflow.Visibility visibility = 3;</code>
       */
      public Builder clearVisibility() {
        bitField0_ = (bitField0_ & ~0x00000004);
        visibility_ = 1;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList originalProtoPath_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureOriginalProtoPathIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          originalProtoPath_ = new com.google.protobuf.LazyStringArrayList(originalProtoPath_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getOriginalProtoPathList() {
        return originalProtoPath_.getUnmodifiableView();
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public int getOriginalProtoPathCount() {
        return originalProtoPath_.size();
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public java.lang.String getOriginalProtoPath(int index) {
        return originalProtoPath_.get(index);
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public com.google.protobuf.ByteString
          getOriginalProtoPathBytes(int index) {
        return originalProtoPath_.getByteString(index);
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public Builder setOriginalProtoPath(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureOriginalProtoPathIsMutable();
        originalProtoPath_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public Builder addOriginalProtoPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureOriginalProtoPathIsMutable();
        originalProtoPath_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public Builder addAllOriginalProtoPath(
          java.lang.Iterable<java.lang.String> values) {
        ensureOriginalProtoPathIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, originalProtoPath_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public Builder clearOriginalProtoPath() {
        originalProtoPath_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The original proto path in the internal representation. This is useful when performing field
       * flattening to figure out what the original field was.
       * One example is ["jobs","Run","original_attempt_run_id"] for jobs.
       * This path is unique.
       * </pre>
       *
       * <code>repeated string original_proto_path = 4;</code>
       */
      public Builder addOriginalProtoPathBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureOriginalProtoPathIsMutable();
        originalProtoPath_.add(value);
        onChanged();
        return this;
      }

      private int position_ ;
      /**
       * <pre>
       * The location (line number) of the start of the documentation. This is required to keep the
       * pieces of documentation sorted.
       * </pre>
       *
       * <code>optional int32 position = 5;</code>
       */
      public boolean hasPosition() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <pre>
       * The location (line number) of the start of the documentation. This is required to keep the
       * pieces of documentation sorted.
       * </pre>
       *
       * <code>optional int32 position = 5;</code>
       */
      public int getPosition() {
        return position_;
      }
      /**
       * <pre>
       * The location (line number) of the start of the documentation. This is required to keep the
       * pieces of documentation sorted.
       * </pre>
       *
       * <code>optional int32 position = 5;</code>
       */
      public Builder setPosition(int value) {
        bitField0_ |= 0x00000010;
        position_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The location (line number) of the start of the documentation. This is required to keep the
       * pieces of documentation sorted.
       * </pre>
       *
       * <code>optional int32 position = 5;</code>
       */
      public Builder clearPosition() {
        bitField0_ = (bitField0_ & ~0x00000010);
        position_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.DocumentationMetadata)
    }

    // @@protoc_insertion_point(class_scope:mlflow.DocumentationMetadata)
    private static final com.databricks.api.proto.databricks.Databricks.DocumentationMetadata DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.DocumentationMetadata();
    }

    public static com.databricks.api.proto.databricks.Databricks.DocumentationMetadata getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DocumentationMetadata>
        PARSER = new com.google.protobuf.AbstractParser<DocumentationMetadata>() {
      @java.lang.Override
      public DocumentationMetadata parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DocumentationMetadata(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DocumentationMetadata> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DocumentationMetadata> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.DocumentationMetadata getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DatabricksServiceExceptionProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:mlflow.DatabricksServiceExceptionProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .mlflow.ErrorCode error_code = 1;</code>
     */
    boolean hasErrorCode();
    /**
     * <code>optional .mlflow.ErrorCode error_code = 1;</code>
     */
    com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCode();

    /**
     * <code>optional string message = 2;</code>
     */
    boolean hasMessage();
    /**
     * <code>optional string message = 2;</code>
     */
    java.lang.String getMessage();
    /**
     * <code>optional string message = 2;</code>
     */
    com.google.protobuf.ByteString
        getMessageBytes();

    /**
     * <code>optional string stack_trace = 3;</code>
     */
    boolean hasStackTrace();
    /**
     * <code>optional string stack_trace = 3;</code>
     */
    java.lang.String getStackTrace();
    /**
     * <code>optional string stack_trace = 3;</code>
     */
    com.google.protobuf.ByteString
        getStackTraceBytes();
  }
  /**
   * <pre>
   * Serialization format for DatabricksServiceException.
   * </pre>
   *
   * Protobuf type {@code mlflow.DatabricksServiceExceptionProto}
   */
  public  static final class DatabricksServiceExceptionProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:mlflow.DatabricksServiceExceptionProto)
      DatabricksServiceExceptionProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DatabricksServiceExceptionProto.newBuilder() to construct.
    private DatabricksServiceExceptionProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DatabricksServiceExceptionProto() {
      errorCode_ = 1;
      message_ = "";
      stackTrace_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DatabricksServiceExceptionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              com.databricks.api.proto.databricks.Databricks.ErrorCode value = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                errorCode_ = rawValue;
              }
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              message_ = bs;
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              stackTrace_ = bs;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksServiceExceptionProto_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksServiceExceptionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto.class, com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto.Builder.class);
    }

    private int bitField0_;
    public static final int ERROR_CODE_FIELD_NUMBER = 1;
    private int errorCode_;
    /**
     * <code>optional .mlflow.ErrorCode error_code = 1;</code>
     */
    public boolean hasErrorCode() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .mlflow.ErrorCode error_code = 1;</code>
     */
    public com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCode() {
      @SuppressWarnings("deprecation")
      com.databricks.api.proto.databricks.Databricks.ErrorCode result = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(errorCode_);
      return result == null ? com.databricks.api.proto.databricks.Databricks.ErrorCode.INTERNAL_ERROR : result;
    }

    public static final int MESSAGE_FIELD_NUMBER = 2;
    private volatile java.lang.Object message_;
    /**
     * <code>optional string message = 2;</code>
     */
    public boolean hasMessage() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string message = 2;</code>
     */
    public java.lang.String getMessage() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          message_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string message = 2;</code>
     */
    public com.google.protobuf.ByteString
        getMessageBytes() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        message_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int STACK_TRACE_FIELD_NUMBER = 3;
    private volatile java.lang.Object stackTrace_;
    /**
     * <code>optional string stack_trace = 3;</code>
     */
    public boolean hasStackTrace() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string stack_trace = 3;</code>
     */
    public java.lang.String getStackTrace() {
      java.lang.Object ref = stackTrace_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          stackTrace_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string stack_trace = 3;</code>
     */
    public com.google.protobuf.ByteString
        getStackTraceBytes() {
      java.lang.Object ref = stackTrace_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        stackTrace_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, errorCode_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, message_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, stackTrace_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, errorCode_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, message_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, stackTrace_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto)) {
        return super.equals(obj);
      }
      com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto other = (com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto) obj;

      boolean result = true;
      result = result && (hasErrorCode() == other.hasErrorCode());
      if (hasErrorCode()) {
        result = result && errorCode_ == other.errorCode_;
      }
      result = result && (hasMessage() == other.hasMessage());
      if (hasMessage()) {
        result = result && getMessage()
            .equals(other.getMessage());
      }
      result = result && (hasStackTrace() == other.hasStackTrace());
      if (hasStackTrace()) {
        result = result && getStackTrace()
            .equals(other.getStackTrace());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasErrorCode()) {
        hash = (37 * hash) + ERROR_CODE_FIELD_NUMBER;
        hash = (53 * hash) + errorCode_;
      }
      if (hasMessage()) {
        hash = (37 * hash) + MESSAGE_FIELD_NUMBER;
        hash = (53 * hash) + getMessage().hashCode();
      }
      if (hasStackTrace()) {
        hash = (37 * hash) + STACK_TRACE_FIELD_NUMBER;
        hash = (53 * hash) + getStackTrace().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Serialization format for DatabricksServiceException.
     * </pre>
     *
     * Protobuf type {@code mlflow.DatabricksServiceExceptionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:mlflow.DatabricksServiceExceptionProto)
        com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksServiceExceptionProto_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksServiceExceptionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto.class, com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto.Builder.class);
      }

      // Construct using com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        errorCode_ = 1;
        bitField0_ = (bitField0_ & ~0x00000001);
        message_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        stackTrace_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.databricks.api.proto.databricks.Databricks.internal_static_mlflow_DatabricksServiceExceptionProto_descriptor;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto getDefaultInstanceForType() {
        return com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto.getDefaultInstance();
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto build() {
        com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto buildPartial() {
        com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto result = new com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.errorCode_ = errorCode_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.message_ = message_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.stackTrace_ = stackTrace_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto) {
          return mergeFrom((com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto other) {
        if (other == com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto.getDefaultInstance()) return this;
        if (other.hasErrorCode()) {
          setErrorCode(other.getErrorCode());
        }
        if (other.hasMessage()) {
          bitField0_ |= 0x00000002;
          message_ = other.message_;
          onChanged();
        }
        if (other.hasStackTrace()) {
          bitField0_ |= 0x00000004;
          stackTrace_ = other.stackTrace_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int errorCode_ = 1;
      /**
       * <code>optional .mlflow.ErrorCode error_code = 1;</code>
       */
      public boolean hasErrorCode() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .mlflow.ErrorCode error_code = 1;</code>
       */
      public com.databricks.api.proto.databricks.Databricks.ErrorCode getErrorCode() {
        @SuppressWarnings("deprecation")
        com.databricks.api.proto.databricks.Databricks.ErrorCode result = com.databricks.api.proto.databricks.Databricks.ErrorCode.valueOf(errorCode_);
        return result == null ? com.databricks.api.proto.databricks.Databricks.ErrorCode.INTERNAL_ERROR : result;
      }
      /**
       * <code>optional .mlflow.ErrorCode error_code = 1;</code>
       */
      public Builder setErrorCode(com.databricks.api.proto.databricks.Databricks.ErrorCode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        errorCode_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .mlflow.ErrorCode error_code = 1;</code>
       */
      public Builder clearErrorCode() {
        bitField0_ = (bitField0_ & ~0x00000001);
        errorCode_ = 1;
        onChanged();
        return this;
      }

      private java.lang.Object message_ = "";
      /**
       * <code>optional string message = 2;</code>
       */
      public boolean hasMessage() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string message = 2;</code>
       */
      public java.lang.String getMessage() {
        java.lang.Object ref = message_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            message_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string message = 2;</code>
       */
      public com.google.protobuf.ByteString
          getMessageBytes() {
        java.lang.Object ref = message_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          message_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string message = 2;</code>
       */
      public Builder setMessage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        message_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string message = 2;</code>
       */
      public Builder clearMessage() {
        bitField0_ = (bitField0_ & ~0x00000002);
        message_ = getDefaultInstance().getMessage();
        onChanged();
        return this;
      }
      /**
       * <code>optional string message = 2;</code>
       */
      public Builder setMessageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        message_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object stackTrace_ = "";
      /**
       * <code>optional string stack_trace = 3;</code>
       */
      public boolean hasStackTrace() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string stack_trace = 3;</code>
       */
      public java.lang.String getStackTrace() {
        java.lang.Object ref = stackTrace_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            stackTrace_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string stack_trace = 3;</code>
       */
      public com.google.protobuf.ByteString
          getStackTraceBytes() {
        java.lang.Object ref = stackTrace_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          stackTrace_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string stack_trace = 3;</code>
       */
      public Builder setStackTrace(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        stackTrace_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string stack_trace = 3;</code>
       */
      public Builder clearStackTrace() {
        bitField0_ = (bitField0_ & ~0x00000004);
        stackTrace_ = getDefaultInstance().getStackTrace();
        onChanged();
        return this;
      }
      /**
       * <code>optional string stack_trace = 3;</code>
       */
      public Builder setStackTraceBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        stackTrace_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:mlflow.DatabricksServiceExceptionProto)
    }

    // @@protoc_insertion_point(class_scope:mlflow.DatabricksServiceExceptionProto)
    private static final com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto();
    }

    public static com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DatabricksServiceExceptionProto>
        PARSER = new com.google.protobuf.AbstractParser<DatabricksServiceExceptionProto>() {
      @java.lang.Override
      public DatabricksServiceExceptionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DatabricksServiceExceptionProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DatabricksServiceExceptionProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DatabricksServiceExceptionProto> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.databricks.api.proto.databricks.Databricks.DatabricksServiceExceptionProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public static final int VISIBILITY_FIELD_NUMBER = 51310;
  /**
   * <pre>
   * Indicates an overriding visibility for this field. This can only reduce the visibility;
   * a public field in an internal API will not have an effect.
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      com.databricks.api.proto.databricks.Databricks.Visibility> visibility = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.Visibility.class,
        null);
  public static final int VALIDATE_REQUIRED_FIELD_NUMBER = 51311;
  /**
   * <pre>
   * This annotation indicates that certain fields must be supplied for the request to be carried
   * out successfully.
   * A request field may go from being required to optional over time, but a field may not
   * go from being optional to required, for backwards compatiblity reasons.
   * Request RPCs are validated automatically prior to processing for required fields, but
   * returned values are not validated in any way.
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      java.lang.Boolean> validateRequired = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        java.lang.Boolean.class,
        null);
  public static final int JSON_INLINE_FIELD_NUMBER = 51312;
  /**
   * <pre>
   * Causes the fields within the tagged Message to be inlined into this Message, for the purposes
   * of our JSON API.
   * For example, rather than serializing
   *   {
   *     "attrs" : {
   *       "cluster_name" : "Foo"
   *     }
   *   }
   * If "attrs" were marked json_inline, we would upgrade cluster_name to a top-level field:
   *   {
   *     "cluster_name" : "Foo"
   *   }
   * Note that this is only applicable to singular Message fields.
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      java.lang.Boolean> jsonInline = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        java.lang.Boolean.class,
        null);
  public static final int JSON_MAP_FIELD_NUMBER = 51313;
  /**
   * <pre>
   * Causes a field which conceptually represents a Map to be serialized as a JSON Map.
   * The given field must be a Message with exactly 2 fields called "key" and "value", where key
   * must be a string.
   * For example, rather than serializing
   *   [ { "key" : "spark.speculation", "value" : "false" } ]
   * If this field were marked json_map, we would serialize it as
   *   { "spark.speculation" : "false" }
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      java.lang.Boolean> jsonMap = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        java.lang.Boolean.class,
        null);
  public static final int FIELD_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation meta data for this field. This gets added automatically when the proto is
   * parsed.
   * There are as many doc blocks as visibility levels.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.FieldOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.FieldOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> fieldDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int RPC_FIELD_NUMBER = 51310;
  /**
   * <code>extend .google.protobuf.MethodOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.MethodOptions,
      com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions> rpc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.class,
        com.databricks.api.proto.databricks.Databricks.DatabricksRpcOptions.getDefaultInstance());
  public static final int METHOD_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.MethodOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.MethodOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> methodDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int MESSAGE_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.MessageOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.MessageOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> messageDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int SERVICE_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.ServiceOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.ServiceOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> serviceDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int ENUM_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.EnumOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.EnumOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> enumDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  public static final int ENUM_VALUE_VISIBILITY_FIELD_NUMBER = 51310;
  /**
   * <pre>
   * Indicates an overriding visibility for this field. This can only reduce the visibility;
   * a public field in an internal API will not have an effect.
   * </pre>
   *
   * <code>extend .google.protobuf.EnumValueOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.EnumValueOptions,
      com.databricks.api.proto.databricks.Databricks.Visibility> enumValueVisibility = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.Visibility.class,
        null);
  public static final int ENUM_VALUE_DOC_FIELD_NUMBER = 51314;
  /**
   * <pre>
   * The documentation metadata.
   * This is not meant to be crafted by hand; this will be automatically generated when parsing
   * the proto file.
   * </pre>
   *
   * <code>extend .google.protobuf.EnumValueOptions { ... }</code>
   */
  public static final
    com.google.protobuf.GeneratedMessage.GeneratedExtension<
      com.google.protobuf.DescriptorProtos.EnumValueOptions,
      java.util.List<com.databricks.api.proto.databricks.Databricks.DocumentationMetadata>> enumValueDoc = com.google.protobuf.GeneratedMessage
          .newFileScopedGeneratedExtension(
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.class,
        com.databricks.api.proto.databricks.Databricks.DocumentationMetadata.getDefaultInstance());
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_DatabricksRpcOptions_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_DatabricksRpcOptions_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_HttpEndpoint_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_HttpEndpoint_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_ApiVersion_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_ApiVersion_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_RateLimit_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_RateLimit_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_DocumentationMetadata_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_DocumentationMetadata_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_mlflow_DatabricksServiceExceptionProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_mlflow_DatabricksServiceExceptionProto_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\020databricks.proto\022\006mlflow\032 google/proto" +
      "buf/descriptor.proto\032\025scalapb/scalapb.pr" +
      "oto\"\315\001\n\024DatabricksRpcOptions\022\'\n\tendpoint" +
      "s\030\001 \003(\0132\024.mlflow.HttpEndpoint\022&\n\nvisibil" +
      "ity\030\002 \001(\0162\022.mlflow.Visibility\022&\n\013error_c" +
      "odes\030\003 \003(\0162\021.mlflow.ErrorCode\022%\n\nrate_li" +
      "mit\030\004 \001(\0132\021.mlflow.RateLimit\022\025\n\rrpc_doc_" +
      "title\030\005 \001(\t\"U\n\014HttpEndpoint\022\024\n\006method\030\001 " +
      "\001(\t:\004POST\022\014\n\004path\030\002 \001(\t\022!\n\005since\030\003 \001(\0132\022" +
      ".mlflow.ApiVersion\"*\n\nApiVersion\022\r\n\005majo" +
      "r\030\001 \001(\005\022\r\n\005minor\030\002 \001(\005\"@\n\tRateLimit\022\021\n\tm" +
      "ax_burst\030\001 \001(\003\022 \n\030max_sustained_per_seco" +
      "nd\030\002 \001(\003\"\223\001\n\025DocumentationMetadata\022\021\n\tdo" +
      "cstring\030\001 \001(\t\022\020\n\010lead_doc\030\002 \001(\t\022&\n\nvisib" +
      "ility\030\003 \001(\0162\022.mlflow.Visibility\022\033\n\023origi" +
      "nal_proto_path\030\004 \003(\t\022\020\n\010position\030\005 \001(\005\"n" +
      "\n\037DatabricksServiceExceptionProto\022%\n\nerr" +
      "or_code\030\001 \001(\0162\021.mlflow.ErrorCode\022\017\n\007mess" +
      "age\030\002 \001(\t\022\023\n\013stack_trace\030\003 \001(\t*?\n\nVisibi" +
      "lity\022\n\n\006PUBLIC\020\001\022\014\n\010INTERNAL\020\002\022\027\n\023PUBLIC" +
      "_UNDOCUMENTED\020\003*\366\004\n\tErrorCode\022\022\n\016INTERNA" +
      "L_ERROR\020\001\022\033\n\027TEMPORARILY_UNAVAILABLE\020\002\022\014" +
      "\n\010IO_ERROR\020\003\022\017\n\013BAD_REQUEST\020\004\022\034\n\027INVALID" +
      "_PARAMETER_VALUE\020\350\007\022\027\n\022ENDPOINT_NOT_FOUN" +
      "D\020\351\007\022\026\n\021MALFORMED_REQUEST\020\352\007\022\022\n\rINVALID_" +
      "STATE\020\353\007\022\026\n\021PERMISSION_DENIED\020\354\007\022\025\n\020FEAT" +
      "URE_DISABLED\020\355\007\022\032\n\025CUSTOMER_UNAUTHORIZED" +
      "\020\356\007\022\033\n\026REQUEST_LIMIT_EXCEEDED\020\357\007\022\035\n\030INVA" +
      "LID_STATE_TRANSITION\020\321\017\022\033\n\026COULD_NOT_ACQ" +
      "UIRE_LOCK\020\322\017\022\034\n\027RESOURCE_ALREADY_EXISTS\020" +
      "\271\027\022\034\n\027RESOURCE_DOES_NOT_EXIST\020\272\027\022\023\n\016QUOT" +
      "A_EXCEEDED\020\241\037\022\034\n\027MAX_BLOCK_SIZE_EXCEEDED" +
      "\020\242\037\022\033\n\026MAX_READ_SIZE_EXCEEDED\020\243\037\022\023\n\016DRY_" +
      "RUN_FAILED\020\211\'\022\034\n\027RESOURCE_LIMIT_EXCEEDED" +
      "\020\212\'\022\030\n\023DIRECTORY_NOT_EMPTY\020\361.\022\030\n\023DIRECTO" +
      "RY_PROTECTED\020\362.\022\037\n\032MAX_NOTEBOOK_SIZE_EXC" +
      "EEDED\020\363.:G\n\nvisibility\022\035.google.protobuf" +
      ".FieldOptions\030\356\220\003 \001(\0162\022.mlflow.Visibilit" +
      "y::\n\021validate_required\022\035.google.protobuf" +
      ".FieldOptions\030\357\220\003 \001(\010:4\n\013json_inline\022\035.g" +
      "oogle.protobuf.FieldOptions\030\360\220\003 \001(\010:1\n\010j" +
      "son_map\022\035.google.protobuf.FieldOptions\030\361" +
      "\220\003 \001(\010:Q\n\tfield_doc\022\035.google.protobuf.Fi" +
      "eldOptions\030\362\220\003 \003(\0132\035.mlflow.Documentatio" +
      "nMetadata:K\n\003rpc\022\036.google.protobuf.Metho" +
      "dOptions\030\356\220\003 \001(\0132\034.mlflow.DatabricksRpcO" +
      "ptions:S\n\nmethod_doc\022\036.google.protobuf.M" +
      "ethodOptions\030\362\220\003 \003(\0132\035.mlflow.Documentat" +
      "ionMetadata:U\n\013message_doc\022\037.google.prot" +
      "obuf.MessageOptions\030\362\220\003 \003(\0132\035.mlflow.Doc" +
      "umentationMetadata:U\n\013service_doc\022\037.goog" +
      "le.protobuf.ServiceOptions\030\362\220\003 \003(\0132\035.mlf" +
      "low.DocumentationMetadata:O\n\010enum_doc\022\034." +
      "google.protobuf.EnumOptions\030\362\220\003 \003(\0132\035.ml" +
      "flow.DocumentationMetadata:V\n\025enum_value" +
      "_visibility\022!.google.protobuf.EnumValueO" +
      "ptions\030\356\220\003 \001(\0162\022.mlflow.Visibility:Z\n\016en" +
      "um_value_doc\022!.google.protobuf.EnumValue" +
      "Options\030\362\220\003 \003(\0132\035.mlflow.DocumentationMe" +
      "tadataB*\n#com.databricks.api.proto.datab" +
      "ricks\342?\002\020\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          com.google.protobuf.DescriptorProtos.getDescriptor(),
          org.mlflow.scalapb_interface.Scalapb.getDescriptor(),
        }, assigner);
    internal_static_mlflow_DatabricksRpcOptions_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_mlflow_DatabricksRpcOptions_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_DatabricksRpcOptions_descriptor,
        new java.lang.String[] { "Endpoints", "Visibility", "ErrorCodes", "RateLimit", "RpcDocTitle", });
    internal_static_mlflow_HttpEndpoint_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_mlflow_HttpEndpoint_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_HttpEndpoint_descriptor,
        new java.lang.String[] { "Method", "Path", "Since", });
    internal_static_mlflow_ApiVersion_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_mlflow_ApiVersion_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_ApiVersion_descriptor,
        new java.lang.String[] { "Major", "Minor", });
    internal_static_mlflow_RateLimit_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_mlflow_RateLimit_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_RateLimit_descriptor,
        new java.lang.String[] { "MaxBurst", "MaxSustainedPerSecond", });
    internal_static_mlflow_DocumentationMetadata_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_mlflow_DocumentationMetadata_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_DocumentationMetadata_descriptor,
        new java.lang.String[] { "Docstring", "LeadDoc", "Visibility", "OriginalProtoPath", "Position", });
    internal_static_mlflow_DatabricksServiceExceptionProto_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_mlflow_DatabricksServiceExceptionProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_mlflow_DatabricksServiceExceptionProto_descriptor,
        new java.lang.String[] { "ErrorCode", "Message", "StackTrace", });
    visibility.internalInit(descriptor.getExtensions().get(0));
    validateRequired.internalInit(descriptor.getExtensions().get(1));
    jsonInline.internalInit(descriptor.getExtensions().get(2));
    jsonMap.internalInit(descriptor.getExtensions().get(3));
    fieldDoc.internalInit(descriptor.getExtensions().get(4));
    rpc.internalInit(descriptor.getExtensions().get(5));
    methodDoc.internalInit(descriptor.getExtensions().get(6));
    messageDoc.internalInit(descriptor.getExtensions().get(7));
    serviceDoc.internalInit(descriptor.getExtensions().get(8));
    enumDoc.internalInit(descriptor.getExtensions().get(9));
    enumValueVisibility.internalInit(descriptor.getExtensions().get(10));
    enumValueDoc.internalInit(descriptor.getExtensions().get(11));
    com.google.protobuf.ExtensionRegistry registry =
        com.google.protobuf.ExtensionRegistry.newInstance();
    registry.add(org.mlflow.scalapb_interface.Scalapb.options);
    com.google.protobuf.Descriptors.FileDescriptor
        .internalUpdateFileDescriptor(descriptor, registry);
    com.google.protobuf.DescriptorProtos.getDescriptor();
    org.mlflow.scalapb_interface.Scalapb.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
