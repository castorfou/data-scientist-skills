{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating transcription helper functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting audio to the right format\n",
    "Acme Studios have asked you to do a proof of concept to find out more about their audio files.\n",
    "\n",
    "After exploring them briefly, you find there's a few calls but they're in the wrong file format for transcription.\n",
    "\n",
    "As you'll be interacting with many audio files, you decide to begin by creating some helper functions.\n",
    "\n",
    "The first one, convert_to_wav(filename) takes a file path and uses PyDub to convert it from a non-wav format to .wav format.\n",
    "\n",
    "Once it's built, we'll use the function to convert Acme's first call, call_1.mp3, from .mp3 format to .wav.\n",
    "\n",
    "PyDub's AudioSegment class has already been imported. Remember, to work with non-wav files, you'll need ffmpeg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:35:30.645638Z",
     "start_time": "2020-05-29T07:35:25.436551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_1.mp3': 'https://file.io/LR9nRLl5'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  322k    0  322k    0     0   312k      0 --:--:--  0:00:01 --:--:--  312k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_1.mp3')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_1.mp3': 'https://file.io/LR9nRLl5'}}\n",
    "\"\"\"\n",
    "prefixToc = '1.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:36:18.753868Z",
     "start_time": "2020-05-29T07:36:18.721319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import AudioSegment from Pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:42:31.902108Z",
     "start_time": "2020-05-29T07:42:27.916727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data_from_datacamp/chapter 4-Exercise1.1_call_1.mp3 to data_from_datacamp/chapter 4-Exercise1.1_call_1.wav...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create function to convert audio file to wav\n",
    "def convert_to_wav(filename):\n",
    "  \"\"\"Takes an audio file of non .wav format and converts to .wav\"\"\"\n",
    "  # Import audio file\n",
    "  audio = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Create new filename\n",
    "  new_filename = os.path.splitext(filename)[0] + \".wav\"\n",
    "  \n",
    "  # Export file as .wav\n",
    "  audio.export(new_filename, format='wav')\n",
    "  print(f\"Converting {filename} to {new_filename}...\")\n",
    " \n",
    "# Test the function\n",
    "convert_to_wav(prefix+'call_1.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding PyDub stats\n",
    "You decide it'll be helpful to know the audio attributes of any given file easily. This will be especially helpful for finding out how many channels an audio file has or if the frame rate is adequate for transcription.\n",
    "\n",
    "In this exercise, we'll create show_pydub_stats() which takes a filename of an audio file as input. It then imports the audio as a PyDub AudioSegment instance and prints attributes such as number of channels, length and more.\n",
    "\n",
    "It then returns the AudioSegment instance so it can be used later on.\n",
    "\n",
    "We'll use our function on the newly converted .wav file, call_1.wav\n",
    "\n",
    "AudioSegment has already imported from PyDub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:42:46.213858Z",
     "start_time": "2020-05-29T07:42:46.202828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 2\n",
      "Length (ms): 54888\n"
     ]
    }
   ],
   "source": [
    "def show_pydub_stats(filename):\n",
    "  \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
    "  # Create AudioSegment instance\n",
    "  audio_segment = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Print audio attributes and return AudioSegment instance\n",
    "  print(f\"Channels: {audio_segment.channels}\")\n",
    "  print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "  print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "  print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "  print(f\"Length (ms): {len(audio_segment)}\")\n",
    "  return audio_segment\n",
    "\n",
    "# Try the function\n",
    "call_1_audio_segment = show_pydub_stats(prefix+'call_1.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing audio with one line\n",
    "Alright, now you've got functions to convert audio files and find out their attributes, it's time to build one to transcribe them.\n",
    "\n",
    "In this exercise, you'll build transcribe_audio() which takes a filename as input, imports the filename using speech_recognition's AudioFile class and then transcribes it using recognize_google().\n",
    "\n",
    "You've seen these functions before but now we'll put them together so they're accessible in a function.\n",
    "\n",
    "To test it out, we'll transcribe Acme's first call, \"call_1.wav\".\n",
    "\n",
    "speech_recognition has been imported as sr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:45:48.378894Z",
     "start_time": "2020-05-29T07:45:48.362814Z"
    }
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:47:09.727294Z",
     "start_time": "2020-05-29T07:46:52.988757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello welcome to acne Studios support line my name is Daniel how can I best help you pay Daniel this is John I've recently bought a smartphone from you guys 3 weeks ago and already having issues with it oh no that's not good to hear John let's let's get your serial number and then we can we can set up a wider fix it for you get one second grandma serial number it is for 17 very displays how long do you reckon it's going well done we're going to try our best to get the same number of startup disk support case just really really really really I've been trying to contact support from past 3-4 days now and have been put on hold for more than an hour and a half not really happy I can't wait to get this fixed as fast\n"
     ]
    }
   ],
   "source": [
    "def transcribe_audio(filename):\n",
    "  \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "  # Setup a recognizer instance\n",
    "  recognizer = sr.Recognizer()\n",
    "  \n",
    "  # Import the audio file and convert to audio data\n",
    "  audio_file = sr.AudioFile(filename)\n",
    "  with audio_file as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "  \n",
    "  # Return the transcribed text\n",
    "  return recognizer.recognize_google(audio_data)\n",
    "\n",
    "# Test the function\n",
    "print(transcribe_audio(prefix+'call_1.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the helper functions you've built\n",
    "Okay, now we've got some helper functions ready to go, it's time to put them to use!\n",
    "\n",
    "You'll first use convert_to_wav() to convert Acme's call_1.mp3 to .wav format and save it as call_1.wav\n",
    "\n",
    "Using show_pydub_stats() you find call_1.wav has 2 channels so you decide to split them using PyDub's split_to_mono(). Acme tells you the customer channel is likely channel 2. So you export channel 2 using PyDub's .export().\n",
    "\n",
    "Finally, you'll use transcribe_audio() to transcribe channel 2 only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:52:00.344702Z",
     "start_time": "2020-05-29T07:51:58.422979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_1.mp3': 'https://file.io/vegb3SL2'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  644k    0  644k    0     0   401k      0 --:--:--  0:00:01 --:--:--  401k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_1.mp3')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_1.mp3': 'https://file.io/vegb3SL2'}}\n",
    "\"\"\"\n",
    "prefixToc = '1.4'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:52:03.649291Z",
     "start_time": "2020-05-29T07:52:02.394761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data_from_datacamp/chapter 4-Exercise1.4_call_1.mp3 to data_from_datacamp/chapter 4-Exercise1.4_call_1.wav...\n",
      "Channels: 2\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 4\n",
      "Length (ms): 54888\n"
     ]
    }
   ],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(prefix+'call_1.mp3')\n",
    "\n",
    "# Check the stats of new file\n",
    "call_1 = show_pydub_stats(prefix+'call_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:52:53.323447Z",
     "start_time": "2020-05-29T07:52:53.288394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='data_from_datacamp/chapter 4-Exercise1.4_call_1_channel_2.wav'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split call_1 to mono\n",
    "call_1_split = call_1.split_to_mono()\n",
    "\n",
    "# Export channel 2 (the customer channel)\n",
    "call_1_split[1].export(prefix+\"call_1_channel_2.wav\",\n",
    "                       format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:53:51.551043Z",
     "start_time": "2020-05-29T07:53:38.552618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey Daniel this is John I've recently bought a smartphone from your eyes 3 weeks ago and already having issues with that one second grandma serial number it is for 177 I'm very displays how long do you reckon it's going to take me about an hour I'm just just really really really really just I've been trying to contact reports and past past 3-4 days now and have been put on hold Morgan and not really happy I can't get this issue fixed as fast as possible\n"
     ]
    }
   ],
   "source": [
    "# Transcribe the single channel\n",
    "print(transcribe_audio(prefix+\"call_1_channel_2.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on spoken language text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing sentiment of a phone call\n",
    "Once you've transcribed the text from an audio file, it's possible to perform natural language processing on the text.\n",
    "\n",
    "In this exercise, we'll use NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner) to analyze the sentiment of the transcribed text of call_2.wav.\n",
    "\n",
    "To transcribe the text, we'll use the transcribe_audio() function we created earlier.\n",
    "\n",
    "Once we have the text, we'll use NLTK's SentimentIntensityAnalyzer() class to obtain a sentiment polarity score.\n",
    "\n",
    ".polarity_scores(text) returns a value for pos (positive), neu (neutral), neg (negative) and compound. Compound is a mixture of the other three values. The higher it is, the more positive the text. Lower means more negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:00:37.514365Z",
     "start_time": "2020-05-29T08:00:33.314709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_2.wav': 'https://file.io/4Sjun5W4'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3297k    0 3297k    0     0   816k      0 --:--:--  0:00:04 --:--:--  816k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_2.wav')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_2.wav': 'https://file.io/4Sjun5W4'}}\n",
    "\"\"\"\n",
    "prefixToc = '2.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:04:18.510627Z",
     "start_time": "2020-05-29T08:04:17.927238Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\F279814\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:08:32.790714Z",
     "start_time": "2020-05-29T08:08:31.047220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_2_channel_2.wav': 'https://file.io/5cOeP97R'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3297k    0 3297k    0     0  2082k      0 --:--:--  0:00:01 --:--:-- 2081k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_2_channel_2.wav')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_2_channel_2.wav': 'https://file.io/5cOeP97R'}}\n",
    "\"\"\"\n",
    "prefixToc = '2.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:04:32.313541Z",
     "start_time": "2020-05-29T08:04:24.116352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello my name is Daniel thank you for calling acne Studios how can I best help you are hi Daniel my name is Sally I've recently purchased a smart phone from you guys and extremely happy with it but I just got to learn a little bit more about the message bank OK Google location but I'm finding it hard I got you on the corner of Edward and Elizabeth according to Google according to the max but damn would you be able to help me in some way because I think I actually walk straight past your shop yeah sure thing or thank you Sally that's good to hear you're enjoying it let me let me find out where the nearest store is for you\n",
      "{'neg': 0.035, 'neu': 0.708, 'pos': 0.257, 'compound': 0.9844}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Let's try it on one of our phone calls\n",
    "call_2_text = transcribe_audio(prefix+'call_2.wav')\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_text)\n",
    "print(sid.polarity_scores(call_2_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:09:04.375814Z",
     "start_time": "2020-05-29T08:08:57.322207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh hi Daniel my name is Billy recently purchased a smartphone from you guys and extremely happy with them I've just got an issue but I've just got to learn a little bit more about the message Frank I had Google location but I'm finding it hard I don't you want the corner of Edward and Elizabeth according to Google according to the maps but would you be able to help me in some way because I think I actually walk straight past your shop\n",
      "{'neg': 0.034, 'neu': 0.867, 'pos': 0.098, 'compound': 0.7553}\n"
     ]
    }
   ],
   "source": [
    "# Transcribe customer channel of call 2\n",
    "call_2_channel_2_text = transcribe_audio(prefix+'call_2_channel_2.wav')\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_channel_2_text)\n",
    "print(sid.polarity_scores(call_2_channel_2_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:10:15.972480Z",
     "start_time": "2020-05-29T08:10:15.969464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import sent tokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:10:35.037352Z",
     "start_time": "2020-05-29T08:10:35.011282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh hi Daniel my name is Billy recently purchased a smartphone from you guys and extremely happy with them I've just got an issue but I've just got to learn a little bit more about the message Frank I had Google location but I'm finding it hard I don't you want the corner of Edward and Elizabeth according to Google according to the maps but would you be able to help me in some way because I think I actually walk straight past your shop\n",
      "{'neg': 0.034, 'neu': 0.867, 'pos': 0.098, 'compound': 0.7553}\n"
     ]
    }
   ],
   "source": [
    "# Split call 2 channel 2 into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:13:57.021461Z",
     "start_time": "2020-05-29T08:13:57.017968Z"
    }
   },
   "outputs": [],
   "source": [
    "call_2_channel_2_paid_api_text = \"Hello and welcome to acme studios. My name's Daniel. How can I best help you? Hi Diane. This is paid on this call up to see the status of my, I'm proctor mortars at three weeks ago, and then service is terrible. Okay, Peter, sorry to hear about that. Hey, Peter, before we go on, do you mind just, uh, is there something going on with your microphone? I can't quite hear you. Is this any better? Yeah, that's much better. And sorry, what was, what was it that you said when you first first started speaking?  So I ordered a product from you guys three weeks ago and, uh, it's, it's currently on July 1st and I haven't received a provocative, again, three weeks to a full four weeks down line. This service is terrible. Okay. Well, what's your order id? I'll, uh, I'll start looking into that for you. Six, nine, eight, seven five. Okay. Thank you.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:14:09.851322Z",
     "start_time": "2020-05-29T08:14:09.842294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome to acme studios.\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.4588}\n",
      "My name's Daniel.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "How can I best help you?\n",
      "{'neg': 0.0, 'neu': 0.303, 'pos': 0.697, 'compound': 0.7845}\n",
      "Hi Diane.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "This is paid on this call up to see the status of my, I'm proctor mortars at three weeks ago, and then service is terrible.\n",
      "{'neg': 0.114, 'neu': 0.886, 'pos': 0.0, 'compound': -0.4767}\n",
      "Okay, Peter, sorry to hear about that.\n",
      "{'neg': 0.159, 'neu': 0.61, 'pos': 0.232, 'compound': 0.1531}\n",
      "Hey, Peter, before we go on, do you mind just, uh, is there something going on with your microphone?\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "I can't quite hear you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Is this any better?\n",
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "Yeah, that's much better.\n",
      "{'neg': 0.0, 'neu': 0.282, 'pos': 0.718, 'compound': 0.6249}\n",
      "And sorry, what was, what was it that you said when you first first started speaking?\n",
      "{'neg': 0.08, 'neu': 0.92, 'pos': 0.0, 'compound': -0.0772}\n",
      "So I ordered a product from you guys three weeks ago and, uh, it's, it's currently on July 1st and I haven't received a provocative, again, three weeks to a full four weeks down line.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "This service is terrible.\n",
      "{'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.4767}\n",
      "Okay.\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
      "Well, what's your order id?\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "I'll, uh, I'll start looking into that for you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Six, nine, eight, seven five.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Okay.\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
      "Thank you.\n",
      "{'neg': 0.0, 'neu': 0.286, 'pos': 0.714, 'compound': 0.3612}\n"
     ]
    }
   ],
   "source": [
    "# Split channel 2 paid text into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_paid_api_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition on transcribed text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity recognition in spaCy\n",
    "Named entities are real-world objects which have names, such as, cities, people, dates or times. We can use spaCy to find named entities in our transcribed text.\n",
    "\n",
    "In this exercise, you'll transcribe call_4_channel_2.wav using transcribe_audio() and then use spaCy's language model, en_core_web_sm to convert the transcribed text to a spaCy doc.\n",
    "\n",
    "Transforming text to a spaCy doc allows us to leverage spaCy's built-in features for analyzing text, such as, .text for tokens (single words), .sents for sentences and .ents for named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:33:39.512403Z",
     "start_time": "2020-06-10T08:33:32.906991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_4_channel_2.wav': 'https://file.io/NQK8vWrq', 'call_4.wav': 'https://file.io/rItZyWvo'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3590k    0 3590k    0     0  1370k      0 --:--:--  0:00:02 --:--:-- 1369k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3590k    0 3590k    0     0  1704k      0 --:--:--  0:00:02 --:--:-- 1704k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_4_channel_2.wav')\n",
    "uploadToFileIO_pushto_fileio('call_4.wav')\n",
    "\n",
    "{\"success\":true,\"key\":\"NQK8vWrq\",\"link\":\"https://file.io/NQK8vWrq\",\"expiry\":\"14 days\"}\n",
    "{\"success\":true,\"key\":\"rItZyWvo\",\"link\":\"https://file.io/rItZyWvo\",\"expiry\":\"14 days\"}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_4_channel_2.wav': 'https://file.io/NQK8vWrq', 'call_4.wav': 'https://file.io/rItZyWvo'}}\n",
    "\"\"\"\n",
    "prefixToc = '3.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:36:00.784569Z",
     "start_time": "2020-06-10T08:35:54.825334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Daniel my name is Ian and I've recently just purchased a smart phone from you and I'm very happy with the product I'd like to order another one for my friend who lives in Sydney and have it delivered I'm pretty sure it's model 315 I can check that for you and I'll give you my details and if you'd like to take my details and I will also give you the address thank you excellent\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def transcribe_audio(filename):\n",
    "  \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "  # Setup a recognizer instance\n",
    "  recognizer = sr.Recognizer()\n",
    "  \n",
    "  # Import the audio file and convert to audio data\n",
    "  audio_file = sr.AudioFile(filename)\n",
    "  with audio_file as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "  \n",
    "  # Return the transcribed text\n",
    "  return recognizer.recognize_google(audio_data)\n",
    "\n",
    "# Test the function\n",
    "print(transcribe_audio(prefix+'call_4_channel_2.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:36:06.792771Z",
     "start_time": "2020-06-10T08:36:00.792605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Transcribe call 4 channel 2\n",
    "call_4_channel_2_text = transcribe_audio(prefix+\"call_4_channel_2.wav\")\n",
    "\n",
    "# Create a spaCy language model instance\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Check the type of doc\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:37:16.887172Z",
     "start_time": "2020-06-10T08:37:16.876142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi 0\n",
      "Daniel 3\n",
      "my 10\n",
      "name 13\n",
      "is 18\n",
      "Ian 21\n",
      "and 25\n",
      "I 29\n",
      "'ve 30\n",
      "recently 34\n",
      "just 43\n",
      "purchased 48\n",
      "a 58\n",
      "smart 60\n",
      "phone 66\n",
      "from 72\n",
      "you 77\n",
      "and 81\n",
      "I 85\n",
      "'m 86\n",
      "very 89\n",
      "happy 94\n",
      "with 100\n",
      "the 105\n",
      "product 109\n",
      "I 117\n",
      "'d 118\n",
      "like 121\n",
      "to 126\n",
      "order 129\n",
      "another 135\n",
      "one 143\n",
      "for 147\n",
      "my 151\n",
      "friend 154\n",
      "who 161\n",
      "lives 165\n",
      "in 171\n",
      "Sydney 174\n",
      "and 181\n",
      "have 185\n",
      "it 190\n",
      "delivered 193\n",
      "I 203\n",
      "'m 204\n",
      "pretty 207\n",
      "sure 214\n",
      "it 219\n",
      "'s 221\n",
      "model 224\n",
      "315 230\n",
      "I 234\n",
      "can 236\n",
      "check 240\n",
      "that 246\n",
      "for 251\n",
      "you 255\n",
      "and 259\n",
      "I 263\n",
      "'ll 264\n",
      "give 268\n",
      "you 273\n",
      "my 277\n",
      "details 280\n",
      "and 288\n",
      "if 292\n",
      "you 295\n",
      "'d 298\n",
      "like 301\n",
      "to 306\n",
      "take 309\n",
      "my 314\n",
      "details 317\n",
      "and 325\n",
      "I 329\n",
      "will 331\n",
      "also 336\n",
      "give 341\n",
      "you 346\n",
      "the 350\n",
      "address 354\n",
      "thank 362\n",
      "you 368\n",
      "excellent 372\n"
     ]
    }
   ],
   "source": [
    "# Show tokens in doc\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:38:12.535993Z",
     "start_time": "2020-06-10T08:38:12.520332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Daniel\n",
      "my name is Ian\n",
      "and I've recently just purchased a smart phone from you\n",
      "and I'm very happy with the product I'd like to order another one for my friend who lives in Sydney and have it delivered\n",
      "I'm pretty sure it's model 315\n",
      "I can check that for you\n",
      "and I'll give you my details\n",
      "and if you'd like to take my details\n",
      "and I will also give you the address\n",
      "thank you excellent\n"
     ]
    }
   ],
   "source": [
    "# Show sentences in doc\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:38:52.673346Z",
     "start_time": "2020-06-10T08:38:52.668333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel ORG\n",
      "Ian PERSON\n",
      "Sydney GPE\n",
      "315 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Show named entities and their labels\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a custom named entity in spaCy\n",
    "If spaCy's built-in named entities aren't enough, you can make your own using spaCy's EntityRuler() class.\n",
    "\n",
    "EntityRuler() allows you to create your own entities to add to a spaCy pipeline.\n",
    "\n",
    "You start by creating an instance of EntityRuler() and passing it the current pipeline, nlp.\n",
    "\n",
    "You can then call add_patterns() on the instance and pass it a dictionary of the text pattern you'd like to label with an entity.\n",
    "\n",
    "Once you've setup a pattern you can add it the nlp pipeline using add_pipe().\n",
    "\n",
    "Since Acme is a technology company, you decide to tag the pattern \"smartphone\" with the \"PRODUCT\" entity tag.\n",
    "\n",
    "spaCy has been imported and a doc already exists containing the transcribed text from call_4_channel_2.wav."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:40:08.614494Z",
     "start_time": "2020-06-10T08:40:08.600494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel ORG\n",
      "Ian PERSON\n",
      "Sydney GPE\n",
      "315 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Import EntityRuler class\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Define pattern for new entity\n",
    "ruler.add_patterns([{\"label\": \"PRODUCT\", \"pattern\": \"smartphone\"}])\n",
    "\n",
    "# Update existing pipeline\n",
    "nlp.add_pipe(ruler, before=\"ner\")\n",
    "\n",
    "# Test new entity\n",
    "for entity in doc.ents:\n",
    "  print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying transcribed speech with Sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing audio files for text classification\n",
    "Acme are very impressed with your work so far. So they've sent over two more folders of audio files.\n",
    "\n",
    "One folder is called pre_purchase and contains audio snippets from customers who are pre-purchase, like pre_purchase_audio_25.mp3.\n",
    "\n",
    "And the other is called post_purchase and contains audio snippets from customers who have made a purchase (post-purchase), like post_purchase_audio_27.mp3.\n",
    "\n",
    "Upon inspecting the files you find there's about 50 in each and they're in the .mp3 format.\n",
    "\n",
    "Acme want to know if you can build a classifier to classify future calls. You tell them you sure can.\n",
    "\n",
    "So in this exercise, you'll go through each folder and convert the audio files to .wav format using convert_to_wav() so you can transcribe them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:46:21.283012Z",
     "start_time": "2020-06-10T08:46:21.271949Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post_purchase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e199995ed54d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert post purchase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpost_purchase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Converting {file} to .wav...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mconvert_to_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'post_purchase' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert post purchase\n",
    "for file in post_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)\n",
    "\n",
    "# Convert pre purchase\n",
    "for file in pre_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing phone call excerpts\n",
    "In this exercise, we'll transcribe the audio files we converted to .wav format to text using transcribe_audio().\n",
    "\n",
    "Since there's lots of them and there could be more, we'll build a function create_test_list() which takes a list of filenames of audio files as input and goes through each file transcribing the text.\n",
    "\n",
    "create_test_list() uses our transcribe_audio() function we created earlier and returns a list of strings containing the transcribed text from each audio file.\n",
    "\n",
    "pre_purchase_wav_files and post_purchase_wav_files are lists of audio snippet filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:47:15.903841Z",
     "start_time": "2020-06-10T08:47:15.892809Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-218a6d6eb41e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcreate_text_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'folder' is not defined"
     ]
    }
   ],
   "source": [
    "def create_text_list(folder):\n",
    "  # Create empty list\n",
    "  text_list = []\n",
    "  \n",
    "  # Go through each file\n",
    "  for file in folder:\n",
    "    # Make sure the file is .wav\n",
    "    if file.endswith(\".wav\"):\n",
    "      print(f\"Transcribing file: {file}...\")\n",
    "      \n",
    "      # Transcribe audio and append text to list\n",
    "      text_list.append(transcribe_audio(file))   \n",
    "  return text_list\n",
    "\n",
    "create_text_list(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe post and pre purchase text\n",
    "post_purchase_text = create_text_list(post_purchase_wav_files)\n",
    "pre_purchase_text = create_text_list(pre_purchase_wav_files)\n",
    "\n",
    "# Inspect the first transcription of post purchase\n",
    "print(post_purchase_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing transcribed phone call data\n",
    "We're almost ready to build a text classifier. But right now, all of our transcribed text data is in two lists, pre_purchase_text and post_purchase_text.\n",
    "\n",
    "To organize it better for building a text classifier as well as for future use, we'll put it together into a pandas DataFrame.\n",
    "\n",
    "To start we'll import pandas as pd then we'll create a post purchase dataframe, post_purchase_df using pd.DataFrame().\n",
    "\n",
    "We'll pass pd.DataFrame() a dictionary containing a \"label\" key with a value of \"post_purchase\" and a \"text\" key with a value of our post_purchase_text list.\n",
    "\n",
    "We'll do the same for pre_purchase_df except with pre_purchase_text.\n",
    "\n",
    "To have all the data in one place, we'll use pd.concat() and pass it the pre and post purchase DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:49:31.264336Z",
     "start_time": "2020-06-10T08:49:31.255276Z"
    },
    "code_folding": [
     1,
     47
    ]
   },
   "outputs": [],
   "source": [
    "pre_purchase_text = ['yeah hi John just calling in regards to a recent order I just placed I found a cheaper product online and I was wondering if I could cancel that',\n",
    " \"I was looking online it says that you're only size is available a large and small I was wondering if you'll have any mediums in soon\",\n",
    " 'hi I was just wondering if you have the extra large tea and blue',\n",
    " 'yeah hey Steve just calling in regards to a recent order I just placed I was wondering if I could cancel that order',\n",
    " 'hi I just ordered a new phone and I was just wondering if I could cancel out order and organise a refund',\n",
    " 'hi I just ordered a new t-shirt and I was wondering if I could cancel an order and organise a refund',\n",
    " 'accidentally made some errors and order I recently just placed I was wondering if you could help me',\n",
    " \"I just placed an order online and I was just wondering when I'll get my confirmation email\",\n",
    " \"hey mate I just finished paying for my order and I was just wondering when I'm going to get that email to confirm it\",\n",
    " 'hey I was wondering if you know where my new phone is that I just recently ordered',\n",
    " 'do you currently offer any new promotions at the moment',\n",
    " \"hi I just pre-ordered the nudity and this is my order number but doctor I was just wondering if you know where abouts it isn't shipment\",\n",
    " 'your hi Jacob looking to make an order but just have a few questions regarding some products that you have online',\n",
    " 'hi I just recently placed an order with your company I was just wondering if you know the status of my shipment',\n",
    " \"Archie thank god I'm free been on hold for the last 30 minutes yeah got a couple of complaints made about this order I just posted\",\n",
    " \"hi just calling in regards to my order on November the 3rd I was just wondering when that's going to leave your office\",\n",
    " \"just looking to get some more information on the current promotions you're offering right now before I place my order\",\n",
    " \"hi I recently ordered a new phone and I'm just wondering where I could find my reference number for the delivery\",\n",
    " 'hey mate just looking to make some alterations to my order I just placed',\n",
    " 'hey just looking to place this order but I see that you have a promotion still running can you give me some more details behind this promotion',\n",
    " \"hi I placed an order a couple days ago and I was just wondering why my tracking number isn't working\",\n",
    " 'hi I just realised I ordered the wrong computer I was wondering if I could just cancel that and organise a refund',\n",
    " \"yeah I just placed an all this you guys and I was wondering if I could change a few things before it's shift out\",\n",
    " \"how's it going after I just placed an order with you guys and I accidentally sent it to the wrong address can you please help me change this\",\n",
    " \"hey Polly just looking to place an order but before I proceed I'm just wondering if this offer still stands\",\n",
    " 'yeah hi Tommy I just placed an order with you guys but I use the wrong payment processing method I was wondering if I could change that',\n",
    " 'hi Michael just looking to enquire about a few things before I placed an order I was wondering if you could help me',\n",
    " 'hi I saw your new phone on your website I was wondering if you have any setup tips for',\n",
    " \"I just ordered the new remote control car off you website I was just didn't see how many horsepower it has can you tell me\",\n",
    " 'hi just about to order these shoes online I was just wondering if you have any different sizes in store',\n",
    " 'I just placed an order and I was wondering if I could change my shipping time from standard business days to rush if possible',\n",
    " 'hey I just ordered the new phone and I was wondering if I could get airpods put into that order just before you guys send it',\n",
    " 'hi Jacob I just placed an order with you guys but I found the same product online it and other store for a cheaper price I was wondering if you could price match it or could I cancel this order',\n",
    " 'it says here you have the iPhone x l and X I was wondering if you still stock the iPhone 10',\n",
    " 'hey I was just looking online at your shoes and I was wondering if you have this brand in Pink',\n",
    " 'I just placed an order I was wondering how long shipping time would be expected to be',\n",
    " \"hey mate just have a few questions regarding the recent order I just posted it shows that it's coming from overseas however when I looked at the Australian soccer shop online it says that there's current stock in store for the Australian store\",\n",
    " 'hi I just ordered some shoes and I was just wondering if I could cancel that order and make a refund',\n",
    " 'hey I just ordered the blue and yellow shoes off your website and I was wondering if I could cancel that order and organise a refund',\n",
    " 'hey so I just placed an order with your company and I was just wondering where I can find my reference number',\n",
    " 'hey I was just wondering about the sizing on your shirts it says us as how does that relate to AUD',\n",
    " \"hi Tony I just placed an order I'm currently having a few problems I was wondering if you could help me\",\n",
    " 'yeah hi David I just placed an order online and I was wondering if I could make an alteration to that order before you send it off',\n",
    " 'hi I was just looking at finding a new phone I was wondering if you could recommend anything to me',\n",
    " 'I I just ordered the green and blue shoes off your website and I was wondering if I could add a shirt to my order before you send it']\n",
    "\n",
    "post_purchase_text = ['hey man I just bought a product from you guys and I think is amazing but I leave a little help setting it up',\n",
    " 'these clothes I just bought from you guys too small is there any way I can change the size',\n",
    " \"I recently got these pair of shoes but they're too big can I change the size\",\n",
    " \"I bought a pair of pants from you guys but they're way too small\",\n",
    " \"I bought a pair of pants and they're the wrong colour is there any chance I can change that\",\n",
    " \"hey mate how you doing I'm just calling in regards the product that god it's faulty and doesn't work\",\n",
    " \"just wondering if there's any tutorials on how to set up my device I just received\",\n",
    " \"hey I'm just not happy with the product that you guys send me there any chance I can swap it out for another one\",\n",
    " 'I bought a pair of pants from you guys and they are just a bit too long do you guys do Hemi',\n",
    " 'is there anybody that can help me set up this product or any how to use',\n",
    " \"hey mate I just bought a product from you guys and I'm just unhappy with the pop the product can I return it\",\n",
    " \"just received the product from you guys and it didn't meet my expectations can I please get a refund\",\n",
    " \"what's the process I have to go through to send my product back for a swap\",\n",
    " \"hey mate how are you doing just wanting to know if there's any support I can get on this device how to set it up\",\n",
    " \"what's your refund policy on items that I've purchased from you guys\",\n",
    " \"hey how we doing I just put a cat from you guys and it's just the Wrong Colours is there any chance I can change that\",\n",
    " \"call me on to talk about a package I got yesterday it's I got it but I need to do I need some help with setting it up\",\n",
    " \"I got my order yesterday and the order number is 1863 3845 I'm just calling up to to check some more details on that\",\n",
    " 'I would have a couple of things from you guys the other day and two it two of them two of them and great and I love them but the other one is is not the right thing',\n",
    " \"yeah hello I'm just wondering if I can speak to someone about an order I received yesterday\",\n",
    " 'wrong package delivered',\n",
    " \"hey I ordered something yesterday and it arrived it arrived this morning but it seems like there's a few a few extra things in there that I didn't really order is there someone that I can talk to you to fix this up\",\n",
    " \"hey I bought something from your website the other day and it arrived but it's it's not the thing that I ordered is there someone I can talk to her to fix this up\",\n",
    " \"hello someone from your team delivered my package today but it's it's got a problem with it\",\n",
    " \"my shipment arrived this afternoon but it's wrong size is there anyone I can talk to you to change it\",\n",
    " 'I just bought a item from you guys and ID want to know if I can swap it for a different colour',\n",
    " \"hey I received my order but it's the wrong size can I get a refund please\",\n",
    " \"hey my order arrived today but it's it's there's a it's I don't think it's the one that I ordered I check the receipt and it doesnt match what what a right\",\n",
    " \"hey I'm calling up to to see if I can talk to someone to help with her a shipment that I received yesterday\",\n",
    " \"I just received this device and I'd love some supported to be able to set it up\",\n",
    " \"I just bought a product from you guys and I wouldn't want to know if I can send it back to get a colour change\",\n",
    " \"I purchase something from your online store yesterday but the receipt didn't come through can can I get another receipt emailed please\",\n",
    " 'the product arrived and there was a few things in the box but two of them the wrong is there someone I can talk to about fixing up my order',\n",
    " \"I'm just happy with the colour that I got from you guys so is there any chance I can change it for a different one\",\n",
    " \"a couple of days ago I got a message saying that my package have been delivered it wasn't delivered that day but it still hasn't arrived there someone I can talk to about my order\",\n",
    " \"my shipment arrived yesterday but it's not the right thing is there someone I can talk to you to fix it up\",\n",
    " \"my shipment arrived yesterday but it's not the right thing is there someone I can talk to you to fix it up\",\n",
    " \"my package was supposed to be delivered yesterday but it it didn't arrive is there someone I can talk to about my order\",\n",
    " \"my package was supposed to be delivered yesterday but it it didn't arrive is there someone I can talk to about my order\",\n",
    " \"I bought a hat from you guys and it's just too big is there anyway I can get it down size and what's your policies on that\",\n",
    " 'calling in regards to the order I just got would love some support',\n",
    " \"my order a 64321 arrived this morning but it's something wrong with it is there someone I can talk to to fix it\",\n",
    " \"yeah hello someone this morning delivered a package but I think it's I think it's not the right one that I ordered is there someone I can talk to you too to change it\",\n",
    " \"on the box that you sent me yesterday arrived but it's damaged the someone I can talk to her about replacement\",\n",
    " \"I've just bought a product can you guys and I want to know what your return keys and Caesar\",\n",
    " \"my order a 64321 arrived this morning but it's something wrong with it is there someone I can talk to to fix it\",\n",
    " \"hey my name is Daniel I received my shipment yesterday but it's wrong can I change it\",\n",
    " \"all the things I received the my order yesterday would damaged I'm not sure what happened to delivery is there someone that can give me a hand\",\n",
    " 'the shipment I received is wrong',\n",
    " \"yeah hey I need I need some help with her with an order that I ordered the other day it it came and it wasn't it wasn't correct\",\n",
    " \"yeah hello someone this morning delivered a package but I think it's I think it's not the right one that I ordered is there someone I can talk to you too to change it\",\n",
    " 'the shipment I received is wrong',\n",
    " \"yeah hello I'm just wondering if I can speak to someone about an order I received yesterday\",\n",
    " \"my shipment arrived this afternoon but it's wrong size is there anyone I can talk to you to change it\",\n",
    " \"all the things I received the my order yesterday would damaged I'm not sure what happened to delivery is there someone that can give me a hand\",\n",
    " 'hey mate the must have been a problem with the shipping because the product I just received from you is damaged',\n",
    " \"hey mate how you doing just calling in regards to the phone I just purchased from you guys faulty not working and now he's damaged on the way here\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:50:28.894775Z",
     "start_time": "2020-06-10T08:50:28.887292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           label                                               text\n",
      "0  post_purchase  hey man I just bought a product from you guys ...\n",
      "1  post_purchase  these clothes I just bought from you guys too ...\n",
      "2  post_purchase  I recently got these pair of shoes but they're...\n",
      "3  post_purchase  I bought a pair of pants from you guys but the...\n",
      "4  post_purchase  I bought a pair of pants and they're the wrong...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make dataframes with the text\n",
    "post_purchase_df = pd.DataFrame({\"label\": \"post_purchase\",\n",
    "                                 \"text\": post_purchase_text})\n",
    "pre_purchase_df = pd.DataFrame({\"label\": \"pre_purchase\",\n",
    "                                \"text\": pre_purchase_text})\n",
    "\n",
    "# Combine DataFrames\n",
    "df = pd.concat([post_purchase_df, pre_purchase_df])\n",
    "\n",
    "# Print the combined DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a spoken language text classifier\n",
    "Now you've transcribed some customer call audio data, we'll build a model to classify whether the text from the customer call is pre_purchase or post_purchase.\n",
    "\n",
    "We've got 45 examples of pre_purchase calls and 57 examples of post_purchase calls.\n",
    "\n",
    "The data the model will train on is stored in train_df and the data the model will predict on is stored in test_df.\n",
    "\n",
    "Try printing the .head() of each of these to the console.\n",
    "\n",
    "We'll build an sklearn pipeline using CountVectorizer() and TfidfTransformer() to convert our text samples to numbers and then use a MultinomialNB() classifier to learn what category each sample belongs to.\n",
    "\n",
    "This model will work well on our small example here but for larger amounts of text, you may want to consider something more sophisticated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:54:47.433205Z",
     "start_time": "2020-06-10T08:54:46.616907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'train_df.csv': 'https://file.io/YhAD08rE'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10372    0 10372    0     0  16055      0 --:--:-- --:--:-- --:--:-- 16030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(train_df)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'train_df.csv': 'https://file.io/YhAD08rE'}}\n",
    "\"\"\"\n",
    "prefixToc='4.4'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(prefix+'train_df.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:56:53.500437Z",
     "start_time": "2020-06-10T08:56:52.195209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'test_df.csv': 'https://file.io/0Y7QdGXP'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2709    0  2709    0     0   2625      0 --:--:--  0:00:01 --:--:--  2625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(test_df)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'test_df.csv': 'https://file.io/0Y7QdGXP'}}\n",
    "\"\"\"\n",
    "prefixToc='4.4'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "test_df = pd.read_csv(prefix+'test_df.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:55:35.775150Z",
     "start_time": "2020-06-10T08:55:34.057322Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:55:36.693257Z",
     "start_time": "2020-06-10T08:55:36.671697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the text_classifier as an sklearn pipeline\n",
    "text_classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(train_df.text, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:57:10.995228Z",
     "start_time": "2020-06-10T08:57:10.987706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is 90.47619047619048% accurate\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the MultinomialNB model\n",
    "predicted = text_classifier.predict(test_df.text)\n",
    "accuracy = 100 * np.mean(predicted == test_df.label)\n",
    "print(f'The model is {accuracy}% accurate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datacamp] *",
   "language": "python",
   "name": "conda-env-datacamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
