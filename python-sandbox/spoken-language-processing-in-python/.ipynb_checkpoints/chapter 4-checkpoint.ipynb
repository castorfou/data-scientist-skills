{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating transcription helper functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting audio to the right format\n",
    "Acme Studios have asked you to do a proof of concept to find out more about their audio files.\n",
    "\n",
    "After exploring them briefly, you find there's a few calls but they're in the wrong file format for transcription.\n",
    "\n",
    "As you'll be interacting with many audio files, you decide to begin by creating some helper functions.\n",
    "\n",
    "The first one, convert_to_wav(filename) takes a file path and uses PyDub to convert it from a non-wav format to .wav format.\n",
    "\n",
    "Once it's built, we'll use the function to convert Acme's first call, call_1.mp3, from .mp3 format to .wav.\n",
    "\n",
    "PyDub's AudioSegment class has already been imported. Remember, to work with non-wav files, you'll need ffmpeg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:35:30.645638Z",
     "start_time": "2020-05-29T07:35:25.436551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_1.mp3': 'https://file.io/LR9nRLl5'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  322k    0  322k    0     0   312k      0 --:--:--  0:00:01 --:--:--  312k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_1.mp3')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_1.mp3': 'https://file.io/LR9nRLl5'}}\n",
    "\"\"\"\n",
    "prefixToc = '1.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:36:18.753868Z",
     "start_time": "2020-05-29T07:36:18.721319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import AudioSegment from Pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:42:31.902108Z",
     "start_time": "2020-05-29T07:42:27.916727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data_from_datacamp/chapter 4-Exercise1.1_call_1.mp3 to data_from_datacamp/chapter 4-Exercise1.1_call_1.wav...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create function to convert audio file to wav\n",
    "def convert_to_wav(filename):\n",
    "  \"\"\"Takes an audio file of non .wav format and converts to .wav\"\"\"\n",
    "  # Import audio file\n",
    "  audio = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Create new filename\n",
    "  new_filename = os.path.splitext(filename)[0] + \".wav\"\n",
    "  \n",
    "  # Export file as .wav\n",
    "  audio.export(new_filename, format='wav')\n",
    "  print(f\"Converting {filename} to {new_filename}...\")\n",
    " \n",
    "# Test the function\n",
    "convert_to_wav(prefix+'call_1.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding PyDub stats\n",
    "You decide it'll be helpful to know the audio attributes of any given file easily. This will be especially helpful for finding out how many channels an audio file has or if the frame rate is adequate for transcription.\n",
    "\n",
    "In this exercise, we'll create show_pydub_stats() which takes a filename of an audio file as input. It then imports the audio as a PyDub AudioSegment instance and prints attributes such as number of channels, length and more.\n",
    "\n",
    "It then returns the AudioSegment instance so it can be used later on.\n",
    "\n",
    "We'll use our function on the newly converted .wav file, call_1.wav\n",
    "\n",
    "AudioSegment has already imported from PyDub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:42:46.213858Z",
     "start_time": "2020-05-29T07:42:46.202828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 2\n",
      "Length (ms): 54888\n"
     ]
    }
   ],
   "source": [
    "def show_pydub_stats(filename):\n",
    "  \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
    "  # Create AudioSegment instance\n",
    "  audio_segment = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Print audio attributes and return AudioSegment instance\n",
    "  print(f\"Channels: {audio_segment.channels}\")\n",
    "  print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "  print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "  print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "  print(f\"Length (ms): {len(audio_segment)}\")\n",
    "  return audio_segment\n",
    "\n",
    "# Try the function\n",
    "call_1_audio_segment = show_pydub_stats(prefix+'call_1.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing audio with one line\n",
    "Alright, now you've got functions to convert audio files and find out their attributes, it's time to build one to transcribe them.\n",
    "\n",
    "In this exercise, you'll build transcribe_audio() which takes a filename as input, imports the filename using speech_recognition's AudioFile class and then transcribes it using recognize_google().\n",
    "\n",
    "You've seen these functions before but now we'll put them together so they're accessible in a function.\n",
    "\n",
    "To test it out, we'll transcribe Acme's first call, \"call_1.wav\".\n",
    "\n",
    "speech_recognition has been imported as sr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:45:48.378894Z",
     "start_time": "2020-05-29T07:45:48.362814Z"
    }
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:47:09.727294Z",
     "start_time": "2020-05-29T07:46:52.988757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello welcome to acne Studios support line my name is Daniel how can I best help you pay Daniel this is John I've recently bought a smartphone from you guys 3 weeks ago and already having issues with it oh no that's not good to hear John let's let's get your serial number and then we can we can set up a wider fix it for you get one second grandma serial number it is for 17 very displays how long do you reckon it's going well done we're going to try our best to get the same number of startup disk support case just really really really really I've been trying to contact support from past 3-4 days now and have been put on hold for more than an hour and a half not really happy I can't wait to get this fixed as fast\n"
     ]
    }
   ],
   "source": [
    "def transcribe_audio(filename):\n",
    "  \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "  # Setup a recognizer instance\n",
    "  recognizer = sr.Recognizer()\n",
    "  \n",
    "  # Import the audio file and convert to audio data\n",
    "  audio_file = sr.AudioFile(filename)\n",
    "  with audio_file as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "  \n",
    "  # Return the transcribed text\n",
    "  return recognizer.recognize_google(audio_data)\n",
    "\n",
    "# Test the function\n",
    "print(transcribe_audio(prefix+'call_1.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the helper functions you've built\n",
    "Okay, now we've got some helper functions ready to go, it's time to put them to use!\n",
    "\n",
    "You'll first use convert_to_wav() to convert Acme's call_1.mp3 to .wav format and save it as call_1.wav\n",
    "\n",
    "Using show_pydub_stats() you find call_1.wav has 2 channels so you decide to split them using PyDub's split_to_mono(). Acme tells you the customer channel is likely channel 2. So you export channel 2 using PyDub's .export().\n",
    "\n",
    "Finally, you'll use transcribe_audio() to transcribe channel 2 only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:52:00.344702Z",
     "start_time": "2020-05-29T07:51:58.422979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_1.mp3': 'https://file.io/vegb3SL2'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  644k    0  644k    0     0   401k      0 --:--:--  0:00:01 --:--:--  401k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_1.mp3')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_1.mp3': 'https://file.io/vegb3SL2'}}\n",
    "\"\"\"\n",
    "prefixToc = '1.4'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:52:03.649291Z",
     "start_time": "2020-05-29T07:52:02.394761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data_from_datacamp/chapter 4-Exercise1.4_call_1.mp3 to data_from_datacamp/chapter 4-Exercise1.4_call_1.wav...\n",
      "Channels: 2\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 4\n",
      "Length (ms): 54888\n"
     ]
    }
   ],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(prefix+'call_1.mp3')\n",
    "\n",
    "# Check the stats of new file\n",
    "call_1 = show_pydub_stats(prefix+'call_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:52:53.323447Z",
     "start_time": "2020-05-29T07:52:53.288394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='data_from_datacamp/chapter 4-Exercise1.4_call_1_channel_2.wav'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split call_1 to mono\n",
    "call_1_split = call_1.split_to_mono()\n",
    "\n",
    "# Export channel 2 (the customer channel)\n",
    "call_1_split[1].export(prefix+\"call_1_channel_2.wav\",\n",
    "                       format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:53:51.551043Z",
     "start_time": "2020-05-29T07:53:38.552618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey Daniel this is John I've recently bought a smartphone from your eyes 3 weeks ago and already having issues with that one second grandma serial number it is for 177 I'm very displays how long do you reckon it's going to take me about an hour I'm just just really really really really just I've been trying to contact reports and past past 3-4 days now and have been put on hold Morgan and not really happy I can't get this issue fixed as fast as possible\n"
     ]
    }
   ],
   "source": [
    "# Transcribe the single channel\n",
    "print(transcribe_audio(prefix+\"call_1_channel_2.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on spoken language text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing sentiment of a phone call\n",
    "Once you've transcribed the text from an audio file, it's possible to perform natural language processing on the text.\n",
    "\n",
    "In this exercise, we'll use NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner) to analyze the sentiment of the transcribed text of call_2.wav.\n",
    "\n",
    "To transcribe the text, we'll use the transcribe_audio() function we created earlier.\n",
    "\n",
    "Once we have the text, we'll use NLTK's SentimentIntensityAnalyzer() class to obtain a sentiment polarity score.\n",
    "\n",
    ".polarity_scores(text) returns a value for pos (positive), neu (neutral), neg (negative) and compound. Compound is a mixture of the other three values. The higher it is, the more positive the text. Lower means more negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:00:37.514365Z",
     "start_time": "2020-05-29T08:00:33.314709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_2.wav': 'https://file.io/4Sjun5W4'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3297k    0 3297k    0     0   816k      0 --:--:--  0:00:04 --:--:--  816k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_2.wav')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_2.wav': 'https://file.io/4Sjun5W4'}}\n",
    "\"\"\"\n",
    "prefixToc = '2.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:04:18.510627Z",
     "start_time": "2020-05-29T08:04:17.927238Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\F279814\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:08:32.790714Z",
     "start_time": "2020-05-29T08:08:31.047220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'call_2_channel_2.wav': 'https://file.io/5cOeP97R'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3297k    0 3297k    0     0  2082k      0 --:--:--  0:00:01 --:--:-- 2081k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('call_2_channel_2.wav')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'call_2_channel_2.wav': 'https://file.io/5cOeP97R'}}\n",
    "\"\"\"\n",
    "prefixToc = '2.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:04:32.313541Z",
     "start_time": "2020-05-29T08:04:24.116352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello my name is Daniel thank you for calling acne Studios how can I best help you are hi Daniel my name is Sally I've recently purchased a smart phone from you guys and extremely happy with it but I just got to learn a little bit more about the message bank OK Google location but I'm finding it hard I got you on the corner of Edward and Elizabeth according to Google according to the max but damn would you be able to help me in some way because I think I actually walk straight past your shop yeah sure thing or thank you Sally that's good to hear you're enjoying it let me let me find out where the nearest store is for you\n",
      "{'neg': 0.035, 'neu': 0.708, 'pos': 0.257, 'compound': 0.9844}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Let's try it on one of our phone calls\n",
    "call_2_text = transcribe_audio(prefix+'call_2.wav')\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_text)\n",
    "print(sid.polarity_scores(call_2_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:09:04.375814Z",
     "start_time": "2020-05-29T08:08:57.322207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh hi Daniel my name is Billy recently purchased a smartphone from you guys and extremely happy with them I've just got an issue but I've just got to learn a little bit more about the message Frank I had Google location but I'm finding it hard I don't you want the corner of Edward and Elizabeth according to Google according to the maps but would you be able to help me in some way because I think I actually walk straight past your shop\n",
      "{'neg': 0.034, 'neu': 0.867, 'pos': 0.098, 'compound': 0.7553}\n"
     ]
    }
   ],
   "source": [
    "# Transcribe customer channel of call 2\n",
    "call_2_channel_2_text = transcribe_audio(prefix+'call_2_channel_2.wav')\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_channel_2_text)\n",
    "print(sid.polarity_scores(call_2_channel_2_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:10:15.972480Z",
     "start_time": "2020-05-29T08:10:15.969464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import sent tokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:10:35.037352Z",
     "start_time": "2020-05-29T08:10:35.011282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh hi Daniel my name is Billy recently purchased a smartphone from you guys and extremely happy with them I've just got an issue but I've just got to learn a little bit more about the message Frank I had Google location but I'm finding it hard I don't you want the corner of Edward and Elizabeth according to Google according to the maps but would you be able to help me in some way because I think I actually walk straight past your shop\n",
      "{'neg': 0.034, 'neu': 0.867, 'pos': 0.098, 'compound': 0.7553}\n"
     ]
    }
   ],
   "source": [
    "# Split call 2 channel 2 into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:13:57.021461Z",
     "start_time": "2020-05-29T08:13:57.017968Z"
    }
   },
   "outputs": [],
   "source": [
    "call_2_channel_2_paid_api_text = \"Hello and welcome to acme studios. My name's Daniel. How can I best help you? Hi Diane. This is paid on this call up to see the status of my, I'm proctor mortars at three weeks ago, and then service is terrible. Okay, Peter, sorry to hear about that. Hey, Peter, before we go on, do you mind just, uh, is there something going on with your microphone? I can't quite hear you. Is this any better? Yeah, that's much better. And sorry, what was, what was it that you said when you first first started speaking?  So I ordered a product from you guys three weeks ago and, uh, it's, it's currently on July 1st and I haven't received a provocative, again, three weeks to a full four weeks down line. This service is terrible. Okay. Well, what's your order id? I'll, uh, I'll start looking into that for you. Six, nine, eight, seven five. Okay. Thank you.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T08:14:09.851322Z",
     "start_time": "2020-05-29T08:14:09.842294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome to acme studios.\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.4588}\n",
      "My name's Daniel.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "How can I best help you?\n",
      "{'neg': 0.0, 'neu': 0.303, 'pos': 0.697, 'compound': 0.7845}\n",
      "Hi Diane.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "This is paid on this call up to see the status of my, I'm proctor mortars at three weeks ago, and then service is terrible.\n",
      "{'neg': 0.114, 'neu': 0.886, 'pos': 0.0, 'compound': -0.4767}\n",
      "Okay, Peter, sorry to hear about that.\n",
      "{'neg': 0.159, 'neu': 0.61, 'pos': 0.232, 'compound': 0.1531}\n",
      "Hey, Peter, before we go on, do you mind just, uh, is there something going on with your microphone?\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "I can't quite hear you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Is this any better?\n",
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "Yeah, that's much better.\n",
      "{'neg': 0.0, 'neu': 0.282, 'pos': 0.718, 'compound': 0.6249}\n",
      "And sorry, what was, what was it that you said when you first first started speaking?\n",
      "{'neg': 0.08, 'neu': 0.92, 'pos': 0.0, 'compound': -0.0772}\n",
      "So I ordered a product from you guys three weeks ago and, uh, it's, it's currently on July 1st and I haven't received a provocative, again, three weeks to a full four weeks down line.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "This service is terrible.\n",
      "{'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.4767}\n",
      "Okay.\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
      "Well, what's your order id?\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "I'll, uh, I'll start looking into that for you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Six, nine, eight, seven five.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Okay.\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
      "Thank you.\n",
      "{'neg': 0.0, 'neu': 0.286, 'pos': 0.714, 'compound': 0.3612}\n"
     ]
    }
   ],
   "source": [
    "# Split channel 2 paid text into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_paid_api_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition on transcribed text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datacamp] *",
   "language": "python",
   "name": "conda-env-datacamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
