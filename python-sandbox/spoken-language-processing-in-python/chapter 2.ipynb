{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpeechRecognition Python library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sing the SpeechRecognition library\n",
    "To save typing speech_recognition every time, we'll import it as sr.\n",
    "\n",
    "We'll also setup an instance of the Recognizer class to use later.\n",
    "\n",
    "The energy_threshold is a number between 0 and 4000 for how much the Recognizer class should listen to an audio file.\n",
    "\n",
    "energy_threshold will dynamically adjust whilst the recognizer class listens to audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T07:46:02.030281Z",
     "start_time": "2020-05-05T07:46:01.972721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the speech_recognition library\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Create an instance of the Recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Set the energy threshold\n",
    "recognizer.energy_threshold = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Recognizer class\n",
    "Now you've created an instance of the Recognizer class we'll use the recognize_google() method on it to access the Google web speech API and turn spoken language into text.\n",
    "\n",
    "recognize_google() requires an argument audio_data otherwise it will return an error.\n",
    "\n",
    "US English is the default language. If your audio file isn't in US English, you can change the language with the language argument. A list of language codes can be seen here.\n",
    "\n",
    "An audio file containing English speech has been imported as clean_support_call_audio. You can listen to the audio file here. SpeechRecognition has also been imported as sr.\n",
    "\n",
    "To avoid hitting the API request limit of Google's web API, we've mocked the Recognizer class to work with our audio files. This means some functionality will be limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:10:20.438953Z",
     "start_time": "2020-05-05T08:10:17.535411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'clean_support_call.wav': 'https://file.io/d6HVQN1G'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  902k    0  902k    0     0   461k      0 --:--:--  0:00:01 --:--:--  461k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('clean_support_call.wav')\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'clean_support_call.wav': 'https://file.io/d6HVQN1G'}}\n",
    "\"\"\"\n",
    "prefixToc = '1.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:35:47.090944Z",
     "start_time": "2020-05-05T08:35:47.076903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Read audio data\n",
    "with sr.AudioFile(prefix+'clean_support_call.wav') as source:\n",
    "    clean_support_call_audio = recognizer.record(source)  # read the entire audio file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:35:48.823541Z",
     "start_time": "2020-05-05T08:35:48.038475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I'd like to get some help setting up my account please\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Transcribe the support call audio\n",
    "text = recognizer.recognize_google(\n",
    "  audio_data=clean_support_call_audio, \n",
    "  language='en-US')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test avec enregistrement micro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackabuse.com/introduction-to-speech-recognition-with-python/\n",
    "\n",
    "conda install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:40:31.896985Z",
     "start_time": "2020-05-05T08:40:25.226762Z"
    }
   },
   "outputs": [],
   "source": [
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:40:47.816926Z",
     "start_time": "2020-05-05T08:40:47.801267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mappeur de sons Microsoft - Input',\n",
       " 'Microphone Array (Realtek High ',\n",
       " 'Mappeur de sons Microsoft - Output',\n",
       " 'Speaker/HP (Realtek High Defini',\n",
       " 'Casque ()',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Réseau de microphones (Realtek HD Audio Mic input)',\n",
       " 'Casque (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(TAOTRONICS SoundSurge 46))',\n",
       " 'Casque (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(TAOTRONICS SoundSurge 46))']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:45:25.067330Z",
     "start_time": "2020-05-05T08:45:21.140845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak Please\n",
      "fin d'enregistrement...\n"
     ]
    }
   ],
   "source": [
    "with mic as audio_file:\n",
    "    print(\"Speak Please\")\n",
    "\n",
    "    recognizer.adjust_for_ambient_noise(audio_file)\n",
    "    audio = recognizer.listen(audio_file)\n",
    "\n",
    "    print(\"fin d'enregistrement...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:45:37.154706Z",
     "start_time": "2020-05-05T08:45:37.150694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioData"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:35:18.900370Z",
     "start_time": "2020-05-05T09:35:14.910816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parlez svp\n",
      "Converting Speech to Text...\n",
      "Error: recognition request failed: Forbidden\n"
     ]
    }
   ],
   "source": [
    "with mic as audio_file:\n",
    "    print(\"Parlez svp\")\n",
    "\n",
    "    recognizer.adjust_for_ambient_noise(audio_file)\n",
    "    audio = recognizer.listen(audio_file)\n",
    "\n",
    "    print(\"Converting Speech to Text...\")\n",
    "\n",
    "    try:\n",
    "        print(\"You said: \" + recognizer.recognize_google(audio, 'en-US'))\n",
    "    except Exception as e:\n",
    "        print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading audio files with SpeechRecognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From AudioFile to AudioData\n",
    "As you saw earlier, there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "\n",
    "In this exercise, we'll import the clean_support_call.wav audio file and get it ready to be recognized.\n",
    "\n",
    "We first read our audio file using the AudioFile class. But the recognize_google() method requires an input of type AudioData.\n",
    "\n",
    "To convert our AudioFile to AudioData, we'll use the Recognizer class's method record() along with a context manager. The record() method takes an AudioFile as input and converts it to AudioData, ready to be used with recognize_google().\n",
    "\n",
    "SpeechRecognition has already been imported as sr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:06:10.692005Z",
     "start_time": "2020-05-05T09:06:09.267862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I'd like to get some help setting up my account please\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Convert audio to AudioFile\n",
    "clean_support_call = sr.AudioFile(prefix+'clean_support_call.wav')\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with clean_support_call as source:\n",
    "    clean_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(clean_support_call_audio,\n",
    "                                   language=\"en-US\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording the audio we need\n",
    "Sometimes you may not want the entire audio file you're working with. The duration and offset parameters of the record() method can help with this.\n",
    "\n",
    "After exploring your dataset, you find there's one file, imported as nothing_at_end which has 30-seconds of silence at the end and a support call file, imported as out_of_warranty has 3-seconds of static at the front.\n",
    "\n",
    "Setting duration and offset means the record() method will record up to duration audio starting at offset. They're both measured in seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:15:02.557871Z",
     "start_time": "2020-05-05T09:14:54.992440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'30_seconds_of_nothing.wav': 'https://file.io/4NjpePKk', 'static_out_of_warranty.wav': 'https://file.io/gcaUrCI7'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2239k    0 2239k    0     0   523k      0 --:--:--  0:00:04 --:--:--  523k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1804k    0 1804k    0     0   606k      0 --:--:--  0:00:02 --:--:--  606k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('30_seconds_of_nothing.wav')\n",
    "uploadToFileIO_pushto_fileio('static_out_of_warranty.wav')\n",
    "\n",
    "{\"success\":true,\"key\":\"4NjpePKk\",\"link\":\"https://file.io/4NjpePKk\",\"expiry\":\"14 days\"}\n",
    "{\"success\":true,\"key\":\"gcaUrCI7\",\"link\":\"https://file.io/gcaUrCI7\",\"expiry\":\"14 days\"}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'30_seconds_of_nothing.wav': 'https://file.io/4NjpePKk', \n",
    "'static_out_of_warranty.wav': 'https://file.io/gcaUrCI7'}}\n",
    "\"\"\"\n",
    "prefixToc = '2.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:30:57.091909Z",
     "start_time": "2020-05-05T09:30:57.087942Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_audio_from_wav(filename):\n",
    "    source_wav = sr.AudioFile(filename)\n",
    "    with source_wav as source:\n",
    "        return recognizer.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:19:06.685940Z",
     "start_time": "2020-05-05T09:19:06.653855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert audio to AudioFile\n",
    "nothing_at_end_wav = sr.AudioFile(prefix+'30_seconds_of_nothing.wav')\n",
    "# Convert AudioFile to AudioData\n",
    "with nothing_at_end_wav as source:\n",
    "    nothing_at_end = recognizer.record(source)\n",
    "\n",
    "# Convert audio to AudioFile\n",
    "out_of_warranty_wav = sr.AudioFile(prefix+'static_out_of_warranty.wav')\n",
    "# Convert AudioFile to AudioData\n",
    "with out_of_warranty_wav as source:\n",
    "    out_of_warranty = recognizer.record(source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:19:19.939085Z",
     "start_time": "2020-05-05T09:19:19.928045Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d27cd4ef84fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert AudioFile to AudioData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mnothing_at_end\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     nothing_at_end_audio = recognizer.record(source,\n\u001b[0;32m      4\u001b[0m                                              \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                              offset=None)\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "with nothing_at_end as source:\n",
    "    nothing_at_end_audio = recognizer.record(source,\n",
    "                                             duration=10,\n",
    "                                             offset=None)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(nothing_at_end_audio,\n",
    "                                   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:21:17.281928Z",
     "start_time": "2020-05-05T09:21:17.269866Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0fe060194f02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert AudioFile to AudioData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mout_of_warranty\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     static_art_start_audio = recognizer.record(source,\n\u001b[0;32m      4\u001b[0m                                                \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                offset=3)\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "with out_of_warranty as source:\n",
    "    static_art_start_audio = recognizer.record(source,\n",
    "                                               duration=None,\n",
    "                                               offset=3)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(static_art_start_audio,\n",
    "                                   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with different kinds of audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different kinds of audio\n",
    "Now you've seen an example of how the Recognizer class works. Let's try a few more. How about speech from a different language?\n",
    "\n",
    "What do you think will happen when we call the recognize_google() function on a Japanese version of good_morning.wav (japanese_audio)?\n",
    "\n",
    "The default language is \"en-US\", are the results the same with the \"ja\" tag?\n",
    "\n",
    "How about non-speech audio? Like this leopard roaring (leopard_audio).\n",
    "\n",
    "Or speech where the sounds may not be real words, such as a baby talking (charlie_audio)?\n",
    "\n",
    "To familiarize more with the Recognizer class, we'll look at an example of each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:29:12.482532Z",
     "start_time": "2020-05-05T09:29:05.421223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'charlie.wav': 'https://file.io/aOAxAIEu', 'japanese_good_morning.wav': 'https://file.io/IIe7UoDf', 'leopard.wav': 'https://file.io/8o17be2D'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1550k    0 1550k    0     0   437k      0 --:--:--  0:00:03 --:--:--  437k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  341k    0  341k    0     0   239k      0 --:--:--  0:00:01 --:--:--  239k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  255k    0  255k    0     0   164k      0 --:--:--  0:00:01 --:--:--  164k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('charlie.wav')\n",
    "uploadToFileIO_pushto_fileio('japanese_good_morning.wav')\n",
    "uploadToFileIO_pushto_fileio('leopard.wav')\n",
    "\n",
    "{\"success\":true,\"key\":\"aOAxAIEu\",\"link\":\"https://file.io/aOAxAIEu\",\"expiry\":\"14 days\"}\n",
    "{\"success\":true,\"key\":\"IIe7UoDf\",\"link\":\"https://file.io/IIe7UoDf\",\"expiry\":\"14 days\"}\n",
    "{\"success\":true,\"key\":\"8o17be2D\",\"link\":\"https://file.io/8o17be2D\",\"expiry\":\"14 days\"}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'charlie.wav': 'https://file.io/aOAxAIEu', \n",
    "'japanese_good_morning.wav': 'https://file.io/IIe7UoDf', \n",
    "'leopard.wav': 'https://file.io/8o17be2D'}}\n",
    "\"\"\"\n",
    "prefixToc = '3.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:32:12.606781Z",
     "start_time": "2020-05-05T09:32:12.589736Z"
    }
   },
   "outputs": [],
   "source": [
    "japanese_audio = get_audio_from_wav(prefix+'japanese_good_morning.wav')\n",
    "charlie_audio =  get_audio_from_wav(prefix+'charlie.wav')\n",
    "leopard_audio = get_audio_from_wav(prefix+'leopard.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:32:45.773171Z",
     "start_time": "2020-05-05T09:32:45.028587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio gozaimasu\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text = recognizer.recognize_google(japanese_audio, language='en-US')\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:33:10.779808Z",
     "start_time": "2020-05-05T09:33:09.513515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "おはようございます\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text = recognizer.recognize_google(japanese_audio, language='ja')\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:33:32.371269Z",
     "start_time": "2020-05-05T09:33:31.895000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Pass the leopard roar audio to recognize_google\n",
    "text = recognizer.recognize_google(leopard_audio, \n",
    "                                   language=\"en-US\", \n",
    "                                   show_all=True)\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:33:49.902615Z",
     "start_time": "2020-05-05T09:33:48.505303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie Charlie bit me\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Pass charlie_audio to recognize_google\n",
    "text = recognizer.recognize_google(charlie_audio, \n",
    "                                   language=\"en-US\")\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Speakers 1\n",
    "If your goal is to transcribe conversations, there will be more than one speaker. However, as you'll see, the recognize_google() function will only transcribe speech into a single block of text.\n",
    "\n",
    "You can hear in this audio file there are three different speakers.\n",
    "\n",
    "But if you transcribe it on its own, recognize_google() returns a single block of text. Which is still useful but it doesn't let you know which speaker said what.\n",
    "\n",
    "We'll see an alternative to this in the next exercise.\n",
    "\n",
    "The multiple speakers audio file has been imported and converted to AudioData as multiple_speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:46:40.805076Z",
     "start_time": "2020-05-05T09:46:38.508642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'multiple_speakers.wav': 'https://file.io/MDkwS70q'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  706k    0  706k    0     0   337k      0 --:--:--  0:00:02 --:--:--  337k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('multiple_speakers.wav')\n",
    "\n",
    "\n",
    "{\"success\":true,\"key\":\"MDkwS70q\",\"link\":\"https://file.io/MDkwS70q\",\"expiry\":\"14 days\"}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'multiple_speakers.wav': 'https://file.io/MDkwS70q'}}\n",
    "\"\"\"\n",
    "prefixToc = '3.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:47:04.335869Z",
     "start_time": "2020-05-05T09:47:04.320242Z"
    }
   },
   "outputs": [],
   "source": [
    "multiple_speakers = get_audio_from_wav(prefix+'multiple_speakers.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:47:27.439946Z",
     "start_time": "2020-05-05T09:47:26.048893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the limitations of the speech recognition library\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Recognize the multiple speaker AudioData\n",
    "text = recognizer.recognize_google(multiple_speakers, \n",
    "                       \t\t\t   language='en-US')\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Speakers 2\n",
    "Deciphering between multiple speakers in one audio file is called speaker diarization. However, you've seen the free function we've been using, recognize_google() doesn't have the ability to transcribe different speakers.\n",
    "\n",
    "One way around this, without using one of the paid speech to text services, is to ensure your audio files are single speaker.\n",
    "\n",
    "This means if you were working with phone call data, you would make sure the caller and receiver are recorded separately. Then you could transcribe each file individually.\n",
    "\n",
    "In this exercise, we'll transcribe each of the speakers in our multiple speakers audio file individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:49:44.157229Z",
     "start_time": "2020-05-05T09:49:38.352048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'speaker_0.wav': 'https://file.io/okzGvNrJ', 'speaker_1.wav': 'https://file.io/JiZRvwHs', 'speaker_2.wav': 'https://file.io/CrbOlD0x'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  539k    0  539k    0     0   297k      0 --:--:--  0:00:01 --:--:--  297k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  769k    0  769k    0     0   398k      0 --:--:--  0:00:01 --:--:--  398k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  539k    0  539k    0     0   338k      0 --:--:--  0:00:01 --:--:--  338k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('speaker_0.wav')\n",
    "uploadToFileIO_pushto_fileio('speaker_1.wav')\n",
    "uploadToFileIO_pushto_fileio('speaker_2.wav')\n",
    "\n",
    "{\"success\":true,\"key\":\"okzGvNrJ\",\"link\":\"https://file.io/okzGvNrJ\",\"expiry\":\"14 days\"}\n",
    "{\"success\":true,\"key\":\"JiZRvwHs\",\"link\":\"https://file.io/JiZRvwHs\",\"expiry\":\"14 days\"}\n",
    "{\"success\":true,\"key\":\"CrbOlD0x\",\"link\":\"https://file.io/CrbOlD0x\",\"expiry\":\"14 days\"}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'speaker_0.wav': 'https://file.io/okzGvNrJ', \n",
    "'speaker_1.wav': 'https://file.io/JiZRvwHs', \n",
    "'speaker_2.wav': 'https://file.io/CrbOlD0x'}}\n",
    "\"\"\"\n",
    "prefixToc = '3.3'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T09:51:11.427348Z",
     "start_time": "2020-05-05T09:51:07.367326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from speaker 0:\n",
      "what are the limitations of the speech recognition library\n",
      "Text from speaker 1:\n",
      "is that it doesn't recognise different speakers and voice\n",
      "Text from speaker 2:\n",
      "you're just returning always one block a text\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Multiple speakers on different files\n",
    "speakers = [sr.AudioFile(prefix+\"speaker_0.wav\"), \n",
    "            sr.AudioFile(prefix+\"speaker_1.wav\"), \n",
    "            sr.AudioFile(prefix+\"speaker_2.wav\")]\n",
    "\n",
    "# Transcribe each speaker individually\n",
    "for i, speaker in enumerate(speakers):\n",
    "    with speaker as source:\n",
    "        speaker_audio = recognizer.record(source)\n",
    "    print(f\"Text from speaker {i}:\")\n",
    "    print(recognizer.recognize_google(speaker_audio,\n",
    "         \t\t\t\t  language=\"en-US\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with noisy audio\n",
    "In this exercise, we'll start by transcribing a clean speech sample to text and then see what happens when we add some background noise.\n",
    "\n",
    "A clean audio sample has been imported as clean_support_call.\n",
    "\n",
    "Play clean support call.\n",
    "\n",
    "We'll then do the same with the noisy audio file saved as noisy_support_call. It has the same speech as clean_support_call but with additional background noise.\n",
    "\n",
    "Play noisy support call.\n",
    "\n",
    "To try and negate the background noise, we'll take advantage of Recognizer's adjust_for_ambient_noise() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:38:54.396578Z",
     "start_time": "2020-05-05T10:38:49.169982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'numpy.ndarray': {'clean_support_call.wav': 'https://file.io/W1i13sVb', 'noisy_support_call.wav': 'https://file.io/2xLA74St'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  902k    0  902k    0     0   385k      0 --:--:--  0:00:02 --:--:--  385k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1025k    0 1025k    0     0   397k      0 --:--:--  0:00:02 --:--:--  397k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### file\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO_pushto_fileio('clean_support_call.wav')\n",
    "uploadToFileIO_pushto_fileio('noisy_support_call.wav')\n",
    "\n",
    "{\"success\":true,\"key\":\"W1i13sVb\",\"link\":\"https://file.io/W1i13sVb\",\"expiry\":\"14 days\"}\n",
    "{\"success\":true,\"key\":\"2xLA74St\",\"link\":\"https://file.io/2xLA74St\",\"expiry\":\"14 days\"}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{numpy.ndarray: {'clean_support_call.wav': 'https://file.io/W1i13sVb', \n",
    "'noisy_support_call.wav': 'https://file.io/2xLA74St'}}\n",
    "\"\"\"\n",
    "prefixToc = '3.4'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:41:36.782753Z",
     "start_time": "2020-05-05T10:41:36.779757Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_support_call = sr.AudioFile(prefix+\"clean_support_call.wav\")\n",
    "noisy_support_call = sr.AudioFile(prefix+\"noisy_support_call.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:42:41.077372Z",
     "start_time": "2020-05-05T10:42:39.681425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I'd like to get some help setting up my account please\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record the audio from the clean support call\n",
    "with clean_support_call as source:\n",
    "  clean_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe the speech from the clean support call\n",
    "text = recognizer.recognize_google(clean_support_call_audio,\n",
    "\t\t\t\t\t   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:43:26.392525Z",
     "start_time": "2020-05-05T10:43:24.162432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'transcript': \"hello I'd like to get me on my account please\", 'confidence': 0.93839359}, {'transcript': \"hello I'd like to get on my account please\"}, {'transcript': \"hello I'd like to get to know me on my account please\"}, {'transcript': \"hello I'd like to get to me on my account please\"}, {'transcript': \"hello I'd like to be on my account please\"}], 'final': True}\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record the audio from the noisy support call\n",
    "with noisy_support_call as source:\n",
    "  noisy_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe the speech from the noisy support call\n",
    "text = recognizer.recognize_google(noisy_support_call_audio,\n",
    "                         language=\"en-US\",\n",
    "                         show_all=True)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:43:57.946032Z",
     "start_time": "2020-05-05T10:43:54.605279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'transcript': \"I'd like to get on my account please\", 'confidence': 0.80877352}, {'transcript': \"I'd like to get some help please\"}, {'transcript': \"I'd like to get to know me on my account please\"}, {'transcript': \"I'd like to get me on my account please\"}, {'transcript': \"I'm going to get some help please\"}], 'final': True}\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record the audio from the noisy support call\n",
    "with noisy_support_call as source:\n",
    "\t# Adjust the recognizer energy threshold for ambient noise\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "    noisy_support_call_audio = recognizer.record(noisy_support_call)\n",
    " \n",
    "# Transcribe the speech from the noisy support call\n",
    "text = recognizer.recognize_google(noisy_support_call_audio,\n",
    "                                   language=\"en-US\",\n",
    "                                   show_all=True)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:44:26.107999Z",
     "start_time": "2020-05-05T10:44:24.003943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'transcript': \"hello I'd like to get my account please\", 'confidence': 0.85416079}, {'transcript': \"hello I'd like to get to my account please\"}, {'transcript': 'hello my account please'}, {'transcript': \"hello I'm sending up my account please\"}, {'transcript': 'hello by Adele please'}], 'final': True}\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record the audio from the noisy support call\n",
    "with noisy_support_call as source:\n",
    "\t# Adjust the recognizer energy threshold for ambient noise\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "    noisy_support_call_audio = recognizer.record(noisy_support_call)\n",
    " \n",
    "# Transcribe the speech from the noisy support call\n",
    "text = recognizer.recognize_google(noisy_support_call_audio,\n",
    "                                   language=\"en-US\",\n",
    "                                   show_all=True)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datacamp] *",
   "language": "python",
   "name": "conda-env-datacamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
