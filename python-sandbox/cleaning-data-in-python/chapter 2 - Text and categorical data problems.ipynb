{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership constraints\n",
    "\n",
    "```python\n",
    "\n",
    "# Finding inconsistent categories\n",
    "inconsistent_categories = set(study_data['blood_type']).difference(categories['blood_type'])\n",
    "print(inconsistent_categories)\n",
    "{'Z+'}\n",
    "# Get and print rows with inconsistent categories\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistent_categories)\n",
    "study_data[inconsistent_rows]\n",
    "name\n",
    "birthday blood_type\n",
    "5 Jennifer 2019-12-17\n",
    "Z+\n",
    "\n",
    "# Dropping inconsistent categories\n",
    "inconsistent_categories = set(study_data['blood_type']).difference(categories['blood_type'])\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistent_categories)\n",
    "inconsistent_data = study_data[inconsistent_rows]\n",
    "# Drop inconsistent categories and get consistent data only\n",
    "consistent_data = study_data[~inconsistent_rows]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding consistency\n",
    "> \n",
    "> In this exercise and throughout this chapter, you'll be working with the `airlines` DataFrame which contains survey responses on the San Francisco Airport from airline customers.\n",
    "> \n",
    "> The DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction. Another DataFrame named `categories` was created, containing all correct possible values for the survey columns.\n",
    "> \n",
    "> In this exercise, you will use both of these DataFrames to find survey answers with inconsistent values, and drop them, effectively performing an outer and inner join on both these DataFrames as seen in the video exercise. The `pandas` package has been imported as `pd`, and the `airlines` and `categories` DataFrames are in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:32:53.291694Z",
     "start_time": "2021-04-29T13:32:51.474321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'airlines.csv': 'https://file.io/xPfG689sAVWn', 'categories.csv': 'https://file.io/TVCLlH7rxkpR'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  291k    0  291k    0     0   301k      0 --:--:-- --:--:-- --:--:--  301k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   233    0   233    0     0    413      0 --:--:-- --:--:-- --:--:--   412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(airlines, categories)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'airlines.csv': 'https://file.io/xPfG689sAVWn',\n",
    "  'categories.csv': 'https://file.io/TVCLlH7rxkpR'}}\n",
    "  \"\"\"\n",
    "prefixToc='1.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc)\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "airlines = pd.read_csv(prefix+'airlines.csv',index_col=0)\n",
    "categories = pd.read_csv(prefix+'categories.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Finding consistency | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/text-and-categorical-data-problems?ex=3)\n",
    "\n",
    "> -   Print the `categories` DataFrame and take a close look at all possible correct categories of the survey columns.\n",
    "> -   Print the unique values of the survey columns in `airlines` using the `.unique()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:34:39.447616Z",
     "start_time": "2021-04-29T13:34:39.439361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cleanliness           safety          satisfaction\n",
      "0           Clean          Neutral        Very satisfied\n",
      "1         Average        Very safe               Neutral\n",
      "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
      "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
      "4           Dirty  Somewhat unsafe      Very unsatisfied\n",
      "Cleanliness:  ['Clean' 'Average' 'Unacceptable' 'Somewhat clean' 'Somewhat dirty'\n",
      " 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satisfied' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print categories DataFrame\n",
    "print(categories)\n",
    "\n",
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Finding consistency | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/text-and-categorical-data-problems?ex=3)\n",
    "\n",
    "> -   Create a set out of the `cleanliness` column in `airlines` using `set()` and find the inconsistent category by finding the **difference** in the `cleanliness` column of `categories`.\n",
    "> -   Find rows of `airlines` with a `cleanliness` value not in `categories` and print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:36:54.699159Z",
     "start_time": "2021-04-29T13:36:54.688766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id        day           airline  destination  dest_region dest_size  \\\n",
      "4    2992  Wednesday          AMERICAN        MIAMI      East US       Hub   \n",
      "18   2913     Friday  TURKISH AIRLINES     ISTANBUL  Middle East       Hub   \n",
      "100  2321  Wednesday         SOUTHWEST  LOS ANGELES      West US       Hub   \n",
      "\n",
      "    boarding_area   dept_time  wait_min   cleanliness         safety  \\\n",
      "4     Gates 50-59  2018-12-31     559.0  Unacceptable      Very safe   \n",
      "18   Gates 91-102  2018-12-31     225.0  Unacceptable      Very safe   \n",
      "100   Gates 20-39  2018-12-31     130.0  Unacceptable  Somewhat safe   \n",
      "\n",
      "           satisfaction  \n",
      "4    Somewhat satisfied  \n",
      "18   Somewhat satisfied  \n",
      "100  Somewhat satisfied  \n"
     ]
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Finding consistency | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/text-and-categorical-data-problems?ex=3)\n",
    "\n",
    "> Print the rows with the consistent categories of `cleanliness` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:37:25.835625Z",
     "start_time": "2021-04-29T13:37:25.823423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id       day        airline        destination    dest_region  \\\n",
      "0     1351   Tuesday    UNITED INTL             KANSAI           Asia   \n",
      "1      373    Friday         ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
      "2     2820  Thursday          DELTA        LOS ANGELES        West US   \n",
      "3     1157   Tuesday      SOUTHWEST        LOS ANGELES        West US   \n",
      "5      634  Thursday         ALASKA             NEWARK        East US   \n",
      "...    ...       ...            ...                ...            ...   \n",
      "2804  1475   Tuesday         ALASKA       NEW YORK-JFK        East US   \n",
      "2805  2222  Thursday      SOUTHWEST            PHOENIX        West US   \n",
      "2806  2684    Friday         UNITED            ORLANDO        East US   \n",
      "2807  2549   Tuesday        JETBLUE         LONG BEACH        West US   \n",
      "2808  2162  Saturday  CHINA EASTERN            QINGDAO           Asia   \n",
      "\n",
      "     dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
      "0          Hub  Gates 91-102  2018-12-31     115.0           Clean   \n",
      "1        Small   Gates 50-59  2018-12-31     135.0           Clean   \n",
      "2          Hub   Gates 40-48  2018-12-31      70.0         Average   \n",
      "3          Hub   Gates 20-39  2018-12-31     190.0           Clean   \n",
      "5          Hub   Gates 50-59  2018-12-31     140.0  Somewhat clean   \n",
      "...        ...           ...         ...       ...             ...   \n",
      "2804       Hub   Gates 50-59  2018-12-31     280.0  Somewhat clean   \n",
      "2805       Hub   Gates 20-39  2018-12-31     165.0           Clean   \n",
      "2806       Hub   Gates 70-90  2018-12-31      92.0           Clean   \n",
      "2807     Small    Gates 1-12  2018-12-31      95.0           Clean   \n",
      "2808     Large    Gates 1-12  2018-12-31     220.0           Clean   \n",
      "\n",
      "             safety        satisfaction  \n",
      "0           Neutral      Very satisfied  \n",
      "1         Very safe      Very satisfied  \n",
      "2     Somewhat safe             Neutral  \n",
      "3         Very safe  Somewhat satisfied  \n",
      "5         Very safe      Very satisfied  \n",
      "...             ...                 ...  \n",
      "2804        Neutral  Somewhat satisfied  \n",
      "2805      Very safe      Very satisfied  \n",
      "2806      Very safe      Very satisfied  \n",
      "2807  Somewhat safe      Very satisfied  \n",
      "2808      Very safe  Somewhat satisfied  \n",
      "\n",
      "[2474 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print rows with consistent categories only\n",
    "print(airlines[~cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical variables\n",
    "\n",
    "```python\n",
    "\n",
    "# Capitalization: 'married' , 'Married' , 'UNMARRIED' , 'unmarried' ..\n",
    "marriage_status['marriage_status'] = marriage_status['marriage_status'].str.upper()\n",
    "\n",
    "# Trailing spaces: 'married ' , 'married' , 'unmarried' , ' unmarried' ..\n",
    "demographics['marriage_status'] = demographics['marriage_status'].str.strip()\n",
    "\n",
    "# Collapsing data into categories\n",
    "# Using qcut()\n",
    "import pandas as pd\n",
    "group_names = ['0-200K', '200K-500K', '500K+']\n",
    "demographics['income_group'] = pd.qcut(demographics['household_income'], q = 3,\n",
    "labels = group_names)\n",
    "# Print income_group column\n",
    "demographics[['income_group', 'household_income']]\n",
    "\n",
    "# Using cut() - create category ranges and names\n",
    "ranges = [0,200000,500000,np.inf]\n",
    "group_names = ['0-200K', '200K-500K', '500K+']\n",
    "# Create income group column\n",
    "demographics['income_group'] = pd.cut(demographics['household_income'], bins=ranges,\n",
    "labels=group_names)\n",
    "demographics[['income_group', 'household_income']]\n",
    "\n",
    "# Collapsing data into categories\n",
    "# Map categories to fewer ones: reducing categories in categorical column.\n",
    "# Create mapping dictionary and replace\n",
    "mapping = {'Microsoft':'DesktopOS', 'MacOS':'DesktopOS', 'Linux':'DesktopOS',\n",
    "'IOS':'MobileOS', 'Android':'MobileOS'}\n",
    "devices['operating_system'] = devices['operating_system'].replace(mapping)\n",
    "devices['operating_system'].unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inconsistent categories\n",
    "> \n",
    "> In this exercise, you'll be revisiting the `airlines` DataFrame from the previous lesson.\n",
    "> \n",
    "> As a reminder, the DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction on the San Francisco Airport.\n",
    "> \n",
    "> In this exercise, you will examine two categorical columns from this DataFrame, `dest_region` and `dest_size` respectively, assess how to address them and make sure that they are cleaned and ready for analysis. The `pandas` package has been imported as `pd`, and the `airlines` DataFrame is in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:44:49.294646Z",
     "start_time": "2021-04-29T13:44:49.280352Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:46:26.774571Z",
     "start_time": "2021-04-29T13:46:26.770800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:46:51.000590Z",
     "start_time": "2021-04-29T13:46:50.992989Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remapping categories\n",
    "> \n",
    "> To better understand survey respondents from `airlines`, you want to find out if there is a relationship between certain responses and the day of the week and wait time at the gate.\n",
    "> \n",
    "> The `airlines` DataFrame contains the `day` and `wait_min` columns, which are categorical and numerical respectively. The `day` column contains the exact day a flight took place, and `wait_min` contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:\n",
    "> \n",
    "> -   `wait_type`: `'short'` for 0-60 min, `'medium'` for 60-180 and `long` for 180+\n",
    "> -   `day_week`: `'weekday'` if day is in the weekday, `'weekend'` if day is in the weekend.\n",
    "> \n",
    "> The `pandas` and `numpy` packages have been imported as `pd` and `np`. Let's create some new categorical data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Remapping categories | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/text-and-categorical-data-problems?ex=7)\n",
    "\n",
    "> -   Create the ranges and labels for the `wait_type` column mentioned in the description above.\n",
    "> -   Create the `wait_type` column by from `wait_min` by using `pd.cut()`, while inputting `label_ranges` and `label_names` in the correct arguments.\n",
    "> -   Create the `mapping` dictionary mapping weekdays to `'weekday'` and weekend days to `'weekend'`.\n",
    "> -   Create the `day_week` column by using `.replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:50:13.104372Z",
     "start_time": "2021-04-29T13:50:13.102081Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:51:02.161791Z",
     "start_time": "2021-04-29T13:51:02.154303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'mrdium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning text data\n",
    "\n",
    "```python\n",
    "\n",
    "# Fixing the phone number column\n",
    "# Replace \"+\" with \"00\"\n",
    "phones[\"Phone number\"] = phones[\"Phone number\"].str.replace(\"+\", \"00\")\n",
    "# Replace \"-\" with nothing\n",
    "phones[\"Phone number\"] = phones[\"Phone number\"].str.replace(\"-\", \"\")\n",
    "# Replace phone numbers with lower than 10 digits to NaN\n",
    "digits = phones['Phone number'].str.len()\n",
    "phones.loc[digits < 10, \"Phone number\"] = np.nan\n",
    "\n",
    "# Fixing the phone number column\n",
    "# Find length of each row in Phone number column\n",
    "sanity_check = phone['Phone number'].str.len()\n",
    "# Assert minmum phone number length is 10\n",
    "assert sanity_check.min() >= 10\n",
    "# Assert all numbers do not have \"+\" or \"-\"\n",
    "assert phone['Phone number'].str.contains(\"+|-\").any() == False\n",
    "\n",
    "# Regular expressions in action\n",
    "# Replace letters with nothing\n",
    "phones['Phone number'] = phones['Phone number'].str.replace(r'\\D+', '')\n",
    "phones.head()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing titles and taking names\n",
    "> \n",
    "> While collecting survey respondent metadata in the `airlines` DataFrame, the full name of respondents was saved in the `full_name` column. However upon closer inspection, you found that a lot of the different names are prefixed by honorifics such as `\"Dr.\"`, `\"Mr.\"`, `\"Ms.\"` and `\"Miss\"`.\n",
    "> \n",
    "> Your ultimate objective is to create two new columns named `first_name` and `last_name`, containing the first and last names of respondents respectively. Before doing so however, you need to remove honorifics.\n",
    "> \n",
    "> The `airlines` DataFrame is in your environment, alongside `pandas` as `pd.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Removing titles and taking names | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/text-and-categorical-data-problems?ex=9)\n",
    "\n",
    "> -   Remove `\"Dr.\"`, `\"Mr.\"`, `\"Miss\"` and `\"Ms.\"` from `full_name` by replacing them with an empty string `\"\"` in that order.\n",
    "> -   Run the `assert` statement using `.str.contains()` that tests whether `full_name` still contains any of the honorifics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:57:52.689872Z",
     "start_time": "2021-04-29T13:57:52.052260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'airlines.csv': 'https://file.io/qNLxyI9GEyFA'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 26842    0 26842    0     0  44075      0 --:--:-- --:--:-- --:--:-- 44003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(airlines)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'airlines.csv': 'https://file.io/qNLxyI9GEyFA'}}\n",
    "  \"\"\"\n",
    "prefixToc='3.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc)\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "airlines = pd.read_csv(prefix+'airlines.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:59:06.200759Z",
     "start_time": "2021-04-29T13:59:06.194837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\")\n",
    "\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n",
    "\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping it descriptive\n",
    "> \n",
    "> To further understand travelers' experiences in the San Francisco Airport, the quality assurance department sent out a qualitative questionnaire to all travelers who gave the airport the worst score on all possible categories. The objective behind this questionnaire is to identify common patterns in what travelers are saying about the airport.\n",
    "> \n",
    "> Their response is stored in the `survey_response` column. Upon a closer look, you realized a few of the answers gave the shortest possible character amount without much substance. In this exercise, you will isolate the responses with a character count higher than **_40_** , and make sure your new DataFrame contains responses with **_40_** characters or more using an `assert` statement.\n",
    "> \n",
    "> The `airlines` DataFrame is in your environment, and `pandas` is imported as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keeping it descriptive | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/text-and-categorical-data-problems?ex=10)\n",
    "\n",
    "> -   Using the `airlines` DataFrame, store the length of each instance in the `survey_response` column in `resp_length` by using `.str.len()`.\n",
    "> -   Isolate the rows of `airlines` with `resp_length` higher than `40`.\n",
    "> -   Assert that the smallest survey response length in `airlines_survey` is now bigger than 40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T14:18:47.806098Z",
     "start_time": "2021-04-29T14:18:47.232401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'airlines.csv': 'https://file.io/wZ9Rdh26pikG'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4801    0  4801    0     0   8776      0 --:--:-- --:--:-- --:--:--  8760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(airlines)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'airlines.csv': 'https://file.io/wZ9Rdh26pikG'}}\n",
    "\"\"\"\n",
    "prefixToc='3.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc)\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "airlines = pd.read_csv(prefix+'airlines.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T14:20:06.110391Z",
     "start_time": "2021-04-29T14:20:06.105204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    The airport personnell forgot to alert us of d...\n",
      "19    The food in the airport was really really expe...\n",
      "20    One of the other travelers was really loud and...\n",
      "21    I don't remember answering the survey with the...\n",
      "22    The airport personnel kept ignoring my request...\n",
      "23    The chair I sat in was extremely uncomfortable...\n",
      "24    I wish you were more like other airports, the ...\n",
      "25    I was really unsatisfied with the wait times b...\n",
      "27    The flight was okay, but I didn't really like ...\n",
      "28    We were really slowed down by security measure...\n",
      "29    There was a spill on the aisle next to the bat...\n",
      "30    I felt very unsatisfied by how long the flight...\n",
      "Name: survey_response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Store length of each row in survey_response column\n",
    "resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey['survey_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datacamp] *",
   "language": "python",
   "name": "conda-env-datacamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
