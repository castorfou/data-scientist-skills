{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data type constraints\n",
    "\n",
    "```python\n",
    "\n",
    "# String to integers\n",
    "# Print sum of all Revenue column\n",
    "sales['Revenue'].sum()\n",
    "'23153$1457$36865$32474$472$27510$16158$5694$6876$40487$807$6893$9153$6895$4216..\n",
    "# Remove $ from Revenue column\n",
    "sales['Revenue'] = sales['Revenue'].str.strip('$')\n",
    "sales['Revenue'] = sales['Revenue'].astype('int')\n",
    "# Verify that Revenue is now an integer\n",
    "assert sales['Revenue'].dtype == 'int'\n",
    "\n",
    "# Numeric or categorical?\n",
    "# Convert to categorical\n",
    "df[\"marriage_status\"] = df[\"marriage_status\"].astype('category')\n",
    "df.describe()\n",
    "marriage_status\n",
    "count 241\n",
    "unique 4\n",
    "top 1\n",
    "freq 120\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data range constraints\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "# drop values\n",
    "import pandas as pd\n",
    "# Output Movies with rating > 5\n",
    "movies[movies['avg_rating'] > 5]\n",
    "movie_name\n",
    "avg_rating\n",
    "23 A Beautiful Mind 6\n",
    "65 La Vita e Bella 6\n",
    "77 Amelie 6\n",
    "# Drop values using filtering\n",
    "movies = movies[movies['avg_rating'] <= 5]\n",
    "# Drop values using .drop()\n",
    "movies.drop(movies[movies['avg_rating'] > 5].index, inplace = True)\n",
    "# Assert results\n",
    "assert movies['avg_rating'].max() <= 5\n",
    "\n",
    "\n",
    "# Change out of range value to upper limit\n",
    "# Convert avg_rating > 5 to 5\n",
    "movies.loc[movies['avg_rating'] > 5, 'avg_rating'] = 5\n",
    "# Assert statement\n",
    "assert movies['avg_rating'].max() <= 5\n",
    "\n",
    "# Date range example\n",
    "today_date = dt.date.today()\n",
    "Drop the data\n",
    "# Drop values using filtering\n",
    "user_signups = user_signups[user_signups['subscription_date'] < today_date]\n",
    "# Drop values using .drop()\n",
    "user_signups.drop(user_signups[user_signups['subscription_date'] > today_date].index, inplace = True)\n",
    "Hardcode dates with upper limit\n",
    "# Drop values using filtering\n",
    "user_signups.loc[user_signups['subscription_date'] > today_date, 'subscription_date'] = today_date\n",
    "# Assert is true\n",
    "assert user_signups.subscription_date.max().date() <= today_date\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tire size constraints\n",
    "> \n",
    "> In this lesson, you're going to build on top of the work you've been doing with the `ride_sharing` DataFrame. You'll be working with the `tire_sizes` column which contains data on each bike's tire size.\n",
    "> \n",
    "> Bicycle tire sizes could be either 26″, 27″ or 29″ and are here correctly stored as a categorical value. In an effort to cut maintenance costs, the ride sharing provider decided to set the maximum tire size to be 27″.\n",
    "> \n",
    "> In this exercise, you will make sure the `tire_sizes` column has the correct range by first converting it to an integer, then setting and testing the new upper limit of 27″ for tire sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:33:37.124493Z",
     "start_time": "2021-04-29T12:33:35.586506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'ride_sharing.csv': 'https://file.io/X6hoOa3LYCsS'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3083k    0 3083k    0     0  2470k      0 --:--:--  0:00:01 --:--:-- 2470k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(ride_sharing)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'ride_sharing.csv': 'https://file.io/X6hoOa3LYCsS'}}\n",
    "\"\"\"\n",
    "prefixToc='2.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc)\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "ride_sharing = pd.read_csv(prefix+'ride_sharing.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:33:57.468469Z",
     "start_time": "2021-04-29T12:33:57.455430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25760 entries, 0 to 25759\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   duration         25760 non-null  object \n",
      " 1   station_A_id     25760 non-null  int64  \n",
      " 2   station_A_name   25760 non-null  object \n",
      " 3   station_B_id     25760 non-null  int64  \n",
      " 4   station_B_name   25760 non-null  object \n",
      " 5   bike_id          25760 non-null  int64  \n",
      " 6   user_type        25760 non-null  object \n",
      " 7   user_birth_year  25760 non-null  int64  \n",
      " 8   user_gender      25760 non-null  object \n",
      " 9   tire_sizes       25760 non-null  float64\n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ride_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:35:01.871035Z",
     "start_time": "2021-04-29T12:35:01.856800Z"
    }
   },
   "outputs": [],
   "source": [
    "ride_sharing['tire_sizes']=ride_sharing['tire_sizes'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:35:10.925192Z",
     "start_time": "2021-04-29T12:35:10.895608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     25760.0\n",
       "unique        3.0\n",
       "top          26.0\n",
       "freq      12486.0\n",
       "Name: tire_sizes, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing['tire_sizes'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tire size constraints | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/common-data-problems-1?ex=6)\n",
    "\n",
    "> -   Convert the `tire_sizes` column from `category` to `'int'`.\n",
    "> -   Use `.loc[]` to set all values of `tire_sizes` above 27 to 27.\n",
    "> -   Reconvert back `tire_sizes` to `'category'` from `int`.\n",
    "> -   Print the description of the `tire_sizes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:38:19.603464Z",
     "start_time": "2021-04-29T12:38:19.595942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     25760\n",
      "unique        2\n",
      "top          27\n",
      "freq      13274\n",
      "Name: tire_sizes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert tire_sizes to integer\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('int')\n",
    "\n",
    "# Set all values above 27 to 27\n",
    "ride_sharing.loc[ride_sharing['tire_sizes'] > 27, 'tire_sizes'] = 27\n",
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('category')\n",
    "\n",
    "# Print tire size description\n",
    "print(ride_sharing['tire_sizes'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to the future\n",
    "> \n",
    "> A new update to the data pipeline feeding into the `ride_sharing` DataFrame has been updated to register each ride's date. This information is stored in the `ride_date` column of the type `object`, which represents strings in `pandas`.\n",
    "> \n",
    "> A bug was discovered which was relaying rides taken today as taken next year. To fix this, you will find all instances of the `ride_date` column that occur anytime in the future, and set the maximum possible value of this column to today's date. Before doing so, you would need to convert `ride_date` to a `datetime` object.\n",
    "> \n",
    "> The `datetime` package has been imported as `dt`, alongside all the packages you've been using till now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:39:35.235442Z",
     "start_time": "2021-04-29T12:39:33.771442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'ride_sharing.csv': 'https://file.io/Dkg2rSM37lnn'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3360k    0 3360k    0     0  2447k      0 --:--:--  0:00:01 --:--:-- 2447k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(ride_sharing)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'ride_sharing.csv': 'https://file.io/Dkg2rSM37lnn'}}\n",
    "\"\"\"\n",
    "prefixToc='2.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc)\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "ride_sharing = pd.read_csv(prefix+'ride_sharing.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:39:36.679463Z",
     "start_time": "2021-04-29T12:39:36.668042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25760 entries, 0 to 25759\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   duration         25760 non-null  object \n",
      " 1   station_A_id     25760 non-null  int64  \n",
      " 2   station_A_name   25760 non-null  object \n",
      " 3   station_B_id     25760 non-null  int64  \n",
      " 4   station_B_name   25760 non-null  object \n",
      " 5   bike_id          25760 non-null  int64  \n",
      " 6   user_type        25760 non-null  object \n",
      " 7   user_birth_year  25760 non-null  int64  \n",
      " 8   user_gender      25760 non-null  object \n",
      " 9   tire_sizes       25760 non-null  float64\n",
      " 10  ride_date        25760 non-null  object \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ride_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:39:53.535640Z",
     "start_time": "2021-04-29T12:39:53.529654Z"
    }
   },
   "outputs": [],
   "source": [
    "ride_sharing['tire_sizes']=ride_sharing['tire_sizes'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:39:54.345317Z",
     "start_time": "2021-04-29T12:39:54.340107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     25760.0\n",
       "unique        3.0\n",
       "top          26.0\n",
       "freq      12486.0\n",
       "Name: tire_sizes, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing['tire_sizes'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the future | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/common-data-problems-1?ex=7)\n",
    "\n",
    "> -   Convert `ride_date` to a `datetime` object and store it in `ride_dt` column using `to_datetime()`.\n",
    "> -   Create the variable `today`, which stores today's date by using the `dt.date.today()` function.\n",
    "> -   For all instances of `ride_dt` in the future, set them to today's date.\n",
    "> -   Print the maximum date in the `ride_dt` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T12:43:01.673829Z",
     "start_time": "2021-04-29T12:43:01.653737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# Convert ride_date to datetime\n",
    "ride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_date']).dt.date\n",
    "\n",
    "# Save today's date\n",
    "today = dt.date.today()\n",
    "\n",
    "# Set all in the future to today's date\n",
    "ride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n",
    "\n",
    "# Print maximum of ride_dt column\n",
    "print(ride_sharing['ride_dt'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniqueness constraints\n",
    "\n",
    "```python\n",
    "\n",
    "# How to find duplicate values?\n",
    "# Get duplicates across all columns\n",
    "duplicates = height_weight.duplicated()\n",
    "print(duplicates)\n",
    "\n",
    "# How to find duplicate rows?\n",
    "# The .duplicated() method\n",
    "subset : List of column names to check for duplication.\n",
    "keep : Whether to keep first ( 'first' ), last ( 'last' ) or all ( False ) duplicate values.\n",
    "# Column names to check for duplication\n",
    "column_names = ['first_name','last_name','address']\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "\n",
    "# How to find duplicate rows?\n",
    "# Output duplicate values\n",
    "height_weight[duplicates].sort_values(by = 'first_name')\n",
    "\n",
    "# How to treat duplicate values?\n",
    "# The .drop_duplicates() method\n",
    "subset : List of column names to check for duplication.\n",
    "keep : Whether to keep first ( 'first' ), last ( 'last' ) or all ( False ) duplicate values.\n",
    "inplace : Drop duplicated rows directly inside DataFrame without creating new object ( True).\n",
    "# Drop duplicates\n",
    "height_weight.drop_duplicates(inplace = True)\n",
    "\n",
    "# How to treat duplicate values?\n",
    "The .groupby() and .agg() methods\n",
    "# Group by column names and produce statistical summaries\n",
    "column_names = ['first_name','last_name','address']\n",
    "summaries = {'height': 'max', 'weight': 'mean'}\n",
    "height_weight = height_weight.groupby(by = column_names).agg(summaries).reset_index()\n",
    "# Make sure aggregation is done\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "height_weight[duplicates].sort_values(by = 'first_name')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicates\n",
    "> \n",
    "> A new update to the data pipeline feeding into `ride_sharing` has added the `ride_id` column, which represents a unique identifier for each ride.\n",
    "> \n",
    "> The update however coincided with radically shorter average ride duration times and irregular user birth dates set in the future. Most importantly, the number of rides taken has increased by 20% overnight, leading you to think there might be both complete and incomplete duplicates in the `ride_sharing` DataFrame.\n",
    "> \n",
    "> In this exercise, you will confirm this suspicion by finding those duplicates. A sample of `ride_sharing` is in your environment, as well as all the packages you've been working with thus far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:19:46.842448Z",
     "start_time": "2021-04-29T13:19:46.079046Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'ride_sharing.csv': 'https://file.io/fjp81hCjFhFs'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  9813    0  9813    0     0  13516      0 --:--:-- --:--:-- --:--:-- 13497\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78 entries, 0 to 77\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ride_id          78 non-null     int64 \n",
      " 1   duration         78 non-null     int64 \n",
      " 2   station_A_id     78 non-null     int64 \n",
      " 3   station_A_name   78 non-null     object\n",
      " 4   station_B_id     78 non-null     int64 \n",
      " 5   station_B_name   78 non-null     object\n",
      " 6   bike_id          78 non-null     int64 \n",
      " 7   user_type        78 non-null     object\n",
      " 8   user_birth_year  78 non-null     int64 \n",
      " 9   user_gender      78 non-null     object\n",
      " 10  tire_sizes       78 non-null     int64 \n",
      " 11  ride_date        78 non-null     object\n",
      "dtypes: int64(7), object(5)\n",
      "memory usage: 7.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     78\n",
       "unique     2\n",
       "top       27\n",
       "freq      45\n",
       "Name: tire_sizes, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(ride_sharing)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'ride_sharing.csv': 'https://file.io/fjp81hCjFhFs'}}\n",
    "\"\"\"\n",
    "prefixToc='3.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc)\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "ride_sharing = pd.read_csv(prefix+'ride_sharing.csv',index_col=0)\n",
    "\n",
    "\n",
    "ride_sharing.info()\n",
    "\n",
    "ride_sharing['tire_sizes']=ride_sharing['tire_sizes'].astype('category')\n",
    "\n",
    "ride_sharing['tire_sizes'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Finding duplicates | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/common-data-problems-1?ex=10)\n",
    "\n",
    "> -   Find duplicated rows of `ride_id` in the `ride_sharing` DataFrame while setting `keep` to `False`.\n",
    "> -   Subset `ride_sharing` on `duplicates` and sort by `ride_id` and assign the results to `duplicated_rides`.\n",
    "> -   Print the `ride_id`, `duration` and `user_birth_year` columns of `duplicated_rides` in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:21:54.316395Z",
     "start_time": "2021-04-29T13:21:54.310265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ride_id  duration  user_birth_year\n",
      "22       33        10             1979\n",
      "39       33         2             1979\n",
      "53       55         9             1985\n",
      "65       55         9             1985\n",
      "74       71        11             1997\n",
      "75       71        11             1997\n",
      "76       89         9             1986\n",
      "77       89         9             2060\n"
     ]
    }
   ],
   "source": [
    "# Find duplicates\n",
    "duplicates = ride_sharing.duplicated('ride_id', keep=False)\n",
    "\n",
    "# Sort your duplicated rides\n",
    "duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')\n",
    "\n",
    "# Print relevant columns of duplicated_rides\n",
    "print(duplicated_rides[['ride_id','duration','user_birth_year']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating duplicates\n",
    "> \n",
    "> In the last exercise, you were able to verify that the new update feeding into `ride_sharing` contains a bug generating both complete and incomplete duplicated rows for some values of the `ride_id` column, with occasional discrepant values for the `user_birth_year` and `duration` columns.\n",
    "> \n",
    "> In this exercise, you will be treating those duplicated rows by first dropping complete duplicates, and then merging the incomplete duplicate rows into one while keeping the average `duration`, and the minimum `user_birth_year` for each set of incomplete duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Treating duplicates | Python](https://campus.datacamp.com/courses/cleaning-data-in-python/common-data-problems-1?ex=11)\n",
    "\n",
    "> -   Drop complete duplicates in `ride_sharing` and store the results in `ride_dup`.\n",
    "> -   Create the `statistics` dictionary which holds **min**imum aggregation for `user_birth_year` and **mean** aggregation for `duration`.\n",
    "> -   Drop incomplete duplicates by grouping by `ride_id` and applying the aggregation in `statistics`.\n",
    "> -   Find duplicates again and run the `assert` statement to verify de-duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:24:22.279261Z",
     "start_time": "2021-04-29T13:24:22.267953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop complete duplicates from ride_sharing\n",
    "ride_dup = ride_sharing.drop_duplicates()\n",
    "\n",
    "# Create statistics dictionary for aggregation function\n",
    "statistics = {'user_birth_year': 'min', 'duration': 'mean'}\n",
    "\n",
    "# Group by ride_id and compute new statistics\n",
    "ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n",
    "\n",
    "# Find duplicated values again\n",
    "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
    "duplicated_rides = ride_unique[duplicates == True]\n",
    "\n",
    "# Assert duplicates are processed\n",
    "assert duplicated_rides.shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datacamp] *",
   "language": "python",
   "name": "conda-env-datacamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
