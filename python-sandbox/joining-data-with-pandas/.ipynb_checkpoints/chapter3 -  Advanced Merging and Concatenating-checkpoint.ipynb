{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering joins\n",
    "\n",
    "```python\n",
    "\n",
    "###########\n",
    "# semi-join\n",
    "\n",
    "# Step 1 - semi-join\n",
    "genres_tracks = genres.merge(top_tracks, on='gid')\n",
    "\n",
    "# Step 2 - semi-join\n",
    "genres['gid'].isin(genres_tracks['gid'])\n",
    "\n",
    "# Step 3 - semi-join\n",
    "genres_tracks = genres.merge(top_tracks, on='gid')\n",
    "top_genres = genres[genres['gid'].isin(genres_tracks['gid'])]\n",
    "\n",
    "###########\n",
    "# anti-join\n",
    "\n",
    "# Step 1 - anti-join\n",
    "genres_tracks = genres.merge(top_tracks, on='gid', how='left', indicator=True)\n",
    "\n",
    "# Step 2 - anti-join\n",
    "gid_list = genres_tracks.loc[genres_tracks['_merge'] == 'left_only', 'gid']\n",
    "\n",
    "# Step 3 - anti-join\n",
    "genres_tracks = genres.merge(top_tracks, on='gid', how='left', indicator=True)\n",
    "gid_list = genres_tracks.loc[genres_tracks['_merge'] == 'left_only','gid']\n",
    "non_top_genres = genres[genres['gid'].isin(gid_list)]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Performing an anti-join | Python](https://campus.datacamp.com/courses/joining-data-with-pandas/advanced-merging-and-concatenating?ex=3)\n",
    "\n",
    "> ## Performing an anti-join\n",
    "> \n",
    "> In our music streaming company dataset, each customer is assigned an employee representative to assist them. In this exercise, filter the employee table by a table of top customers, returning only those employees who are **not** assigned to a customer. The results should resemble the results of an anti-join. The company's leadership will assign these employees additional training so that they can work with high valued customers.\n",
    "> \n",
    "> The `top_cust` and `employees` tables have been provided for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:45:46.375209Z",
     "start_time": "2021-01-11T09:45:45.019262Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'employees.csv': 'https://file.io/3GYfiihgJWgh', 'top_cust.csv': 'https://file.io/W98RbvDoM4N4'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   573    0   573    0     0   1097      0 --:--:-- --:--:-- --:--:--  1097\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3976    0  3976    0     0   7796      0 --:--:-- --:--:-- --:--:--  7780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(top_cust , employees)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'employees.csv': 'https://file.io/3GYfiihgJWgh',\n",
    "  'top_cust.csv': 'https://file.io/W98RbvDoM4N4'}}\n",
    "\"\"\"\n",
    "prefixToc='1.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "top_cust = pd.read_csv(prefix+'top_cust.csv',index_col=0)\n",
    "employees = pd.read_csv(prefix+'employees.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:46:09.543592Z",
     "start_time": "2021-01-11T09:46:09.531528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>srid</th>\n",
       "      <th>fname</th>\n",
       "      <th>lname</th>\n",
       "      <th>phone</th>\n",
       "      <th>fax</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Luís</td>\n",
       "      <td>Gonçalves</td>\n",
       "      <td>+55 (12) 3923-5555</td>\n",
       "      <td>+55 (12) 3923-5566</td>\n",
       "      <td>luisg@embraer.com.br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Leonie</td>\n",
       "      <td>Köhler</td>\n",
       "      <td>+49 0711 2842222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leonekohler@surfeu.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>François</td>\n",
       "      <td>Tremblay</td>\n",
       "      <td>+1 (514) 721-4711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ftremblay@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Bjørn</td>\n",
       "      <td>Hansen</td>\n",
       "      <td>+47 22 44 22 22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bjorn.hansen@yahoo.no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>František</td>\n",
       "      <td>Wichterlová</td>\n",
       "      <td>+420 2 4172 5555</td>\n",
       "      <td>+420 2 4172 5555</td>\n",
       "      <td>frantisekw@jetbrains.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid  srid      fname        lname               phone                 fax  \\\n",
       "0    1     3       Luís    Gonçalves  +55 (12) 3923-5555  +55 (12) 3923-5566   \n",
       "1    2     5     Leonie       Köhler    +49 0711 2842222                 NaN   \n",
       "2    3     3   François     Tremblay   +1 (514) 721-4711                 NaN   \n",
       "3    4     4      Bjørn       Hansen     +47 22 44 22 22                 NaN   \n",
       "4    5     4  František  Wichterlová    +420 2 4172 5555    +420 2 4172 5555   \n",
       "\n",
       "                      email  \n",
       "0      luisg@embraer.com.br  \n",
       "1     leonekohler@surfeu.de  \n",
       "2       ftremblay@gmail.com  \n",
       "3     bjorn.hansen@yahoo.no  \n",
       "4  frantisekw@jetbrains.com  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:46:15.978909Z",
     "start_time": "2021-01-11T09:46:15.968428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srid</th>\n",
       "      <th>lname</th>\n",
       "      <th>fname</th>\n",
       "      <th>title</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adams</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>General Manager</td>\n",
       "      <td>2002-08-14</td>\n",
       "      <td>andrew@chinookcorp.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>2002-05-01</td>\n",
       "      <td>nancy@chinookcorp.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Sales Support Agent</td>\n",
       "      <td>2002-04-01</td>\n",
       "      <td>jane@chinookcorp.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Park</td>\n",
       "      <td>Margaret</td>\n",
       "      <td>Sales Support Agent</td>\n",
       "      <td>2003-05-03</td>\n",
       "      <td>margaret@chinookcorp.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Steve</td>\n",
       "      <td>Sales Support Agent</td>\n",
       "      <td>2003-10-17</td>\n",
       "      <td>steve@chinookcorp.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   srid    lname     fname                title   hire_date  \\\n",
       "0     1    Adams    Andrew      General Manager  2002-08-14   \n",
       "1     2  Edwards     Nancy        Sales Manager  2002-05-01   \n",
       "2     3  Peacock      Jane  Sales Support Agent  2002-04-01   \n",
       "3     4     Park  Margaret  Sales Support Agent  2003-05-03   \n",
       "4     5  Johnson     Steve  Sales Support Agent  2003-10-17   \n",
       "\n",
       "                      email  \n",
       "0    andrew@chinookcorp.com  \n",
       "1     nancy@chinookcorp.com  \n",
       "2      jane@chinookcorp.com  \n",
       "3  margaret@chinookcorp.com  \n",
       "4     steve@chinookcorp.com  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Merge `employees` and `top_cust` with a left join, setting `indicator` argument to `True`. Save the result to `empl_cust`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:47:33.077198Z",
     "start_time": "2021-01-11T09:47:33.067341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge employees and top_cust\n",
    "empl_cust = employees.merge(top_cust, on='srid', \n",
    "                            how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:47:42.458669Z",
     "start_time": "2021-01-11T09:47:42.425673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srid</th>\n",
       "      <th>lname_x</th>\n",
       "      <th>fname_x</th>\n",
       "      <th>title</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>email_x</th>\n",
       "      <th>cid</th>\n",
       "      <th>fname_y</th>\n",
       "      <th>lname_y</th>\n",
       "      <th>phone</th>\n",
       "      <th>fax</th>\n",
       "      <th>email_y</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adams</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>General Manager</td>\n",
       "      <td>2002-08-14</td>\n",
       "      <td>andrew@chinookcorp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>2002-05-01</td>\n",
       "      <td>nancy@chinookcorp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Sales Support Agent</td>\n",
       "      <td>2002-04-01</td>\n",
       "      <td>jane@chinookcorp.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Luís</td>\n",
       "      <td>Gonçalves</td>\n",
       "      <td>+55 (12) 3923-5555</td>\n",
       "      <td>+55 (12) 3923-5566</td>\n",
       "      <td>luisg@embraer.com.br</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Sales Support Agent</td>\n",
       "      <td>2002-04-01</td>\n",
       "      <td>jane@chinookcorp.com</td>\n",
       "      <td>3.0</td>\n",
       "      <td>François</td>\n",
       "      <td>Tremblay</td>\n",
       "      <td>+1 (514) 721-4711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ftremblay@gmail.com</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Sales Support Agent</td>\n",
       "      <td>2002-04-01</td>\n",
       "      <td>jane@chinookcorp.com</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Roberto</td>\n",
       "      <td>Almeida</td>\n",
       "      <td>+55 (21) 2271-7000</td>\n",
       "      <td>+55 (21) 2271-7070</td>\n",
       "      <td>roberto.almeida@riotur.gov.br</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   srid  lname_x fname_x                title   hire_date  \\\n",
       "0     1    Adams  Andrew      General Manager  2002-08-14   \n",
       "1     2  Edwards   Nancy        Sales Manager  2002-05-01   \n",
       "2     3  Peacock    Jane  Sales Support Agent  2002-04-01   \n",
       "3     3  Peacock    Jane  Sales Support Agent  2002-04-01   \n",
       "4     3  Peacock    Jane  Sales Support Agent  2002-04-01   \n",
       "\n",
       "                  email_x   cid   fname_y    lname_y               phone  \\\n",
       "0  andrew@chinookcorp.com   NaN       NaN        NaN                 NaN   \n",
       "1   nancy@chinookcorp.com   NaN       NaN        NaN                 NaN   \n",
       "2    jane@chinookcorp.com   1.0      Luís  Gonçalves  +55 (12) 3923-5555   \n",
       "3    jane@chinookcorp.com   3.0  François   Tremblay   +1 (514) 721-4711   \n",
       "4    jane@chinookcorp.com  12.0   Roberto    Almeida  +55 (21) 2271-7000   \n",
       "\n",
       "                  fax                        email_y     _merge  \n",
       "0                 NaN                            NaN  left_only  \n",
       "1                 NaN                            NaN  left_only  \n",
       "2  +55 (12) 3923-5566           luisg@embraer.com.br       both  \n",
       "3                 NaN            ftremblay@gmail.com       both  \n",
       "4  +55 (21) 2271-7070  roberto.almeida@riotur.gov.br       both  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empl_cust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Select the `srid` column of `empl_cust` and the rows where `_merge` is `'left_only'`. Save the result to `srid_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:49:00.766923Z",
     "start_time": "2021-01-11T09:49:00.764518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select the srid column where _merge is left_only\n",
    "srid_list = empl_cust.loc[empl_cust['_merge']=='left_only', 'srid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:49:05.933664Z",
     "start_time": "2021-01-11T09:49:05.921774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     2\n",
       "61    6\n",
       "62    7\n",
       "63    8\n",
       "Name: srid, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srid_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Subset the `employees` table and select those rows where the `srid` is in the variable `srid_list` and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:50:12.752209Z",
     "start_time": "2021-01-11T09:50:12.745085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   srid     lname    fname            title   hire_date  \\\n",
      "0     1     Adams   Andrew  General Manager  2002-08-14   \n",
      "1     2   Edwards    Nancy    Sales Manager  2002-05-01   \n",
      "5     6  Mitchell  Michael       IT Manager  2003-10-17   \n",
      "6     7      King   Robert         IT Staff  2004-01-02   \n",
      "7     8  Callahan    Laura         IT Staff  2004-03-04   \n",
      "\n",
      "                     email  \n",
      "0   andrew@chinookcorp.com  \n",
      "1    nancy@chinookcorp.com  \n",
      "5  michael@chinookcorp.com  \n",
      "6   robert@chinookcorp.com  \n",
      "7    laura@chinookcorp.com  \n"
     ]
    }
   ],
   "source": [
    "# Get employees not working with top customers\n",
    "print(employees[employees['srid'].isin(srid_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Performing a semi-join | Python](https://campus.datacamp.com/courses/joining-data-with-pandas/advanced-merging-and-concatenating?ex=4)\n",
    "\n",
    "> ## Performing a semi-join\n",
    "> \n",
    "> Some of the tracks that have generated the most significant amount of revenue are from TV-shows or are other non-musical audio. You have been given a table of invoices that include top revenue-generating items. Additionally, you have a table of non-musical tracks from the streaming service. In this exercise, you'll use a semi-join to find the top revenue-generating non-musical tracks..\n",
    "> \n",
    "> The tables `non_mus_tcks`, `top_invoices`, and `genres` have been loaded for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:51:41.787387Z",
     "start_time": "2021-01-11T09:51:40.194217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'genres.csv': 'https://file.io/SKfXT86kJ8QS', 'non_mus_tcks.csv': 'https://file.io/Sh3wqKY1AKFw', 'top_invoices.csv': 'https://file.io/qLPcRuVMtqJX'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   390    0   390    0     0    783      0 --:--:-- --:--:-- --:--:--   783\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8310    0  8310    0     0  16488      0 --:--:-- --:--:-- --:--:-- 16455\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   428    0   428    0     0    852      0 --:--:-- --:--:-- --:--:--   852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(non_mus_tcks, top_invoices,  genres)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'genres.csv': 'https://file.io/SKfXT86kJ8QS',\n",
    "  'non_mus_tcks.csv': 'https://file.io/Sh3wqKY1AKFw',\n",
    "  'top_invoices.csv': 'https://file.io/qLPcRuVMtqJX'}}\n",
    "\"\"\"\n",
    "prefixToc='1.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "non_mus_tcks = pd.read_csv(prefix+'non_mus_tcks.csv',index_col=0)\n",
    "top_invoices = pd.read_csv(prefix+'top_invoices.csv',index_col=0)\n",
    "genres = pd.read_csv(prefix+'genres.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> -   Merge `non_mus_tcks` and `top_invoices` on `tid` using an inner join. Save the result as `tracks_invoices`.\n",
    "> -   Use `.isin()` to subset the rows of `non_mus_tck` where `tid` is in the `tid` column of `tracks_invoices`. Save the result as `top_tracks`.\n",
    "> -   Group `top_tracks` by `gid` and count the `tid` rows. Save the result to `cnt_by_gid`.\n",
    "> -   Merge `cnt_by_gid` with the `genres` table on `gid` and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:53:31.754430Z",
     "start_time": "2021-01-11T09:53:31.742917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gid  tid      name\n",
      "0   19    4  TV Shows\n",
      "1   21    2     Drama\n",
      "2   22    1    Comedy\n"
     ]
    }
   ],
   "source": [
    "# Merge the non_mus_tck and top_invoices tables on tid\n",
    "tracks_invoices = non_mus_tcks.merge(top_invoices, on='tid')\n",
    "\n",
    "# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n",
    "top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
    "\n",
    "# Group the top_tracks by gid and count the tid rows\n",
    "cnt_by_gid = top_tracks.groupby(['gid'], as_index=False).agg({'tid':'count'})\n",
    "\n",
    "# Merge the genres table to cnt_by_gid on gid and print\n",
    "print(cnt_by_gid.merge(genres, on='gid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate DataFrames together vertically\n",
    "\n",
    "```python\n",
    "# Basic concatenation\n",
    "pd.concat([inv_jan, inv_feb, inv_mar])\n",
    "\n",
    "# Ignoring the index\n",
    "pd.concat([inv_jan, inv_feb, inv_mar],\n",
    "ignore_index=True)\n",
    "\n",
    "# Setting labels to original tables\n",
    "pd.concat([inv_jan, inv_feb, inv_mar],\n",
    "ignore_index=False,\n",
    "keys=['jan','feb','mar'])\n",
    "\n",
    "# Concatenate tables with different column names\n",
    "pd.concat([inv_jan, inv_feb],\n",
    "sort=True)\n",
    "\n",
    "# Concatenate tables with different column names\n",
    "pd.concat([inv_jan, inv_feb],\n",
    "join='inner')\n",
    "\n",
    "# Append the tables\n",
    "inv_jan.append([inv_feb, inv_mar],\n",
    "ignore_index=True, \n",
    "sort=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Concatenation basics | Python](https://campus.datacamp.com/courses/joining-data-with-pandas/advanced-merging-and-concatenating?ex=6)\n",
    "\n",
    "> ## Concatenation basics\n",
    "> \n",
    "> You have been given a few tables of data with musical track info for different albums from the metal band, _Metallica_. The track info comes from their _Ride The Lightning_, _Master Of Puppets_, and _St. Anger_ albums. Try various features of the `.concat()` method by concatenating the tables vertically together in different ways.\n",
    "> \n",
    "> The tables `tracks_master`, `tracks_ride`, and `tracks_st` have loaded for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:59:18.457415Z",
     "start_time": "2021-01-11T09:59:16.780664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'tracks_master.csv': 'https://file.io/gBCewSuKVquI', 'tracks_ride.csv': 'https://file.io/KaF0xmp8fZjj', 'tracks_st.csv': 'https://file.io/07iFO0AuGwRP'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   194    0   194    0     0    313      0 --:--:-- --:--:-- --:--:--   313\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   227    0   227    0     0    437      0 --:--:-- --:--:-- --:--:--   437\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   197    0   197    0     0    420      0 --:--:-- --:--:-- --:--:--   420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(tracks_master, tracks_ride,  tracks_st)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'tracks_master.csv': 'https://file.io/gBCewSuKVquI',\n",
    "  'tracks_ride.csv': 'https://file.io/KaF0xmp8fZjj',\n",
    "  'tracks_st.csv': 'https://file.io/07iFO0AuGwRP'}}\n",
    "\"\"\"\n",
    "prefixToc='2.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "tracks_master = pd.read_csv(prefix+'tracks_master.csv',index_col=0)\n",
    "tracks_ride = pd.read_csv(prefix+'tracks_ride.csv',index_col=0)\n",
    "tracks_st = pd.read_csv(prefix+'tracks_st.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Concatenate `tracks_master`, `tracks_ride`, and `tracks_st`, in that order, setting `sort` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T09:59:59.887898Z",
     "start_time": "2021-01-11T09:59:59.876429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aid             composer  gid  mtid                     name   tid  u_price\n",
      "0  152  J.Hetfield/L.Ulrich    3     1                  Battery  1853     0.99\n",
      "1  152            K.Hammett    3     1        Master Of Puppets  1854     0.99\n",
      "4  152  J.Hetfield/L.Ulrich    3     1        Disposable Heroes  1857     0.99\n",
      "0  154                  NaN    3     1     Fight Fire With Fire  1874     0.99\n",
      "1  154                  NaN    3     1       Ride The Lightning  1875     0.99\n",
      "2  154                  NaN    3     1  For Whom The Bell Tolls  1876     0.99\n",
      "3  154                  NaN    3     1            Fade To Black  1877     0.99\n",
      "4  154                  NaN    3     1        Trapped Under Ice  1878     0.99\n",
      "0  155                  NaN    3     1                  Frantic  1882     0.99\n",
      "1  155                  NaN    3     1                St. Anger  1883     0.99\n",
      "2  155                  NaN    3     1     Some Kind Of Monster  1884     0.99\n",
      "3  155                  NaN    3     1             Dirty Window  1885     0.99\n",
      "4  155                  NaN    3     1            Invisible Kid  1886     0.99\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the tracks\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Concatenate `tracks_master`, `tracks_ride`, and `tracks_st`, where the index goes from 0 to n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:00:35.739927Z",
     "start_time": "2021-01-11T10:00:35.717415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aid             composer  gid  mtid                     name   tid  \\\n",
      "0   152  J.Hetfield/L.Ulrich    3     1                  Battery  1853   \n",
      "1   152            K.Hammett    3     1        Master Of Puppets  1854   \n",
      "2   152  J.Hetfield/L.Ulrich    3     1        Disposable Heroes  1857   \n",
      "3   154                  NaN    3     1     Fight Fire With Fire  1874   \n",
      "4   154                  NaN    3     1       Ride The Lightning  1875   \n",
      "5   154                  NaN    3     1  For Whom The Bell Tolls  1876   \n",
      "6   154                  NaN    3     1            Fade To Black  1877   \n",
      "7   154                  NaN    3     1        Trapped Under Ice  1878   \n",
      "8   155                  NaN    3     1                  Frantic  1882   \n",
      "9   155                  NaN    3     1                St. Anger  1883   \n",
      "10  155                  NaN    3     1     Some Kind Of Monster  1884   \n",
      "11  155                  NaN    3     1             Dirty Window  1885   \n",
      "12  155                  NaN    3     1            Invisible Kid  1886   \n",
      "\n",
      "    u_price  \n",
      "0      0.99  \n",
      "1      0.99  \n",
      "2      0.99  \n",
      "3      0.99  \n",
      "4      0.99  \n",
      "5      0.99  \n",
      "6      0.99  \n",
      "7      0.99  \n",
      "8      0.99  \n",
      "9      0.99  \n",
      "10     0.99  \n",
      "11     0.99  \n",
      "12     0.99  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate the tracks so the index goes from 0 to n-1\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               ignore_index=True,\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Concatenate `tracks_master`, `tracks_ride`, and `tracks_st`, showing only columns that are in all tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:01:44.243374Z",
     "start_time": "2021-01-11T10:01:44.237218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aid  gid  mtid                     name   tid  u_price\n",
      "0  152    3     1                  Battery  1853     0.99\n",
      "1  152    3     1        Master Of Puppets  1854     0.99\n",
      "4  152    3     1        Disposable Heroes  1857     0.99\n",
      "0  154    3     1     Fight Fire With Fire  1874     0.99\n",
      "1  154    3     1       Ride The Lightning  1875     0.99\n",
      "2  154    3     1  For Whom The Bell Tolls  1876     0.99\n",
      "3  154    3     1            Fade To Black  1877     0.99\n",
      "4  154    3     1        Trapped Under Ice  1878     0.99\n",
      "0  155    3     1                  Frantic  1882     0.99\n",
      "1  155    3     1                St. Anger  1883     0.99\n",
      "2  155    3     1     Some Kind Of Monster  1884     0.99\n",
      "3  155    3     1             Dirty Window  1885     0.99\n",
      "4  155    3     1            Invisible Kid  1886     0.99\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the tracks, show only columns names that are in all tables\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               join='inner',\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Concatenating with keys | Python](https://campus.datacamp.com/courses/joining-data-with-pandas/advanced-merging-and-concatenating?ex=7)\n",
    "\n",
    "> ## Concatenating with keys\n",
    "> \n",
    "> The leadership of the music streaming company has come to you and asked you for assistance in analyzing sales for a recent business quarter. They would like to know which month in the quarter saw the highest average invoice total. You have been given three tables with invoice data named `inv_jul`, `inv_aug`, and `inv_sep`. Concatenate these tables into one to create a graph of the average monthly invoice total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:03:09.985520Z",
     "start_time": "2021-01-11T10:03:08.342877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'inv_aug.csv': 'https://file.io/5aLhWckpbXZd', 'inv_jul.csv': 'https://file.io/P0aK1YKUzO4T', 'inv_sep.csv': 'https://file.io/8L6hwKGRbFok'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1173    0  1173    0     0   2350      0 --:--:-- --:--:-- --:--:--  2350\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1171    0  1171    0     0   2300      0 --:--:-- --:--:-- --:--:--  2296\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1095    0  1095    0     0   2147      0 --:--:-- --:--:-- --:--:--  2147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(inv_jul, inv_aug,  inv_sep)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'inv_aug.csv': 'https://file.io/5aLhWckpbXZd',\n",
    "  'inv_jul.csv': 'https://file.io/P0aK1YKUzO4T',\n",
    "  'inv_sep.csv': 'https://file.io/8L6hwKGRbFok'}}\n",
    "\"\"\"\n",
    "prefixToc='2.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "inv_jul = pd.read_csv(prefix+'inv_jul.csv',index_col=0)\n",
    "inv_aug = pd.read_csv(prefix+'inv_aug.csv',index_col=0)\n",
    "inv_sep = pd.read_csv(prefix+'inv_sep.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> -   Concatenate the three tables together vertically in order with the oldest month first, adding `'7Jul'`, `'8Aug'`, and `'9Sep'` as `keys` for their respective months, and save to variable `avg_inv_by_month`.\n",
    "> -   Use the `.agg()` method to find the average of the `total` column from the grouped invoices.\n",
    "> -   Create a bar chart of `avg_inv_by_month`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:03:47.785938Z",
     "start_time": "2021-01-11T10:03:47.520257Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:05:36.603299Z",
     "start_time": "2021-01-11T10:05:36.484307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenate the tables and add keys\n",
    "inv_jul_thr_sep = pd.concat([inv_jul, inv_aug, inv_sep], \n",
    "                            keys=['7Jul','8Aug','9Sep'])\n",
    "\n",
    "# Group the invoices by the index keys and find avg of the total column\n",
    "avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total':'mean'})\n",
    "\n",
    "# Bar plot of avg_inv_by_month\n",
    "avg_inv_by_month.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Using the append method | Python](https://campus.datacamp.com/courses/joining-data-with-pandas/advanced-merging-and-concatenating?ex=8)\n",
    "\n",
    "> ## Using the append method\n",
    "> \n",
    "> The `.concat()` method is excellent when you need a lot of control over how concatenation is performed. However, if you do not need as much control, then the `.append()` method is another option. You'll try this method out by appending the track lists together from different _Metallica_ albums. From there, you will merge it with the `invoice_items` table to determine which track sold the most.\n",
    "> \n",
    "> The tables `tracks_master`, `tracks_ride`, `tracks_st`, and `invoice_items` have loaded for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:07:27.199147Z",
     "start_time": "2021-01-11T10:07:24.924760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'invoice_items.csv': 'https://file.io/eBFVLaQR0fq8', 'tracks_master.csv': 'https://file.io/NX4cuEFUPuvt', 'tracks_ride.csv': 'https://file.io/F0UaZqOHOgb9', 'tracks_st.csv': 'https://file.io/VQhpUCVYxBSg'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 54742    0 54742    0     0  79451      0 --:--:-- --:--:-- --:--:-- 79336\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   194    0   194    0     0    386      0 --:--:-- --:--:-- --:--:--   385\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   227    0   227    0     0    459      0 --:--:-- --:--:-- --:--:--   459\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   197    0   197    0     0    420      0 --:--:-- --:--:-- --:--:--   420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(tracks_master, tracks_ride, tracks_st,  invoice_items)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'invoice_items.csv': 'https://file.io/eBFVLaQR0fq8',\n",
    "  'tracks_master.csv': 'https://file.io/NX4cuEFUPuvt',\n",
    "  'tracks_ride.csv': 'https://file.io/F0UaZqOHOgb9',\n",
    "  'tracks_st.csv': 'https://file.io/VQhpUCVYxBSg'}}\n",
    "\"\"\"\n",
    "prefixToc='2.3'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "tracks_master = pd.read_csv(prefix+'tracks_master.csv',index_col=0)\n",
    "tracks_ride = pd.read_csv(prefix+'tracks_ride.csv',index_col=0)\n",
    "tracks_st = pd.read_csv(prefix+'tracks_st.csv',index_col=0)\n",
    "invoice_items = pd.read_csv(prefix+'invoice_items.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> -   Use the `.append()` method to combine (**in this order**)`tracks_ride`, `tracks_master`, and `tracks_st` together vertically, and save to `metallica_tracks`.\n",
    "> -   Merge `metallica_tracks` and `invoice_items` on `tid` with an inner join, and save to `tracks_invoices`.\n",
    "> -   For each `tid` and `name` in `tracks_invoices`, sum the quantity sold column, and save as `tracks_sold`.\n",
    "> -   Sort `tracks_sold` in descending order by the `quantity` column, and print the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:12:47.375138Z",
     "start_time": "2021-01-11T10:12:47.365009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              quantity\n",
      "tid  name                             \n",
      "1853 Battery                         2\n",
      "1876 For Whom The Bell Tolls         2\n",
      "1854 Master Of Puppets               1\n",
      "1857 Disposable Heroes               1\n",
      "1875 Ride The Lightning              1\n",
      "1877 Fade To Black                   1\n",
      "1882 Frantic                         1\n",
      "1884 Some Kind Of Monster            1\n",
      "1886 Invisible Kid                   1\n"
     ]
    }
   ],
   "source": [
    "# Use the .append() method to combine the tracks tables\n",
    "metallica_tracks = tracks_ride.append([tracks_master, tracks_st], sort=False)\n",
    "\n",
    "# Merge metallica_tracks and invoice_items\n",
    "tracks_invoices = metallica_tracks.merge(invoice_items, on='tid')\n",
    "\n",
    "# For each tid and name sum the quantity sold\n",
    "tracks_sold = tracks_invoices.groupby(['tid','name']).agg({'quantity': 'sum'})\n",
    "\n",
    "# Sort in decending order by quantity and print the results\n",
    "print(tracks_sold.sort_values('quantity', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying integrity\n",
    "\n",
    "```python\n",
    "\n",
    "# Validating merges\n",
    ".merge(validate=None) :\n",
    "Checks if merge is of specified type\n",
    "'one_to_one'\n",
    "'one_to_many'\n",
    "'many_to_one'\n",
    "'many_to_many'\n",
    "\n",
    "# Merge validate: one_to_one\n",
    "tracks.merge(specs, on='tid',\n",
    "validate='one_to_one')\n",
    "\n",
    "# Merge validate: one_to_many\n",
    "albums.merge(tracks, on='aid',\n",
    "validate='one_to_many')\n",
    "\n",
    "# Verifying concatenations\n",
    ".concat(verify_integrity=False) :\n",
    "Check whether the new concatenated index contains duplicates\n",
    "Default value is False\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Validating a merge | Python](https://campus.datacamp.com/courses/joining-data-with-pandas/advanced-merging-and-concatenating?ex=10)\n",
    "\n",
    "> ## Validating a merge\n",
    "> \n",
    "> You have been given 2 tables, `artists`, and `albums`. Use the console to merge them using `artists.merge(albums, on='artid').head()`. Adjust the `validate` argument to answer which statement is **_False_**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:08:36.540124Z",
     "start_time": "2021-01-11T12:08:35.393820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'albums.csv': 'https://file.io/exJLo2zqORXn', 'artists.csv': 'https://file.io/7WG1q5Ns5QAN'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12088    0 12088    0     0  21022      0 --:--:-- --:--:-- --:--:-- 21022\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8004    0  8004    0     0  15632      0 --:--:-- --:--:-- --:--:-- 15602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(artists,  albums)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'albums.csv': 'https://file.io/exJLo2zqORXn',\n",
    "  'artists.csv': 'https://file.io/7WG1q5Ns5QAN'}}\n",
    "\"\"\"\n",
    "prefixToc='3.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "artists = pd.read_csv(prefix+'artists.csv',index_col=0)\n",
    "albums = pd.read_csv(prefix+'albums.csv',index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:09:00.864912Z",
     "start_time": "2021-01-11T12:09:00.846612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AC/DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aerosmith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alanis Morissette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alice In Chains</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artid               name\n",
       "0      1              AC/DC\n",
       "1      2             Accept\n",
       "2      3          Aerosmith\n",
       "3      4  Alanis Morissette\n",
       "4      5    Alice In Chains"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:09:07.258358Z",
     "start_time": "2021-01-11T12:09:07.239364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>title</th>\n",
       "      <th>artid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>For Those About To Rock We Salute You</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Balls to the Wall</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Restless and Wild</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Let There Be Rock</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Big Ones</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aid                                  title  artid\n",
       "0    1  For Those About To Rock We Salute You      1\n",
       "1    2                      Balls to the Wall      2\n",
       "2    3                      Restless and Wild      2\n",
       "3    4                      Let There Be Rock      1\n",
       "4    5                               Big Ones      3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:10:09.117551Z",
     "start_time": "2021-01-11T12:10:09.105749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artid</th>\n",
       "      <th>name</th>\n",
       "      <th>aid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AC/DC</td>\n",
       "      <td>1</td>\n",
       "      <td>For Those About To Rock We Salute You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AC/DC</td>\n",
       "      <td>4</td>\n",
       "      <td>Let There Be Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Accept</td>\n",
       "      <td>2</td>\n",
       "      <td>Balls to the Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Accept</td>\n",
       "      <td>3</td>\n",
       "      <td>Restless and Wild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Aerosmith</td>\n",
       "      <td>5</td>\n",
       "      <td>Big Ones</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artid       name  aid                                  title\n",
       "0      1      AC/DC    1  For Those About To Rock We Salute You\n",
       "1      1      AC/DC    4                      Let There Be Rock\n",
       "2      2     Accept    2                      Balls to the Wall\n",
       "3      2     Accept    3                      Restless and Wild\n",
       "4      3  Aerosmith    5                               Big Ones"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists.merge(albums, on='artid', validate='many_to_many').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:10:17.888761Z",
     "start_time": "2021-01-11T12:10:17.864812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artid</th>\n",
       "      <th>name</th>\n",
       "      <th>aid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AC/DC</td>\n",
       "      <td>1</td>\n",
       "      <td>For Those About To Rock We Salute You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AC/DC</td>\n",
       "      <td>4</td>\n",
       "      <td>Let There Be Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Accept</td>\n",
       "      <td>2</td>\n",
       "      <td>Balls to the Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Accept</td>\n",
       "      <td>3</td>\n",
       "      <td>Restless and Wild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Aerosmith</td>\n",
       "      <td>5</td>\n",
       "      <td>Big Ones</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artid       name  aid                                  title\n",
       "0      1      AC/DC    1  For Those About To Rock We Salute You\n",
       "1      1      AC/DC    4                      Let There Be Rock\n",
       "2      2     Accept    2                      Balls to the Wall\n",
       "3      2     Accept    3                      Restless and Wild\n",
       "4      3  Aerosmith    5                               Big Ones"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists.merge(albums, on='artid', validate='one_to_many').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:10:25.987328Z",
     "start_time": "2021-01-11T12:10:25.959540Z"
    }
   },
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Merge keys are not unique in right dataset; not a one-to-one merge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-01632b6edc6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'artid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'one_to_one'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/datacamp/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7957\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7958\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7959\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7960\u001b[0m         )\n\u001b[1;32m   7961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/datacamp/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/datacamp/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# are in fact unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/datacamp/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, validate)\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mright_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                 raise MergeError(\n\u001b[0;32m-> 1278\u001b[0;31m                     \u001b[0;34m\"Merge keys are not unique in right dataset; not a one-to-one merge\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m                 )\n\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMergeError\u001b[0m: Merge keys are not unique in right dataset; not a one-to-one merge"
     ]
    }
   ],
   "source": [
    "artists.merge(albums, on='artid', validate='one_to_one').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:10:54.984730Z",
     "start_time": "2021-01-11T12:10:54.975484Z"
    }
   },
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Merge keys are not unique in right dataset; not a many-to-one merge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-109e9a441ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'artid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'many_to_one'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/datacamp/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7957\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7958\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7959\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7960\u001b[0m         )\n\u001b[1;32m   7961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/datacamp/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/datacamp/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# are in fact unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/datacamp/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, validate)\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mright_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m                 raise MergeError(\n\u001b[0;32m-> 1290\u001b[0;31m                     \u001b[0;34m\"Merge keys are not unique in right dataset; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m                     \u001b[0;34m\"not a many-to-one merge\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                 )\n",
      "\u001b[0;31mMergeError\u001b[0m: Merge keys are not unique in right dataset; not a many-to-one merge"
     ]
    }
   ],
   "source": [
    "artists.merge(albums, on='artid', validate='many_to_one').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Concatenate and merge to find common songs | Python](https://campus.datacamp.com/courses/joining-data-with-pandas/advanced-merging-and-concatenating?ex=11)\n",
    "\n",
    "> ## Concatenate and merge to find common songs\n",
    "> \n",
    "> The senior leadership of the streaming service is requesting your help again. You are given the historical files for a popular playlist in the classical music genre in 2018 and 2019. Additionally, you are given a similar set of files for the most popular pop music genre playlist on the streaming service in 2018 and 2019. Your goal is to concatenate the respective files to make a large classical playlist table and overall popular music table. Then filter the classical music table using a semi-join to return only the most popular classical music tracks.\n",
    "> \n",
    "> The tables `classic_18`, `classic_19`, and `pop_18`, `pop_19` have been loaded for you. Additionally, `pandas` has been loaded as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:12:35.387289Z",
     "start_time": "2021-01-11T12:12:33.100767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'classic_18.csv': 'https://file.io/dkqZ5rHa54aK', 'classic_19.csv': 'https://file.io/LGV3mXfrbcmU', 'pop_18.csv': 'https://file.io/vcgEfg9HCyoL', 'pop_19.csv': 'https://file.io/jnb93DKcctES'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   334    0   334    0     0    647      0 --:--:-- --:--:-- --:--:--   646\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   360    0   360    0     0    693      0 --:--:-- --:--:-- --:--:--   692\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2014    0  2014    0     0   3248      0 --:--:-- --:--:-- --:--:--  3248\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2281    0  2281    0     0   4842      0 --:--:-- --:--:-- --:--:--  4832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(classic_18, classic_19,  pop_18, pop_19)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'classic_18.csv': 'https://file.io/dkqZ5rHa54aK',\n",
    "  'classic_19.csv': 'https://file.io/LGV3mXfrbcmU',\n",
    "  'pop_18.csv': 'https://file.io/vcgEfg9HCyoL',\n",
    "  'pop_19.csv': 'https://file.io/jnb93DKcctES'}}\n",
    "\"\"\"\n",
    "prefixToc='3.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "classic_18 = pd.read_csv(prefix+'classic_18.csv',index_col=0)\n",
    "classic_19 = pd.read_csv(prefix+'classic_19.csv',index_col=0)\n",
    "pop_18 = pd.read_csv(prefix+'pop_18.csv',index_col=0)\n",
    "pop_19 = pd.read_csv(prefix+'pop_19.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> -   Concatenate the `classic_18` and `classic_19` tables vertically where the index goes from 0 to n-1, and save to `classic_18_19`.\n",
    "> -   Concatenate the `pop_18` and `pop_19` tables vertically where the index goes from 0 to n-1, and save to `pop_18_19`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:14:20.999983Z",
     "start_time": "2021-01-11T12:14:20.997176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the classic tables vertically\n",
    "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
    "\n",
    "# Concatenate the pop tables vertically\n",
    "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> -   With `classic_18_19` on the left, merge it with `pop_18_19` on `tid` using an inner join.\n",
    "> -   Use `.isin()` to filter `classic_18_19` where `tid` is in `classic_pop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T12:16:20.925256Z",
     "start_time": "2021-01-11T12:16:20.907039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pid   tid\n",
      "3    12  3479\n",
      "10   12  3439\n",
      "21   12  3445\n",
      "23   12  3449\n",
      "48   12  3437\n",
      "50   12  3435\n"
     ]
    }
   ],
   "source": [
    "# Merge classic_18_19 with pop_18_19\n",
    "classic_pop = classic_18_19.merge(pop_18_19, on='tid')\n",
    "\n",
    "# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\n",
    "popular_classic = classic_18_19[classic_18_19['tid'].isin(classic_pop['tid'])]\n",
    "\n",
    "# Print popular chart\n",
    "print(popular_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datacamp] *",
   "language": "python",
   "name": "conda-env-datacamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "308px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
