{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate validation score\n",
    "You've seen both validation and Public Leaderboard scores in the video. However, the code examples are available only for the test data. To get the validation scores you have to repeat the same process on the holdout set.\n",
    "\n",
    "Throughout this chapter, you will work with New York City Taxi competition data. The problem is to predict the fare amount for a taxi ride in New York City. The competition metric is the root mean squared error.\n",
    "\n",
    "The first goal is to evaluate the Baseline model on the validation data. You will replicate the simplest Baseline based on the mean of \"fare_amount\". Recall that as a validation strategy we used a 30% holdout split with validation_train as train and validation_test as holdout DataFrames. Both of them are available in your workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T07:58:42.231680Z",
     "start_time": "2020-02-19T07:58:37.279289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'validation_test.csv': 'https://file.io/hmbPQr', 'validation_train.csv': 'https://file.io/lEmlvU'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  492k    0  492k    0     0   286k      0 --:--:--  0:00:01 --:--:--  286k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1148k    0 1148k    0     0   373k      0 --:--:--  0:00:03 --:--:--  373k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(validation_train, validation_test)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'validation_test.csv': 'https://file.io/hmbPQr',\n",
    "  'validation_train.csv': 'https://file.io/lEmlvU'}}\n",
    "\"\"\"\n",
    "prefixToc='1.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"10.225.92.1:80\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "validation_test = pd.read_csv(prefix+'validation_test.csv',index_col=0)\n",
    "validation_train = pd.read_csv(prefix+'validation_train.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T07:59:12.509570Z",
     "start_time": "2020-02-19T07:59:12.478793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8659</th>\n",
       "      <td>8659</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-12-12 06:23:20</td>\n",
       "      <td>-73.965272</td>\n",
       "      <td>40.766683</td>\n",
       "      <td>-73.952668</td>\n",
       "      <td>40.789520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12631</th>\n",
       "      <td>12631</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2010-12-24 04:22:06</td>\n",
       "      <td>-73.982908</td>\n",
       "      <td>40.762825</td>\n",
       "      <td>-74.012196</td>\n",
       "      <td>40.702656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9579</th>\n",
       "      <td>9579</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2010-03-23 15:53:00</td>\n",
       "      <td>-73.972148</td>\n",
       "      <td>40.756160</td>\n",
       "      <td>-73.950960</td>\n",
       "      <td>40.777520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>6252</td>\n",
       "      <td>20.5</td>\n",
       "      <td>2014-05-06 12:46:00</td>\n",
       "      <td>-73.964060</td>\n",
       "      <td>40.758822</td>\n",
       "      <td>-73.995518</td>\n",
       "      <td>40.739282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11927</th>\n",
       "      <td>11927</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2009-10-19 10:35:00</td>\n",
       "      <td>-73.988930</td>\n",
       "      <td>40.745375</td>\n",
       "      <td>-73.990995</td>\n",
       "      <td>40.742417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  fare_amount      pickup_datetime  pickup_longitude  \\\n",
       "8659    8659          7.5  2014-12-12 06:23:20        -73.965272   \n",
       "12631  12631         16.1  2010-12-24 04:22:06        -73.982908   \n",
       "9579    9579          7.7  2010-03-23 15:53:00        -73.972148   \n",
       "6252    6252         20.5  2014-05-06 12:46:00        -73.964060   \n",
       "11927  11927          3.3  2009-10-19 10:35:00        -73.988930   \n",
       "\n",
       "       pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "8659         40.766683         -73.952668         40.789520                1  \n",
       "12631        40.762825         -74.012196         40.702656                1  \n",
       "9579         40.756160         -73.950960         40.777520                1  \n",
       "6252         40.758822         -73.995518         40.739282                1  \n",
       "11927        40.745375         -73.990995         40.742417                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:00:21.417657Z",
     "start_time": "2020-02-19T08:00:21.070670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE for Baseline I model: 9.986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Calculate the mean fare_amount on the validation_train data\n",
    "naive_prediction = np.mean(validation_train['fare_amount'])\n",
    "\n",
    "# Assign naive prediction to all the holdout observations\n",
    "validation_test['pred'] = naive_prediction\n",
    "\n",
    "# Measure the local RMSE\n",
    "rmse = sqrt(mean_squared_error(validation_test['fare_amount'], validation_test['pred']))\n",
    "print('Validation RMSE for Baseline I model: {:.3f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline based on the date\n",
    "We've already built 3 different baseline models. To get more practice, let's build a couple more. The first model is based on the grouping variables. It's clear that the ride fare could depend on the part of the day. For example, prices could be higher during the rush hours.\n",
    "\n",
    "Your goal is to build a baseline model that will assign the average \"fare_amount\" for the corresponding hour. For now, you will create the model for the whole train data and make predictions for the test dataset.\n",
    "\n",
    "The train and test DataFrames are available in your workspace. Moreover, the \"pickup_datetime\" column in both DataFrames is already converted to a datetime object for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:04:51.364186Z",
     "start_time": "2020-02-19T08:04:51.296586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements déjà effectués - SKIP\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(train, test)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'test.csv': 'https://file.io/SdAPiJ',\n",
    "  'train.csv': 'https://file.io/mU5wVE'}}\n",
    "\"\"\"\n",
    "prefixToc='1.2'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"10.225.92.1:80\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "test = pd.read_csv(prefix+'test.csv',index_col=0, parse_dates=['pickup_datetime'])\n",
    "train = pd.read_csv(prefix+'train.csv',index_col=0, parse_dates=['pickup_datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:04:51.660619Z",
     "start_time": "2020-02-19T08:04:51.647835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  fare_amount     pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0   0          4.5 2009-06-15 17:26:21        -73.844311        40.721319   \n",
       "1   1         16.9 2010-01-05 16:52:16        -74.016048        40.711303   \n",
       "2   2          5.7 2011-08-18 00:35:00        -73.982738        40.761270   \n",
       "3   3          7.7 2012-04-21 04:30:42        -73.987130        40.733143   \n",
       "4   4          5.3 2010-03-09 07:51:00        -73.968095        40.768008   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.841610         40.712278                1  \n",
       "1         -73.979268         40.782004                1  \n",
       "2         -73.991242         40.750562                2  \n",
       "3         -73.991567         40.758092                1  \n",
       "4         -73.956655         40.783762                1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:04:52.376959Z",
     "start_time": "2020-02-19T08:04:52.369294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 19999\n",
      "Data columns (total 8 columns):\n",
      "id                   20000 non-null int64\n",
      "fare_amount          20000 non-null float64\n",
      "pickup_datetime      20000 non-null datetime64[ns]\n",
      "pickup_longitude     20000 non-null float64\n",
      "pickup_latitude      20000 non-null float64\n",
      "dropoff_longitude    20000 non-null float64\n",
      "dropoff_latitude     20000 non-null float64\n",
      "passenger_count      20000 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(5), int64(2)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:06:10.537416Z",
     "start_time": "2020-02-19T08:06:10.464811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get pickup hour from the pickup_datetime column\n",
    "train['hour'] = train['pickup_datetime'].dt.hour\n",
    "test['hour'] = test['pickup_datetime'].dt.hour\n",
    "\n",
    "# Calculate average fare_amount grouped by pickup hour \n",
    "hour_groups = train.groupby('hour')['fare_amount'].mean()\n",
    "\n",
    "# Make predictions on the test set\n",
    "test['fare_amount'] = test.hour.map(hour_groups)\n",
    "\n",
    "# Write predictions\n",
    "test[['id','fare_amount']].to_csv(prefix+'hour_mean_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline based on the gradient boosting\n",
    "Let's build a final baseline based on the Random Forest. You've seen a huge score improvement moving from the grouping baseline to the Gradient Boosting in the video. Now, you will use sklearn's Random Forest to further improve this score.\n",
    "\n",
    "The goal of this exercise is to take numeric features and train a Random Forest model without any tuning. After that, you could make test predictions and validate the result on the Public Leaderboard. Note that you've already got an \"hour\" feature which could also be used as an input to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:08:38.616820Z",
     "start_time": "2020-02-19T08:08:34.414039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'test.csv': 'https://file.io/L97IDp', 'train.csv': 'https://file.io/NjXqT8'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  789k    0  789k    0     0   356k      0 --:--:--  0:00:02 --:--:--  356k\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1694k    0 1694k    0     0   949k      0 --:--:--  0:00:01 --:--:--  949k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(train, test)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'test.csv': 'https://file.io/L97IDp',\n",
    "  'train.csv': 'https://file.io/NjXqT8'}}\n",
    "\"\"\"\n",
    "prefixToc='1.3'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"10.225.92.1:80\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "test = pd.read_csv(prefix+'test.csv',index_col=0, parse_dates=['pickup_datetime'])\n",
    "train = pd.read_csv(prefix+'train.csv',index_col=0, parse_dates=['pickup_datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:09:45.729930Z",
     "start_time": "2020-02-19T08:09:45.710136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19995</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-73.985163</td>\n",
       "      <td>40.747282</td>\n",
       "      <td>-73.974358</td>\n",
       "      <td>40.743270</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19996</td>\n",
       "      <td>38.5</td>\n",
       "      <td>-73.783457</td>\n",
       "      <td>40.648702</td>\n",
       "      <td>-73.954360</td>\n",
       "      <td>40.620647</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19997</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-74.015404</td>\n",
       "      <td>40.709366</td>\n",
       "      <td>-73.978844</td>\n",
       "      <td>40.764610</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19998</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-73.973275</td>\n",
       "      <td>40.760405</td>\n",
       "      <td>-73.984875</td>\n",
       "      <td>40.711660</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19999</td>\n",
       "      <td>8.9</td>\n",
       "      <td>-73.974628</td>\n",
       "      <td>40.741923</td>\n",
       "      <td>-73.985966</td>\n",
       "      <td>40.722214</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  fare_amount  pickup_longitude  pickup_latitude  \\\n",
       "0          0          4.5        -73.844311        40.721319   \n",
       "1          1         16.9        -74.016048        40.711303   \n",
       "2          2          5.7        -73.982738        40.761270   \n",
       "3          3          7.7        -73.987130        40.733143   \n",
       "4          4          5.3        -73.968095        40.768008   \n",
       "...      ...          ...               ...              ...   \n",
       "19995  19995          6.1        -73.985163        40.747282   \n",
       "19996  19996         38.5        -73.783457        40.648702   \n",
       "19997  19997         22.0        -74.015404        40.709366   \n",
       "19998  19998         12.5        -73.973275        40.760405   \n",
       "19999  19999          8.9        -73.974628        40.741923   \n",
       "\n",
       "       dropoff_longitude  dropoff_latitude  passenger_count  hour  \n",
       "0             -73.841610         40.712278                1    17  \n",
       "1             -73.979268         40.782004                1    16  \n",
       "2             -73.991242         40.750562                2     0  \n",
       "3             -73.991567         40.758092                1     4  \n",
       "4             -73.956655         40.783762                1     7  \n",
       "...                  ...               ...              ...   ...  \n",
       "19995         -73.974358         40.743270                2    20  \n",
       "19996         -73.954360         40.620647                1    22  \n",
       "19997         -73.978844         40.764610                1    20  \n",
       "19998         -73.984875         40.711660                1    12  \n",
       "19999         -73.985966         40.722214                1    14  \n",
       "\n",
       "[20000 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:11:00.085471Z",
     "start_time": "2020-02-19T08:10:46.674477Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Select only numeric features\n",
    "features = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "            'dropoff_latitude', 'passenger_count', 'hour']\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(train[features], train.fare_amount)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['fare_amount'] = rf.predict(test[features])\n",
    "\n",
    "# Write predictions\n",
    "test[['id','fare_amount']].to_csv(prefix+'rf_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "Recall that we've created a baseline Gradient Boosting model in the previous lesson. Your goal now is to find the best max_depth hyperparameter value for this Gradient Boosting model. This hyperparameter limits the number of nodes in each individual tree. You will be using K-fold cross-validation to measure the local performance of the model for each hyperparameter value.\n",
    "\n",
    "You're given a function get_cv_score(), which takes the train dataset and dictionary of the model parameters as arguments and returns the overall validation RMSE score over 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:20:17.700330Z",
     "start_time": "2020-02-19T08:20:17.694112Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "import inspect\n",
    "print_func(get_cv_score)\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "def get_cv_score(train, params):\n",
    "    # Create KFold object\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "    rmse_scores = []\n",
    "    \n",
    "    # Loop through each split\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "        # Train a Gradient Boosting model\n",
    "        gb = GradientBoostingRegressor(random_state=123, **params).fit(cv_train[features], cv_train.fare_amount)\n",
    "    \n",
    "        # Make predictions on the test data\n",
    "        pred = gb.predict(cv_test[features])\n",
    "    \n",
    "        fold_score = np.sqrt(mean_squared_error(cv_test['fare_amount'], pred))\n",
    "        rmse_scores.append(fold_score)\n",
    "    \n",
    "    return np.round(np.mean(rmse_scores) + np.std(rmse_scores), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:20:18.173839Z",
     "start_time": "2020-02-19T08:20:18.155187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements déjà effectués - SKIP\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(train )\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'train.csv': 'https://file.io/MT19wB'}}\n",
    "\"\"\"\n",
    "prefixToc='2.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"10.225.92.1:80\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv(prefix+'train.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:20:22.538111Z",
     "start_time": "2020-02-19T08:20:19.499835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 6.77121, 6: 6.60667, 9: 6.74336, 12: 6.81073, 15: 6.88673}\n"
     ]
    }
   ],
   "source": [
    "# Possible max depth values\n",
    "max_depth_grid = [3,6,9,12,15]\n",
    "results = {}\n",
    "\n",
    "# For each value in the grid\n",
    "for max_depth_candidate in max_depth_grid:\n",
    "    # Specify parameters for the model\n",
    "    params = {'max_depth': max_depth_candidate}\n",
    "\n",
    "    # Calculate validation score for a particular hyperparameter\n",
    "    validation_score = get_cv_score(train, params)\n",
    "\n",
    "    # Save the results for each max depth value\n",
    "    results[max_depth_candidate] = validation_score   \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D grid search\n",
    "The drawback of tuning each hyperparameter independently is a potential dependency between different hyperparameters. The better approach is to try all the possible hyperparameter combinations. However, in such cases, the grid search space is rapidly expanding. For example, if we have 2 parameters with 10 possible values, it will yield 100 experiment runs.\n",
    "\n",
    "Your goal is to find the best hyperparameter couple of max_depth and subsample for the Gradient Boosting model. subsample is a fraction of observations to be used for fitting the individual trees.\n",
    "\n",
    "You're given a function get_cv_score(), which takes the train dataset and dictionary of the model parameters as arguments and returns the overall validation RMSE score over 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:21:37.504094Z",
     "start_time": "2020-02-19T08:21:37.499387Z"
    }
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:23:16.109248Z",
     "start_time": "2020-02-19T08:23:12.572425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(3, 0.8): 6.53359, (3, 0.9): 6.58451, (3, 1.0): 6.77121, (5, 0.8): 6.403, (5, 0.9): 6.6295, (5, 1.0): 6.73183, (7, 0.8): 6.33958, (7, 0.9): 6.60381, (7, 1.0): 6.6401}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Hyperparameter grids\n",
    "max_depth_grid = [3,5,7]\n",
    "subsample_grid = [0.8,0.9,1.0]\n",
    "results = {}\n",
    "\n",
    "# For each couple in the grid\n",
    "for max_depth_candidate, subsample_candidate in itertools.product(max_depth_grid, subsample_grid):\n",
    "    params = {'max_depth': max_depth_candidate,\n",
    "              'subsample': subsample_candidate}\n",
    "    validation_score = get_cv_score(train, params)\n",
    "    # Save the results for each couple\n",
    "    results[(max_depth_candidate, subsample_candidate)] = validation_score   \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ensembling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model blending\n",
    "You will start creating model ensembles with a blending technique.\n",
    "\n",
    "Your goal is to train 2 different models on the New York City Taxi competition data. Make predictions on the test data and then blend them using a simple arithmetic mean.\n",
    "\n",
    "The train and test DataFrames are already available in your workspace. features is a list of columns to be used for training and it is also available in your workspace. The target variable name is \"fare_amount\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:31:13.136257Z",
     "start_time": "2020-02-19T08:31:13.111214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements déjà effectués - SKIP\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(train, test)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'test.csv': 'https://file.io/b2Veyh',\n",
    "  'train.csv': 'https://file.io/LX4SEh'}}\n",
    "\"\"\"\n",
    "prefixToc='3.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"10.225.92.1:80\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "test = pd.read_csv(prefix+'test.csv',index_col=0)\n",
    "train = pd.read_csv(prefix+'train.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:31:40.336202Z",
     "start_time": "2020-02-19T08:31:40.332515Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['pickup_longitude',\n",
    " 'pickup_latitude',\n",
    " 'dropoff_longitude',\n",
    " 'dropoff_latitude',\n",
    " 'passenger_count',\n",
    " 'distance_km',\n",
    " 'hour']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:32:58.200875Z",
     "start_time": "2020-02-19T08:32:57.606742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gb_pred  rf_pred     blend\n",
      "0  9.661374    8.907  9.284187\n",
      "1  9.304288    8.130  8.717144\n",
      "2  5.795140    4.663  5.229070\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb = GradientBoostingRegressor().fit(train[features], train.fare_amount)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor().fit(train[features], train.fare_amount)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['gb_pred'] = gb.predict(test[features])\n",
    "test['rf_pred'] = rf.predict(test[features])\n",
    "\n",
    "# Find mean of model predictions\n",
    "test['blend'] = (test['gb_pred'] + test['rf_pred']) / 2\n",
    "print(test[['gb_pred', 'rf_pred', 'blend']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model stacking I\n",
    "Now it's time for stacking. To implement the stacking approach, you will follow the 6 steps we've discussed in the previous video:\n",
    "\n",
    "- Split train data into two parts\n",
    "- Train multiple models on Part 1\n",
    "- Make predictions on Part 2\n",
    "- Make predictions on the test data\n",
    "- Train a new model on Part 2 using predictions as features\n",
    "- Make predictions on the test data using the 2nd level model\n",
    "\n",
    "train and test DataFrames are already available in your workspace. features is a list of columns to be used for training on the Part 1 data and it is also available in your workspace. Target variable name is \"fare_amount\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:43:03.475331Z",
     "start_time": "2020-02-19T08:43:03.155775Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Split train data into two parts\n",
    "part_1, part_2 = train_test_split(train, test_size=0.5, random_state=123)\n",
    "\n",
    "# Train a Gradient Boosting model on Part 1\n",
    "gb = GradientBoostingRegressor().fit(part_1[features], part_1.fare_amount)\n",
    "\n",
    "# Train a Random Forest model on Part 1\n",
    "rf = RandomForestRegressor().fit(part_1[features], part_1.fare_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T08:44:20.103569Z",
     "start_time": "2020-02-19T08:44:20.057487Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-fb9f7cd87009>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  part_2['gb_pred'] = gb.predict(part_2[features])\n",
      "<ipython-input-43-fb9f7cd87009>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  part_2['rf_pred'] = rf.predict(part_2[features])\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the Part 2 data\n",
    "part_2['gb_pred'] = gb.predict(part_2[features])\n",
    "part_2['rf_pred'] = rf.predict(part_2[features])\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['gb_pred'] = gb.predict(test[features])\n",
    "test['rf_pred'] = rf.predict(test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model stacking II\n",
    "OK, what you've done so far in the stacking implementation:\n",
    "\n",
    "- Split train data into two parts\n",
    "- Train multiple models on Part 1\n",
    "- Make predictions on Part 2\n",
    "- Make predictions on the test data\n",
    "\n",
    "Now, your goal is to create a second level model using predictions from steps 3 and 4 as features. So, this model is trained on Part 2 data and then you can make stacking predictions on the test data.\n",
    "\n",
    "part_2 and test DataFrames are already available in your workspace. Gradient Boosting and Random Forest predictions are stored in these DataFrames under the names \"gb_pred\" and \"rf_pred\", respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T14:37:03.993082Z",
     "start_time": "2020-02-19T14:37:01.945842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'part_2.csv': 'https://file.io/OGVcb8', 'test.csv': 'https://file.io/i7krVF'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 54048    0 54048    0     0  70010      0 --:--:-- --:--:-- --:--:-- 70101\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  101k    0  101k    0     0   216k      0 --:--:-- --:--:-- --:--:--  216k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(part_2 , test)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'part_2.csv': 'https://file.io/OGVcb8',\n",
    "  'test.csv': 'https://file.io/i7krVF'}}\n",
    "\"\"\"\n",
    "prefixToc='3.3'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"10.225.92.1:80\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "part_2 = pd.read_csv(prefix+'part_2.csv',index_col=0)\n",
    "test = pd.read_csv(prefix+'test.csv',index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T14:39:08.952082Z",
     "start_time": "2020-02-19T14:39:08.929890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>hour</th>\n",
       "      <th>gb_pred</th>\n",
       "      <th>rf_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>16.5</td>\n",
       "      <td>-73.983837</td>\n",
       "      <td>40.676052</td>\n",
       "      <td>-74.002522</td>\n",
       "      <td>40.723145</td>\n",
       "      <td>1</td>\n",
       "      <td>5.468283</td>\n",
       "      <td>23</td>\n",
       "      <td>14.799923</td>\n",
       "      <td>16.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>11.3</td>\n",
       "      <td>-73.993973</td>\n",
       "      <td>40.746577</td>\n",
       "      <td>-74.005060</td>\n",
       "      <td>40.709365</td>\n",
       "      <td>1</td>\n",
       "      <td>4.241944</td>\n",
       "      <td>20</td>\n",
       "      <td>12.298103</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-73.985582</td>\n",
       "      <td>40.739765</td>\n",
       "      <td>-73.973899</td>\n",
       "      <td>40.760426</td>\n",
       "      <td>1</td>\n",
       "      <td>2.499316</td>\n",
       "      <td>9</td>\n",
       "      <td>10.087326</td>\n",
       "      <td>8.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.984797</td>\n",
       "      <td>40.763133</td>\n",
       "      <td>-73.975928</td>\n",
       "      <td>40.765276</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784031</td>\n",
       "      <td>23</td>\n",
       "      <td>6.353219</td>\n",
       "      <td>4.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-73.980735</td>\n",
       "      <td>40.747911</td>\n",
       "      <td>-73.970530</td>\n",
       "      <td>40.761998</td>\n",
       "      <td>1</td>\n",
       "      <td>1.786755</td>\n",
       "      <td>11</td>\n",
       "      <td>9.699922</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0  131         16.5        -73.983837        40.676052         -74.002522   \n",
       "1  203         11.3        -73.993973        40.746577         -74.005060   \n",
       "2   50          9.7        -73.985582        40.739765         -73.973899   \n",
       "3  585          5.7        -73.984797        40.763133         -73.975928   \n",
       "4  138          6.5        -73.980735        40.747911         -73.970530   \n",
       "\n",
       "   dropoff_latitude  passenger_count  distance_km  hour    gb_pred  rf_pred  \n",
       "0         40.723145                1     5.468283    23  14.799923    16.06  \n",
       "1         40.709365                1     4.241944    20  12.298103    17.00  \n",
       "2         40.760426                1     2.499316     9  10.087326     8.81  \n",
       "3         40.765276                2     0.784031    23   6.353219     4.91  \n",
       "4         40.761998                1     1.786755    11   9.699922     9.18  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T14:39:55.198773Z",
     "start_time": "2020-02-19T14:39:54.624177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72504358 0.27647395]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression model without the intercept\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# Train 2nd level model on the Part 2 data\n",
    "lr.fit(part_2[['gb_pred', 'rf_pred']], part_2.fare_amount)\n",
    "\n",
    "# Make stacking predictions on the test data\n",
    "test['stacking'] = lr.predict(test[['gb_pred', 'rf_pred']])\n",
    "\n",
    "# Look at the model coefficients\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Kaggle forum ideas\n",
    "Unfortunately, not all the Forum posts and Kernels are necessarily useful for your model. So instead of blindly incorporating ideas into your pipeline, you should test them first.\n",
    "\n",
    "You're given a function get_cv_score(), which takes a train dataset as an argument and returns the overall validation root mean squared error over 3-fold cross-validation. The train DataFrame is already available in your workspace.\n",
    "\n",
    "You should try different suggestions from the Kaggle Forum and check whether they improve your validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T14:46:06.455533Z",
     "start_time": "2020-02-19T14:46:05.578136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargements à lancer\n",
      "{'pandas.core.frame.DataFrame': {'train.csv': 'https://file.io/GxU6cU'}}\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 84136    0 84136    0     0   105k      0 --:--:-- --:--:-- --:--:--  105k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### Dataframe\n",
    "###################\n",
    "\n",
    "#upload and download\n",
    "\n",
    "from downloadfromFileIO import saveFromFileIO\n",
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "uploadToFileIO(train)\n",
    "\"\"\"\n",
    "\n",
    "tobedownloaded=\"\"\"\n",
    "{pandas.core.frame.DataFrame: {'train.csv': 'https://file.io/GxU6cU'}}\n",
    "\"\"\"\n",
    "prefixToc='4.1'\n",
    "prefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"10.225.92.1:80\")\n",
    "\n",
    "#initialisation\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv(prefix+'train.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T14:49:42.989528Z",
     "start_time": "2020-02-19T14:49:42.983107Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\n",
    "import inspect\n",
    "print_func(get_cv_score)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def get_cv_score(train):\n",
    "    features = ['pickup_longitude', 'pickup_latitude',\n",
    "            'dropoff_longitude', 'dropoff_latitude',\n",
    "            'passenger_count', 'distance_km', 'hour', 'weird_feature']\n",
    "    \n",
    "    features = [x for x in features if x in train.columns]\n",
    "  \n",
    "    # Create KFold object\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "    rmse_scores = []\n",
    "    \n",
    "    # Loop through each split\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "        # Train a Gradient Boosting model\n",
    "        gb = GradientBoostingRegressor(random_state=123).fit(cv_train[features], cv_train.fare_amount)\n",
    "    \n",
    "        # Make predictions on the test data\n",
    "        pred = gb.predict(cv_test[features])\n",
    "    \n",
    "        fold_score = np.sqrt(mean_squared_error(cv_test['fare_amount'], pred))\n",
    "        rmse_scores.append(fold_score)\n",
    "    \n",
    "    return np.round(np.mean(rmse_scores) + np.std(rmse_scores), 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T14:49:43.360774Z",
     "start_time": "2020-02-19T14:49:43.349705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>1.030764</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>8.450134</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>1.389525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>2.799270</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>1.999157</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0   0          4.5        -73.844311        40.721319         -73.841610   \n",
       "1   1         16.9        -74.016048        40.711303         -73.979268   \n",
       "2   2          5.7        -73.982738        40.761270         -73.991242   \n",
       "3   3          7.7        -73.987130        40.733143         -73.991567   \n",
       "4   4          5.3        -73.968095        40.768008         -73.956655   \n",
       "\n",
       "   dropoff_latitude  passenger_count  distance_km  hour  \n",
       "0         40.712278                1     1.030764    17  \n",
       "1         40.782004                1     8.450134    16  \n",
       "2         40.750562                2     1.389525     0  \n",
       "3         40.758092                1     2.799270     4  \n",
       "4         40.783762                1     1.999157     7  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first suggestion worked. Suggestion 2: Sum of \"pickup_latitude\" and \"distance_km\" is a good feature. Let's try it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T14:49:44.896917Z",
     "start_time": "2020-02-19T14:49:44.230375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial score is 6.49932 and the new score is 6.42315\n"
     ]
    }
   ],
   "source": [
    "# Delete passenger_count column\n",
    "new_train_1 = train.drop('passenger_count', axis=1)\n",
    "\n",
    "# Compare validation scores\n",
    "initial_score = get_cv_score(train)\n",
    "new_score = get_cv_score(new_train_1)\n",
    "\n",
    "print('Initial score is {} and the new score is {}'.format(initial_score, new_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first suggestion worked. Suggestion 2: Sum of \"pickup_latitude\" and \"distance_km\" is a good feature. Let's try it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T14:54:13.542221Z",
     "start_time": "2020-02-19T14:54:12.826920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial score is 6.49932 and the new score is 6.50495\n"
     ]
    }
   ],
   "source": [
    "# Create copy of the initial train DataFrame\n",
    "new_train_2 = train.copy()\n",
    "\n",
    "# Find sum of pickup latitude and ride distance\n",
    "new_train_2['weird_feature'] = new_train_2.pickup_latitude + new_train_2.distance_km\n",
    "\n",
    "# Compare validation scores\n",
    "initial_score = get_cv_score(train)\n",
    "new_score = get_cv_score(new_train_2)\n",
    "\n",
    "print('Initial score is {} and the new score is {}'.format(initial_score, new_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
