Exercise - Creating time-shifted features
In machine learning for time series, it's common to use information about previous time points to predict a subsequent time point.

In this exercise, you'll "shift" your raw data and visualize the results. You'll use the percent change time series that you calculated in the previous chapter, this time with a very short window. A short window is important because, in a real-world scenario, you want to predict the day-to-day fluctuations of a time series, not its change over a longer window of time.

		# These are the "time lags"
		shifts = np.arange(1, 11).astype(int)

		# Use a dictionary comprehension to create name: value pairs, one pair per shift
		shifted_data = {"lag_{}_day".format(day_shift): prices_perc.shift(day_shift) for day_shift in shifts}

		# Convert into a DataFrame for subsequent use
		prices_perc_shifted = pd.DataFrame(shifted_data)

		# Plot the first 100 samples of each
		ax = prices_perc_shifted.iloc[:100].plot(cmap=plt.cm.viridis)
		prices_perc.iloc[:100].plot(color='r', lw=2)
		ax.legend(loc='best')
		plt.show()
		
Exercise - Special case: Auto-regressive models
Now that you've created time-shifted versions of a single time series, you can fit an auto-regressive model. This is a regression model where the input features are time-shifted versions of the output time series data. You are using previous values of a timeseries to predict current values of the same timeseries (thus, it is auto-regressive).

By investigating the coefficients of this model, you can explore any repetitive patterns that exist in a timeseries, and get an idea for how far in the past a data point is predictive of the future.

		# Replace missing values with the median for each column
		X = prices_perc_shifted.fillna(np.nanmedian(prices_perc_shifted))
		y = prices_perc.fillna(np.nanmedian(prices_perc))

		# Fit the model
		model = Ridge()
		model.fit(X, y)


Exercise - Visualize regression coefficients
Now that you've fit the model, let's visualize its coefficients. This is an important part of machine learning because it gives you an idea for how the different features of a model affect the outcome.

The shifted time series DataFrame (prices_perc_shifted) and the regression model (model) are available in your workspace.

In this exercise, you will create a function that, given a set of coefficients and feature names, visualizes the coefficient values.


		def visualize_coefficients(coefs, names, ax):
			# Make a bar plot for the coefficients, including their names on the x-axis
			ax.bar(names, coefs)
			ax.set(xlabel='Coefficient name', ylabel='Coefficient value')
			
			# Set formatting so it looks nice
			plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')
			return ax

		# Visualize the output data up to "2011-01"
		fig, axs = plt.subplots(2, 1, figsize=(10, 5))
		y.loc[:'2011-01'].plot(ax=axs[0])

		# Run the function to visualize model's coefficients
		visualize_coefficients(model.coef_, X.columns.to_list() , ax=axs[1])
		plt.show()

Exercise - Auto-regression with a smoother time series
Now, let's re-run the same procedure using a smoother signal. You'll use the same percent change algorithm as before, but this time use a much larger window (40 instead of 20). As the window grows, the difference between neighboring timepoints gets smaller, resulting in a smoother signal. What do you think this will do to the auto-regressive model?

prices_perc_shifted and model (updated to use a window of 40) are available in your workspace.

		# Visualize the output data up to "2011-01"
		fig, axs = plt.subplots(2, 1, figsize=(10, 5))
		y.loc[:'2011-01'].plot(ax=axs[0])

		# Run the function to visualize model's coefficients
		visualize_coefficients(model.coef_, prices_perc_shifted.columns, ax=axs[1])
		plt.show()
		
Exercise - Cross-validation with shuffling
As you'll recall, cross-validation is the process of splitting your data into training and test sets multiple times. Each time you do this, you choose a different training and test set. In this exercise, you'll perform a traditional ShuffleSplit cross-validation on the company value data from earlier. Later we'll cover what changes need to be made for time series data. The data we'll use is the same historical price data for several large companies.

An instance of the Linear regression object (model) is available in your workspace along with the function r2_score() for scoring. Also, the data is stored in arrays X and y. We've also provided a helper function (visualize_predictions()) to help visualize the results.

		# Import ShuffleSplit and create the cross-validation object
		from sklearn.model_selection import ShuffleSplit
		cv = ShuffleSplit(n_splits=10, random_state=1)

		# Iterate through CV splits
		results = []
		for tr, tt in cv.split(X, y):
			# Fit the model on training data
			model.fit(X[tr], y[tr])
			
			# Generate predictions on the test data, score the predictions, and collect
			prediction = model.predict(X[tt])
			score = r2_score(y[tt], prediction)
			results.append((prediction, score, tt))

		# Custom function to quickly visualize predictions
		visualize_predictions(results)