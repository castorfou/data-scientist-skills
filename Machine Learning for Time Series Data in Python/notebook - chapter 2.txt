Exercise - Many repetitions of sounds
In this exercise, you'll start with perhaps the simplest classification technique: averaging across dimensions of a dataset and visually inspecting the result.

You'll use the heartbeat data described in the last chapter. Some recordings are normal heartbeat activity, while others are abnormal activity. Let's see if you can spot the difference.

Two DataFrames, normal and abnormal, each with the shape of (n_times_points, n_audio_files) containing the audio for several heartbeats are available in your workspace. Also, the sampling frequency is loaded into a variable called sfreq. A convenience plotting function show_plot_and_make_titles() is also available in your workspace.

		fig, axs = plt.subplots(3, 2, figsize=(15, 7), sharex=True, sharey=True)

		# Calculate the time array
		time = np.arange(normal.shape[0]) / sfreq

		# Stack the normal/abnormal audio so you can loop and plot
		stacked_audio = np.hstack([normal, abnormal]).T

		# Loop through each audio file / ax object and plot
		# .T.ravel() transposes the array, then unravels it into a 1-D vector for looping
		for iaudio, ax in zip(stacked_audio, axs.T.ravel()):
			ax.plot(time, iaudio)
		show_plot_and_make_titles()
		
Exercise - Invariance in time
While you should always start by visualizing your raw data, this is often uninformative when it comes to discriminating between two classes of data points. Data is usually noisy or exhibits complex patterns that aren't discoverable by the naked eye.

Another common technique to find simple differences between two sets of data is to average across multiple instances of the same class. This may remove noise and reveal underlying patterns (or, it may not).

In this exercise, you'll average across many instances of each class of heartbeat sound.

The two DataFrames (normal and abnormal) and the time array (time) from the previous exercise are available in your workspace.

		# Average across the audio files of each DataFrame
		mean_normal = np.mean(normal, axis=1)
		mean_abnormal = np.mean(abnormal, axis=1)

		# Plot each average over time
		fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)
		ax1.plot(time, mean_normal)
		ax1.set(title="Normal Data")
		ax2.plot(time, mean_abnormal)
		ax2.set(title="Abnormal Data")
		plt.show()
		
Exercise - Build a classification model
While eye-balling differences is a useful way to gain an intuition for the data, let's see if you can operationalize things with a model. In this exercise, you will use each repetition as a datapoint, and each moment in time as a feature to fit a classifier that attempts to predict abnormal vs. normal heartbeats using only the raw data.

We've split the two DataFrames (normal and abnormal) into X_train, X_test, y_train, and y_test.

		from sklearn.svm import LinearSVC

		# Initialize and fit the model
		model = LinearSVC()
		model.fit(X_train, y_train)

		# Generate predictions and score them manually
		predictions = model.predict(X_test)
		print(sum(predictions == y_test.squeeze()) / len(y_test))
		
Exercise - Calculating the envelope of sound
One of the ways you can improve the features available to your model is to remove some of the noise present in the data. In audio data, a common way to do this is to smooth the data and then rectify it so that the total amount of sound energy over time is more distinguishable. You'll do this in the current exercise.

A heartbeat file is available in the variable audio.

		# Plot the raw data first
		audio.plot(figsize=(10, 5))
		plt.show()

		# Rectify the audio signal
		audio_rectified = audio.apply(np.abs)

		# Plot the result
		audio_rectified.plot(figsize=(10, 5))
		plt.show()

		# Smooth by applying a rolling mean
		audio_rectified_smooth = audio_rectified.rolling(50).mean()

		# Plot the result
		audio_rectified_smooth.plot(figsize=(10, 5))
		plt.show()
